@misc{aapor_evaluation_2016,
  title = {An {{Evaluation}} of 2016 {{Election Polls}} in the {{U}}.{{S}}.},
  author = {{AAPOR}},
  year = {2016},
  journal = {American Association for Public Opinion Research},
  howpublished = {https://www.aapor.org/Education-Resources/Reports/An-Evaluation-of-2016-Election-Polls-in-the-U-S.aspx},
  file = {/Users/charliejhadley/Zotero/storage/PDL5DG75/An-Evaluation-of-2016-Election-Polls-in-the-U-S.html}
}

@inproceedings{aggarwal_k-anonymity_2005,
  title = {On K-Anonymity and the Curse of Dimensionality},
  booktitle = {Proceedings of the 31st International Conference on {{Very}} Large Data Bases},
  author = {Aggarwal, Charu C.},
  year = {2005},
  month = aug,
  series = {{{VLDB}} '05},
  pages = {901--909},
  publisher = {{VLDB Endowment}},
  address = {{Trondheim, Norway}},
  abstract = {In recent years, the wide availability of personal data has made the problem of privacy preserving data mining an important one. A number of methods have recently been proposed for privacy preserving data mining of multidimensional data records. One of the methods for privacy preserving data mining is that of anonymization, in which a record is released only if it is indistinguishable from k other entities in the data. We note that methods such as k-anonymity are highly dependent upon spatial locality in order to effectively implement the technique in a statistically robust way. In high dimensional space the data becomes sparse, and the concept of spatial locality is no longer easy to define from an application point of view. In this paper, we view the k-anonymization problem from the perspective of inference attacks over all possible combinations of attributes. We show that when the data contains a large number of attributes which may be considered quasi-identifiers, it becomes difficult to anonymize the data without an unacceptably high amount of information loss. This is because an exponential number of combinations of dimensions can be used to make precise inference attacks, even when individual attributes are partially specified within a range. We provide an analysis of the effect of dimensionality on k-anonymity methods. We conclude that when a data set contains a large number of attributes which are open to inference attacks, we are faced with a choice of either completely suppressing most of the data or losing the desired level of anonymity. Thus, this paper shows that the curse of high dimensionality also applies to the problem of privacy preserving data mining.},
  isbn = {978-1-59593-154-2},
  file = {/Users/charliejhadley/Zotero/storage/MH5N749L/Aggarwal - 2005 - On k-anonymity and the curse of dimensionality.pdf}
}

@article{ahn_flavor_2011,
  title = {Flavor Network and the Principles of Food Pairing},
  author = {Ahn, Yong-Yeol and Ahnert, Sebastian E. and Bagrow, James P. and Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  year = {2011},
  month = dec,
  journal = {Scientific Reports},
  volume = {1},
  number = {1},
  pages = {196},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep00196},
  abstract = {The cultural diversity of culinary practice, as illustrated by the variety of regional cuisines, raises the question of whether there are any general patterns that determine the ingredient combinations used in food today or principles that transcend individual tastes and recipes. We introduce a flavor network that captures the flavor compounds shared by culinary ingredients. Western cuisines show a tendency to use ingredient pairs that share many flavor compounds, supporting the so-called food pairing hypothesis. By contrast, East Asian cuisines tend to avoid compound sharing ingredients. Given the increasing availability of information on food preparation, our data-driven investigation opens new avenues towards a systematic understanding of culinary practice.},
  copyright = {2011 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_y Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Applied physics;Statistical physics, thermodynamics and nonlinear dynamics;Statistics;Systems biology Subject\_term\_id: applied-physics;statistical-physics-thermodynamics-and-nonlinear-dynamics;statistics;systems-biology},
  file = {/Users/charliejhadley/Zotero/storage/8JGD2UZ4/Ahn et al. - 2011 - Flavor network and the principles of food pairing.pdf;/Users/charliejhadley/Zotero/storage/8W5FI5QM/srep00196.html}
}

@article{ahn_flavor_2011-1,
  title = {Flavor Network and the Principles of Food Pairing},
  author = {Ahn, Yong-Yeol and Ahnert, Sebastian E. and Bagrow, James P. and Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  year = {2011},
  month = dec,
  journal = {Scientific Reports},
  volume = {1},
  number = {1},
  pages = {196},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep00196},
  abstract = {The cultural diversity of culinary practice, as illustrated by the variety of regional cuisines, raises the question of whether there are any general patterns that determine the ingredient combinations used in food today or principles that transcend individual tastes and recipes. We introduce a flavor network that captures the flavor compounds shared by culinary ingredients. Western cuisines show a tendency to use ingredient pairs that share many flavor compounds, supporting the so-called food pairing hypothesis. By contrast, East Asian cuisines tend to avoid compound sharing ingredients. Given the increasing availability of information on food preparation, our data-driven investigation opens new avenues towards a systematic understanding of culinary practice.},
  copyright = {2011 The Author(s)},
  langid = {english},
  keywords = {Applied physics,Statistical physics,Statistics,Systems biology,thermodynamics and nonlinear dynamics},
  file = {/Users/charliejhadley/Zotero/storage/38RGLGXM/Ahn et al. - 2011 - Flavor network and the principles of food pairing.pdf;/Users/charliejhadley/Zotero/storage/93VWW5QJ/srep00196.html}
}

@misc{ahrc_ahrc_2022,
  title = {{{AHRC Research Funding Guide}}},
  author = {{AHRC}},
  year = {2022},
  month = aug,
  howpublished = {https://www.ukri.org/wp-content/uploads/2022/07/AHRC-210722-ResearchFundingGuide.pdf}
}

@article{ananny_seeing_2018,
  title = {Seeing without Knowing: {{Limitations}} of the Transparency Ideal and Its Application to Algorithmic Accountability},
  shorttitle = {Seeing without Knowing},
  author = {Ananny, Mike and Crawford, Kate},
  year = {2018},
  month = mar,
  journal = {New Media \& Society},
  volume = {20},
  number = {3},
  pages = {973--989},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444816676645},
  abstract = {Models for understanding and holding systems accountable have long rested upon ideals and logics of transparency. Being able to see a system is sometimes equated with being able to know how it works and govern it\textemdash a pattern that recurs in recent work about transparency and computational systems. But can ``black boxes' ever be opened, and if so, would that ever be sufficient? In this article, we critically interrogate the ideal of transparency, trace some of its roots in scientific and sociotechnical epistemological cultures, and present 10 limitations to its application. We specifically focus on the inadequacy of transparency for understanding and governing algorithmic systems and sketch an alternative typology of algorithmic accountability grounded in constructive engagements with the limitations of transparency ideals.},
  langid = {english},
  keywords = {algorithm accountability,algorithm application bias,algorithm training bias,algorithm transparency},
  file = {/Users/charliejhadley/Zotero/storage/3ZK393NY/Ananny and Crawford - 2018 - Seeing without knowing Limitations of the transpa.pdf}
}

@article{anscombe_graphs_1973,
  title = {Graphs in {{Statistical Analysis}}},
  author = {Anscombe, F. J.},
  year = {1973},
  month = feb,
  journal = {The American Statistician},
  volume = {27},
  number = {1},
  pages = {17--21},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.1973.10478966},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/5XG7NS78/Anscombe - 1973 - Graphs in Statistical Analysis.pdf}
}

@article{aschwanden_were_2019,
  title = {We're {{All}} '{{P-Hacking}}' {{Now}}},
  author = {Aschwanden, Christie},
  year = {2019},
  month = nov,
  journal = {Wired},
  abstract = {An insiders' term for scientific malpractice has worked its way into pop culture. Is that a good thing?},
  chapter = {tags},
  langid = {american},
  keywords = {metascience,p-hacking,pop culture,reproducibility,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/3URNX6NQ/were-all-p-hacking-now.html}
}

@article{awad_moral_2018,
  title = {The {{Moral Machine}} Experiment},
  author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-Fran{\c c}ois and Rahwan, Iyad},
  year = {2018},
  month = nov,
  journal = {Nature},
  volume = {563},
  number = {7729},
  pages = {59--64},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-018-0637-6},
  abstract = {With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondents' demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available.},
  copyright = {2018 Springer Nature Limited},
  langid = {english},
  keywords = {Culture,Ethics,Human behaviour},
  file = {/Users/charliejhadley/Zotero/storage/QCPH4J93/Awad et al. - 2018 - The Moral Machine experiment.pdf;/Users/charliejhadley/Zotero/storage/NGF3NBSH/s41586-018-0637-6.html}
}

@misc{barocas_big_2016,
  type = {{{SSRN Scholarly Paper}}},
  title = {Big {{Data}}'s {{Disparate Impact}}},
  author = {Barocas, Solon and Selbst, Andrew D.},
  year = {2016},
  number = {2477899},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.2477899},
  abstract = {Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm's use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court.},
  langid = {english},
  keywords = {algorithms,big data,civil rights,data mining,discrimination,disparate impact,disparate treatment,employment discrimination,inequality,procedural fairness,substantive fairness,Title VII},
  file = {/Users/charliejhadley/Zotero/storage/J7FXLHDD/Barocas and Selbst - 2016 - Big Data's Disparate Impact.pdf;/Users/charliejhadley/Zotero/storage/4MZI2FTV/papers.html}
}

@article{batterton_likert_2017,
  title = {The {{Likert Scale What It Is}} and {{How To Use It}}},
  author = {Batterton, Katherine A. and Hale, Kimberly N.},
  year = {2017},
  journal = {Phalanx},
  volume = {50},
  number = {2},
  pages = {32--39},
  publisher = {{Military Operations Research Society}},
  issn = {0195-1920},
  file = {/Users/charliejhadley/Zotero/storage/FSQGUB2I/Batterton and Hale - 2017 - The Likert Scale What It Is and How To Use It.pdf}
}

@misc{bbsrc_bbsrc_2022,
  title = {{{BBSRC Data Sharing Policy}}},
  author = {{BBSRC}},
  year = {2022},
  month = aug,
  howpublished = {https://www.ukri.org/wp-content/uploads/2021/07/data-sharing-policy-v1.22.pdf}
}

@article{beecham_use_2021,
  title = {On the {{Use}} of `{{Glyphmaps}}' for {{Analysing}} the {{Scale}} and {{Temporal Spread}} of {{COVID-19 Reported Cases}}},
  author = {Beecham, Roger and Dykes, Jason and Hama, Layik and Lomax, Nik},
  year = {2021},
  month = apr,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {10},
  number = {4},
  pages = {213},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2220-9964},
  doi = {10.3390/ijgi10040213},
  abstract = {Recent analysis of area-level COVID-19 cases data attempts to grapple with a challenge familiar to geovisualization: how to capture the development of the virus, whilst supporting analysis across geographic areas? We present several glyphmap designs for addressing this challenge applied to local authority data in England whereby charts displaying multiple aspects related to the pandemic are given a geographic arrangement. These graphics are visually complex, with clutter, occlusion and salience bias an inevitable consequence. We develop a framework for describing and validating the graphics against data and design requirements. Together with an observational data analysis, this framework is used to evaluate our designs, relating them to particular data analysis needs based on the usefulness of the structure they expose. Our designs, documented in an accompanying code repository, attend to common difficulties in geovisualization design and could transfer to contexts outside of the UK and to phenomena beyond the pandemic.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {cartography,COVID-19,geovisualization,glyphs,multivariate visualization},
  file = {/Users/charliejhadley/Zotero/storage/5EAW4NWP/Beecham et al. - 2021 - On the Use of ‘Glyphmaps’ for Analysing the Scale .pdf;/Users/charliejhadley/Zotero/storage/DHT9VMSR/213.html}
}

@article{beecham_use_2021-1,
  title = {On the {{Use}} of `{{Glyphmaps}}' for {{Analysing}} the {{Scale}} and {{Temporal Spread}} of {{COVID-19 Reported Cases}}},
  author = {Beecham, Roger and Dykes, Jason and Hama, Layik and Lomax, Nik},
  year = {2021},
  month = apr,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {10},
  number = {4},
  pages = {213},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2220-9964},
  doi = {10.3390/ijgi10040213},
  abstract = {Recent analysis of area-level COVID-19 cases data attempts to grapple with a challenge familiar to geovisualization: how to capture the development of the virus, whilst supporting analysis across geographic areas? We present several glyphmap designs for addressing this challenge applied to local authority data in England whereby charts displaying multiple aspects related to the pandemic are given a geographic arrangement. These graphics are visually complex, with clutter, occlusion and salience bias an inevitable consequence. We develop a framework for describing and validating the graphics against data and design requirements. Together with an observational data analysis, this framework is used to evaluate our designs, relating them to particular data analysis needs based on the usefulness of the structure they expose. Our designs, documented in an accompanying code repository, attend to common difficulties in geovisualization design and could transfer to contexts outside of the UK and to phenomena beyond the pandemic.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {cartography,COVID-19,geovisualization,glyphs,multivariate visualization},
  file = {/Users/charliejhadley/Zotero/storage/5NERFXBG/Beecham et al. - 2021 - On the Use of ‘Glyphmaps’ for Analysing the Scale .pdf;/Users/charliejhadley/Zotero/storage/V4S9YMXR/htm.html}
}

@article{bem_feeling_2011,
  title = {Feeling the Future: {{Experimental}} Evidence for Anomalous Retroactive Influences on Cognition and Affect},
  shorttitle = {Feeling the Future},
  author = {Bem, Daryl J.},
  year = {2011},
  journal = {Journal of Personality and Social Psychology},
  volume = {100},
  number = {3},
  pages = {407--425},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1315},
  doi = {10.1037/a0021524},
  abstract = {The term psi denotes anomalous processes of information or energy transfer that are currently unexplained in terms of known physical or biological mechanisms. Two variants of psi are precognition (conscious cognitive awareness) and premonition (affective apprehension) of a future event that could not otherwise be anticipated through any known inferential process. Precognition and premonition are themselves special cases of a more general phenomenon: the anomalous retroactive influence of some future event on an individual's current responses, whether those responses are conscious or nonconscious, cognitive or affective. This article reports 9 experiments, involving more than 1,000 participants, that test for retroactive influence by ``time-reversing'' well-established psychological effects so that the individual's responses are obtained before the putatively causal stimulus events occur. Data are presented for 4 time-reversed effects: precognitive approach to erotic stimuli and precognitive avoidance of negative stimuli; retroactive priming; retroactive habituation; and retroactive facilitation of recall. The mean effect size (d) in psi performance across all 9 experiments was 0.22, and all but one of the experiments yielded statistically significant results. The individual-difference variable of stimulus seeking, a component of extraversion, was significantly correlated with psi performance in 5 of the experiments, with participants who scored above the midpoint on a scale of stimulus seeking achieving a mean effect size of 0.43. Skepticism about psi, issues of replication, and theories of psi are also discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Causality,Cognition,Cognitions,Emotional States,Extrasensory Perception,Parapsychology,Precognition,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/9LKI5L26/doiLanding.html}
}

@misc{bennet_netflix_2007,
  title = {The {{Netflix Prize}}},
  author = {Bennet, James and Lanning, Stan},
  year = {2007},
  publisher = {{Netflix}},
  file = {/Users/charliejhadley/Zotero/storage/B6WFTLY7/Bennet and Lanning - 2007 - The Netflix Prize.pdf}
}

@article{blachar_world_nodate,
  title = {World {{Medical Association Officers}}, {{Chairpersons}} and {{Officials}}},
  author = {Blachar, Dr Yoram and Hanson, Dr Dana and Hill, Dr Edward},
  pages = {44},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/Y773K7UV/Blachar et al. - World Medical Association Oﬃcers, Chairpersons and.pdf}
}

@misc{bolukbasi_man_2016,
  title = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}? {{Debiasing Word Embeddings}}},
  shorttitle = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}?},
  author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
  year = {2016},
  month = jul,
  number = {arXiv:1607.06520},
  eprint = {1607.06520},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1607.06520},
  abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/charliejhadley/Zotero/storage/3PT23KQR/Bolukbasi et al. - 2016 - Man is to Computer Programmer as Woman is to Homem.pdf;/Users/charliejhadley/Zotero/storage/WK9WHLEW/1607.html}
}

@misc{bolukbasi_man_2016-1,
  title = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}? {{Debiasing Word Embeddings}}},
  shorttitle = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}?},
  author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
  year = {2016},
  month = jul,
  number = {arXiv:1607.06520},
  eprint = {1607.06520},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1607.06520},
  abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/charliejhadley/Zotero/storage/8PY6Q8SI/Bolukbasi et al. - 2016 - Man is to Computer Programmer as Woman is to Homem.pdf;/Users/charliejhadley/Zotero/storage/VFQZTDQ4/1607.html}
}

@article{bradley_automatic_2022,
  title = {Automatic Registration for {{UK}} Trials},
  author = {Bradley, Stephen H. and Lloyd, Kelly E. and DeVito, Nicholas J.},
  year = {2022},
  month = jan,
  journal = {BMJ},
  volume = {376},
  pages = {o41},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.o41},
  abstract = {{$<$}p{$>$}A welcome development, not a panacea{$<$}/p{$>$}},
  chapter = {Editorial},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  langid = {english},
  pmid = {35031535},
  keywords = {registration},
  file = {/Users/charliejhadley/Zotero/storage/6NH4278J/bmj.o41.html}
}

@article{bradley_automatic_2022-1,
  title = {Automatic Registration for {{UK}} Trials},
  author = {Bradley, Stephen H. and Lloyd, Kelly E. and DeVito, Nicholas J.},
  year = {2022},
  month = jan,
  journal = {BMJ},
  volume = {376},
  pages = {o41},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.o41},
  abstract = {{$<$}p{$>$}A welcome development, not a panacea{$<$}/p{$>$}},
  chapter = {Editorial},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  langid = {english},
  pmid = {35031535},
  keywords = {pre-registration},
  file = {/Users/charliejhadley/Zotero/storage/EBMNNPAH/bmj.o41.html}
}

@misc{british_election_study_british_2019,
  title = {British {{Election Study}} 2019 {{Post-Election Random Probability Survey}}},
  author = {{British Election Study}},
  year = {2019},
  month = dec,
  howpublished = {https://www.britishelectionstudy.com/data-object/2019-british-election-study-post-election-random-probability-survey/}
}

@techreport{broman_recommendations_2017,
  title = {Recommendations to {{Funding Agencies}} for {{Supporting Reproducible Research}}},
  author = {Broman, Karl and {\c C}etinkaya-Rundel, Mine and Nussbaum, Amy and Paciorek, Christopher and Peng, Roger and Turek, Daniel and Wickham, Hadley},
  year = {2017},
  month = jan,
  pages = {1--4},
  institution = {{American Statistial Association}},
  abstract = {The ASA asked these many of its members what advice they would provide to funding agencies to encourage reproducible research. The ASA shares their comments to inform discussions within funding agencies and more broadly. Our motivation is to help produce better scientific research and to highlight the role of statistics and statisticians. We do not intend these steps to be official recommendations that must be implemented but hope they are received as constructive contributions to the ongoing discussions.},
  keywords = {reproducibility advice}
}

@misc{bruckner_uk_2021,
  title = {{{UK}} Launches New System to Achieve 100\% Clinical Trial Registration (Updated)},
  author = {Bruckner, Till},
  year = {2021},
  month = oct,
  journal = {transparimed},
  abstract = {Clinical trials run in the UK will be automatically registered from 2022, the country's Health Research Authority announced today. The new system seeks to ensure that every single clinical trial with be listed on a trial registry from the outset. UK researchers have been formally required to register trials since 2013, but that rule was never enforced, and many trials remained unregistered. WHY IS THIS GROUNDBREAKING? Trial registration is a key pillar of clinical trial transparency. It helps sc},
  howpublished = {https://www.transparimed.org/single-post/uk-clinical-trial-registration},
  langid = {english},
  keywords = {pre-registration clinical trials},
  file = {/Users/charliejhadley/Zotero/storage/FGBFA6U4/uk-clinical-trial-registration.html}
}

@inproceedings{burn-murdoch_ggplot2_2016,
  title = {Ggplot2 as a {{Creativity Engine}}},
  booktitle = {{{EARL}} 2016},
  author = {{Burn-Murdoch}, John},
  year = {2016},
  month = sep,
  address = {{London}},
  file = {/Users/charliejhadley/Zotero/storage/K9WBJ8VS/r-ggplot.html}
}

@misc{buzzclassactioncom_google_2010,
  title = {Google {{Buzz User Privacy Litigation Class Action Settlement Website}}},
  author = {{BuzzClassAction.com}},
  year = {2010},
  month = nov,
  howpublished = {https://web.archive.org/web/20101105105714/http://www.buzzclassaction.com/faq},
  file = {/Users/charliejhadley/Zotero/storage/SUZ88YBH/faq.html}
}

@misc{cairo_download_2016,
  title = {Download the {{Datasaurus}}: {{Never}} Trust Summary Statistics Alone; Always Visualize Your Data},
  shorttitle = {Download the {{Datasaurus}}},
  author = {Cairo, Alberto},
  year = {2016},
  month = aug,
  abstract = {This tweet  is quickly becoming the most popular I've ever written. I drew that dinosaur with this fantastic tool ~created by Robert Grant ,...},
  file = {/Users/charliejhadley/Zotero/storage/5I29NFLE/download-datasaurus-never-trust-summary.html}
}

@article{camerer_evaluating_2018,
  title = {Evaluating the Replicability of Social Science Experiments in {{Nature}} and {{Science}} between 2010 and 2015},
  author = {Camerer, Colin F. and Dreber, Anna and Holzmeister, Felix and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Nave, Gideon and Nosek, Brian A. and Pfeiffer, Thomas and Altmejd, Adam and Buttrick, Nick and Chan, Taizan and Chen, Yiling and Forsell, Eskil and Gampa, Anup and Heikensten, Emma and Hummer, Lily and Imai, Taisuke and Isaksson, Siri and Manfredi, Dylan and Rose, Julia and Wagenmakers, Eric-Jan and Wu, Hang},
  year = {2018},
  month = sep,
  journal = {Nature Human Behaviour},
  volume = {2},
  number = {9},
  pages = {637--644},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-018-0399-z},
  abstract = {Being able to replicate scientific findings is crucial for scientific progress1\textendash 15. We replicate 21 systematically selected experimental studies in the social sciences published in Nature and Science between 2010 and 201516\textendash 36. The replications follow analysis plans reviewed by the original authors and pre-registered prior to the replications. The replications are high powered, with sample sizes on average about five times higher than in the original studies. We find a significant effect in the same direction as the original study for 13 (62\%) studies, and the effect size of the replications is on average about 50\% of the original effect size. Replicability varies between 12 (57\%) and 14 (67\%) studies for complementary replicability indicators. Consistent with these results, the estimated true-positive rate is 67\% in a Bayesian analysis. The relative effect size of true positives is estimated to be 71\%, suggesting that both false positives and inflated effect sizes of true positives contribute to imperfect reproducibility. Furthermore, we find that peer beliefs of replicability are strongly related to replicability, suggesting that the research community could predict which results would replicate and that failures to replicate were not the result of chance alone. Camerer et al. carried out replications of 21 Science and Nature social science experiments, successfully replicating 13 out of 21 (62\%). Effect sizes of replications were about half of the size of the originals.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Economics,Psychology,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/WATZQU7E/Camerer et al. - 2018 - Evaluating the replicability of social science exp.pdf;/Users/charliejhadley/Zotero/storage/GKE3DSSN/s41562-018-0399-z.html}
}

@misc{caplan_algorithmic_2018,
  title = {Algorithmic {{Accountability}}: {{A}} Primer},
  author = {Caplan, Robyn and Donovan, Joan and Hanson, Lauren and Matthews, Jeanna},
  year = {2018},
  month = apr,
  publisher = {{Data Society}}
}

@article{cleveland_graphical_1984,
  title = {Graphical {{Perception}}: {{Theory}}, {{Experimentation}}, and {{Application}} to the {{Development}} of {{Graphical Methods}}},
  shorttitle = {Graphical {{Perception}}},
  author = {Cleveland, William S. and McGill, Robert},
  year = {1984},
  month = sep,
  journal = {Journal of the American Statistical Association},
  volume = {79},
  number = {387},
  pages = {531--554},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1984.10478080},
  abstract = {The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception\textemdash the visual decoding of information encoded on graphs\textemdash and it includes both theory and experimentation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be expanded. The theory provides a guideline for graph construction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The conclusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms\textemdash dot charts, dot charts with grouping, and framed-rectangle charts.},
  keywords = {Computer graphics,Psychophysics},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1984.10478080},
  file = {/Users/charliejhadley/Zotero/storage/MFJN8XRA/Cleveland and McGill - 1984 - Graphical Perception Theory, Experimentation, and.pdf}
}

@article{clifton_eye_2016,
  title = {Eye Movements in Reading and Information Processing: {{Keith Rayner}}'s 40year Legacy},
  shorttitle = {Eye Movements in Reading and Information Processing},
  author = {Clifton, Charles and Ferreira, Fernanda and Henderson, John M. and Inhoff, Albrecht W. and Liversedge, Simon P. and Reichle, Erik D. and Schotter, Elizabeth R.},
  year = {2016},
  month = jan,
  journal = {Journal of Memory and Language},
  volume = {86},
  pages = {1--19},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2015.07.004},
  abstract = {Keith Rayner's extraordinary scientific career revolutionized the field of reading research and had a major impact on almost all areas of cognitive psychology. In this article, we review some of his most significant contributions. We begin with Rayner's research on eye movement control, including the development of paradigms for answering questions about the perceptual span and its relationship to attention, reading experience, and linguistic variables. From there we proceed to lexical processing, where we summarize Rayner's work on effects of word frequency, length, predictability, and the resolution of lexical ambiguity. Next, we turn to syntactic and discourse processing, covering the well-known garden-path model of parsing and briefly reviewing studies of pronoun resolution and inferencing. The next section shifts from language to visual cognition and reviews research which makes use of eye movement techniques to investigate object and scene processing. Next, we summarize Rayner and colleagues' approach to computational modeling, with a description of the E-Z Reader model linking attention and lexical processing to eye movement control. The final section discusses the issues Rayner and his colleagues were focused on most recently and considers how Rayner's legacy will continue into the future.},
  langid = {english},
  keywords = {E-Z Reader,Eye movement control,Keith Rayner,Sentences and discourses,speed reading,Visual scenes,Word recognition},
  file = {/Users/charliejhadley/Zotero/storage/AK5ZSLWF/Clifton et al. - 2016 - Eye movements in reading and information processin.pdf;/Users/charliejhadley/Zotero/storage/LCU5SVUT/S0749596X15000960.html}
}

@article{colavizza_citation_2020,
  title = {The Citation Advantage of Linking Publications to Research Data},
  author = {Colavizza, Giovanni and Hrynaszkiewicz, Iain and Staden, Isla and Whitaker, Kirstie and McGillivray, Barbara},
  year = {2020},
  month = apr,
  journal = {PLOS ONE},
  volume = {15},
  number = {4},
  pages = {e0230416},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0230416},
  abstract = {Efforts to make research results open and reproducible are increasingly reflected by journal policies encouraging or mandating authors to provide data availability statements. As a consequence of this, there has been a strong uptake of data availability statements in recent literature. Nevertheless, it is still unclear what proportion of these statements actually contain well-formed links to data, for example via a URL or permanent identifier, and if there is an added value in providing such links. We consider 531, 889 journal articles published by PLOS and BMC, develop an automatic system for labelling their data availability statements according to four categories based on their content and the type of data availability they display, and finally analyze the citation advantage of different statement categories via regression. We find that, following mandated publisher policies, data availability statements become very common. In 2018 93.7\% of 21,793 PLOS articles and 88.2\% of 31,956 BMC articles had data availability statements. Data availability statements containing a link to data in a repository\textemdash rather than being available on request or included as supporting information files\textemdash are a fraction of the total. In 2017 and 2018, 20.8\% of PLOS publications and 12.2\% of BMC publications provided DAS containing a link to data in a repository. We also find an association between articles that include statements that link to data in a repository and up to 25.36\% ({$\pm$} 1.07\%) higher citation impact on average, using a citation prediction model. We discuss the potential implications of these results for authors (researchers) and journal publishers who make the effort of sharing their data in repositories. All our data and code are made available in order to reproduce and extend our results.},
  langid = {english},
  keywords = {Bibliometrics,Citation analysis,Data management,Open access publishing,Reproducibility,Science policy,Scientific publishing,Support vector machines},
  file = {/Users/charliejhadley/Zotero/storage/VTKH27DB/Colavizza et al. - 2020 - The citation advantage of linking publications to .pdf;/Users/charliejhadley/Zotero/storage/CTHIFZPA/article.html}
}

@article{cook_assessing_2011,
  title = {Assessing {{Google Flu Trends Performance}} in the {{United States}} during the 2009 {{Influenza Virus A}} ({{H1N1}}) {{Pandemic}}},
  author = {Cook, Samantha and Conrad, Corrie and Fowlkes, Ashley L. and Mohebbi, Matthew H.},
  year = {2011},
  month = aug,
  journal = {PLOS ONE},
  volume = {6},
  number = {8},
  pages = {e23610},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0023610},
  abstract = {Background Google Flu Trends (GFT) uses anonymized, aggregated internet search activity to provide near-real time estimates of influenza activity. GFT estimates have shown a strong correlation with official influenza surveillance data. The 2009 influenza virus A (H1N1) pandemic [pH1N1] provided the first opportunity to evaluate GFT during a non-seasonal influenza outbreak. In September 2009, an updated United States GFT model was developed using data from the beginning of pH1N1. Methodology/Principal Findings We evaluated the accuracy of each U.S. GFT model by comparing weekly estimates of ILI (influenza-like illness) activity with the U.S. Outpatient Influenza-like Illness Surveillance Network (ILINet). For each GFT model we calculated the correlation and RMSE (root mean square error) between model estimates and ILINet for four time periods: pre-H1N1, Summer H1N1, Winter H1N1, and H1N1 overall (Mar 2009\textendash Dec 2009). We also compared the number of queries, query volume, and types of queries (e.g., influenza symptoms, influenza complications) in each model. Both models' estimates were highly correlated with ILINet pre-H1N1 and over the entire surveillance period, although the original model underestimated the magnitude of ILI activity during pH1N1. The updated model was more correlated with ILINet than the original model during Summer H1N1 (r = 0.95 and 0.29, respectively). The updated model included more search query terms than the original model, with more queries directly related to influenza infection, whereas the original model contained more queries related to influenza complications. Conclusions Internet search behavior changed during pH1N1, particularly in the categories ``influenza complications'' and ``term for influenza.'' The complications associated with pH1N1, the fact that pH1N1 began in the summer rather than winter, and changes in health-seeking behavior each may have played a part. Both GFT models performed well prior to and during pH1N1, although the updated model performed better during pH1N1, especially during the summer months.},
  langid = {english},
  keywords = {H1N1,Infectious disease surveillance,Influenza,Influenza A virus,Influenza viruses,Outpatients,Pandemics,Swine influenza},
  file = {/Users/charliejhadley/Zotero/storage/CQGWZYU4/Cook et al. - 2011 - Assessing Google Flu Trends Performance in the Uni.pdf;/Users/charliejhadley/Zotero/storage/NYRZW8BC/article.html}
}

@book{dillman_internet_2014,
  title = {Internet, Phone, Mail, and Mixed-Mode Surveys: The Tailored Design Method},
  shorttitle = {Internet, Phone, Mail, and Mixed-Mode Surveys},
  author = {Dillman, Don A. and Smyth, Jolene D. and Christian, Leah Melani},
  year = {2014},
  edition = {4th edition},
  publisher = {{Wiley}},
  address = {{Hoboken}},
  abstract = {"The classic survey design reference, updated for the digital ageFor over two decades, Dillman's classic text on survey design has aided both students and professionals in effectively planning and conducting mail, telephone, and, more recently, Internet surveys. The new edition is thoroughly updated and revised, and covers all aspects of survey research. It features expanded coverage of mobile phones, tablets, and the use of do-it-yourself surveys, and Dillman's unique Tailored Design Method is also thoroughly explained. This invaluable resource is crucial for any researcher seeking to increase response rates and obtain high-quality feedback from survey questions. Consistent with current emphasis on the visual and aural, the new edition is complemented by copious examples within the text and accompanying website.This heavily revised Fourth Edition includes: Strategies and tactics for determining the needs of a given survey, how to design it, and how to effectively administer it How and when to use mail, telephone, and Internet surveys to maximum advantage Proven techniques to increase response rates Guidance on how to obtain high-quality feedback from mail, electronic, and other self-administered surveys Direction on how to construct effective questionnaires, including considerations of layout The effects of sponsorship on the response rates of surveys Use of capabilities provided by newly mass-used media: interactivity, presentation of aural and visual stimuli. The Fourth Edition reintroduces the telephone--including coordinating land and mobile. Grounded in the best research, the book offers practical how-to guidelines and detailed examples for practitioners and students alike"--},
  isbn = {978-1-118-92130-2 978-1-118-92129-6},
  lccn = {HM538},
  keywords = {Data Collection,Questionnaires,SOCIAL SCIENCE / Research,Social surveys}
}

@article{dolan_happy_2016,
  title = {Happy {{Talk}}: {{Mode}} of {{Administration Effects}} on {{Subjective Well-Being}}},
  shorttitle = {Happy {{Talk}}},
  author = {Dolan, Paul and Kavetsos, Georgios},
  year = {2016},
  month = jun,
  journal = {Journal of Happiness Studies},
  volume = {17},
  number = {3},
  pages = {1273--1291},
  issn = {1573-7780},
  doi = {10.1007/s10902-015-9642-8},
  abstract = {There is increasing interest in subjective well-being (SWB) both in academic and policy circles. As a result, considerable research efforts are now being directed at the validity and reliability of SWB measures. This study examines how SWB reports differ by survey mode. Using data from the April 2011 to March 2012 Annual Population Survey in the UK we find that individuals consistently report higher SWB over the phone compared to face-to-face interviews. We also show that the determinants of SWB differ significantly by mode, with life circumstances tending to matter more in face-to-face interviews. These results have substantial implications for research and policy purposes.},
  langid = {english},
  keywords = {D60,Happiness,I30,Subjective well-being,Survey mode,Valuation},
  file = {/Users/charliejhadley/Zotero/storage/I9SBSITU/Dolan and Kavetsos - 2016 - Happy Talk Mode of Administration Effects on Subj.pdf}
}

@misc{douglas_heaven_hundreds_2021,
  title = {Hundreds of {{AI}} Tools Have Been Built to Catch Covid. {{None}} of Them Helped.},
  author = {Douglas Heaven, Will},
  year = {2021},
  month = jul,
  journal = {MIT Technology Review},
  abstract = {Some have been used in hospitals, despite not being properly tested. But the pandemic could help make medical AI better.},
  howpublished = {https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/},
  langid = {english},
  keywords = {covid ai replicability,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/JERXTBNK/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic.html}
}

@article{dreber_using_2015,
  title = {Using Prediction Markets to Estimate the Reproducibility of Scientific Research},
  author = {Dreber, Anna and Pfeiffer, Thomas and Almenberg, Johan and Isaksson, Siri and Wilson, Brad and Chen, Yiling and Nosek, Brian A. and Johannesson, Magnus},
  year = {2015},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {112},
  number = {50},
  pages = {15343--15347},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1516179112},
  keywords = {replication prediction markets,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/5BY9TKAV/Dreber et al. - 2015 - Using prediction markets to estimate the reproduci.pdf}
}

@article{dressel_accuracy_2018,
  title = {The Accuracy, Fairness, and Limits of Predicting Recidivism},
  author = {Dressel, Julia and Farid, Hany},
  year = {2018},
  month = jan,
  journal = {Science Advances},
  volume = {4},
  number = {1},
  pages = {eaao5580},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.aao5580},
  file = {/Users/charliejhadley/Zotero/storage/IZ6JC6K7/Dressel and Farid - 2018 - The accuracy, fairness, and limits of predicting r.pdf}
}

@misc{dwork_fairness_2011,
  title = {Fairness {{Through Awareness}}},
  author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Rich},
  year = {2011},
  month = nov,
  number = {arXiv:1104.3913},
  eprint = {1104.3913},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Computer Science - Computers and Society},
  file = {/Users/charliejhadley/Zotero/storage/7AUCILKA/Dwork et al. - 2011 - Fairness Through Awareness.pdf;/Users/charliejhadley/Zotero/storage/D4VBVC9W/1104.html}
}

@article{dyer_glaxosmithkline_2004,
  title = {{{GlaxoSmithKline}} Faces {{US}} Lawsuit over Concealment of Trial Results},
  author = {Dyer, Owen},
  year = {2004},
  month = jun,
  journal = {BMJ : British Medical Journal},
  volume = {328},
  number = {7453},
  pages = {1395},
  issn = {0959-8138},
  pmcid = {PMC421770},
  pmid = {15191963},
  keywords = {pre-registration clinical trials}
}

@article{eatock_exploratory_2009,
  title = {An Exploratory Survey of Current Practice in the Medical Device Industry},
  author = {Eatock, Julie and Dixon, Dorian and Young, Terry},
  year = {2009},
  month = feb,
  journal = {Journal of Manufacturing Technology Management},
  volume = {20},
  number = {2},
  pages = {218--234},
  issn = {1741-038X},
  doi = {10.1108/17410380910929637},
  abstract = {Purpose               This study seeks to examine the extent to which mainstream tools and strategies are applied in the medical devices sector, which is highly fragmented and contains a high percentage of small companies, and to determine if company size impacts on manufacturing strategy selection.                                         Design/methodology/approach               A questionnaire was developed and disseminated through a number of channels. Responses were received from 38 companies in the UK and Ireland, describing 68 products taken to market in the past five years.                                         Findings               Because of the limited scope of the survey, the findings are indicative rather than conclusive, and interesting trends have emerged. New to the world products were much more likely to exceed company expectations of market success compared to derivative products. It was found that the majority of these innovative products were developed by small companies. Large companies appear to favour minor upgrades over major upgrades even though these prove \textendash{} on the data presented \textendash{} to be less successful overall.                                         Practical implications               These results provide those engaged in this sector with comparative information and some insights for further improvement. The reported trends with respect to company size and product complexity (or degree of novelty) are particularly illuminating. Academically, this sets some expected trends on a firmer footing and unearths one or two unexpected findings.                                         Originality/value               It is believed that this is the largest survey of determinants of success in UK medical device companies and it provides a comparison with other sectors.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/47LZNMGR/Eatock et al. - 2009 - An exploratory survey of current practice in the m.pdf}
}

@article{eberhard_effects_2021,
  title = {The Effects of Visualization on Judgment and Decision-Making: A Systematic Literature Review},
  shorttitle = {The Effects of Visualization on Judgment and Decision-Making},
  author = {Eberhard, Karin},
  year = {2021},
  month = aug,
  journal = {Management Review Quarterly},
  issn = {2198-1639},
  doi = {10.1007/s11301-021-00235-8},
  abstract = {The visualization of information is a widely used tool to improve comprehension and, ultimately, decision-making in strategic management decisions as well as in a diverse array of other domains. Across social science research, many findings have supported this rationale. However, empirical results vary significantly in terms of the variables and mechanisms studied as well as their resulting conclusion. Despite the ubiquity of information visualization with modern software, there is little effort to create a comprehensive understanding of the powers and limitations of its use. The purpose of this article is therefore to review, systematize, and integrate extant research on the effects of information visualization on decision-making and to provide a future research agenda with a particular focus on the context of strategic management decisions. The study shows that information visualization can improve decision quality as well as speed, with more mixed effects on other variables, for instance, decision confidence. Several moderators such as user and task characteristics have been investigated as part of this interaction, along with cognitive aspects as mediating processes. The article presents integrative insights based on research spanning multiple domains across the social and information sciences and provides impulses for prospective applications in the realm of managerial decision-making.},
  langid = {english},
  keywords = {Cognitive load,D91,Decision quality,Information visualization,M00,Strategic decision-making,Task characteristics,User characteristics},
  file = {/Users/charliejhadley/Zotero/storage/9ZGRSTQ7/Eberhard - 2021 - The effects of visualization on judgment and decis.pdf}
}

@article{eberhard_effects_2021-1,
  title = {The Effects of Visualization on Judgment and Decision-Making: A Systematic Literature Review},
  shorttitle = {The Effects of Visualization on Judgment and Decision-Making},
  author = {Eberhard, Karin},
  year = {2021},
  month = aug,
  journal = {Management Review Quarterly},
  issn = {2198-1639},
  doi = {10.1007/s11301-021-00235-8},
  abstract = {The visualization of information is a widely used tool to improve comprehension and, ultimately, decision-making in strategic management decisions as well as in a diverse array of other domains. Across social science research, many findings have supported this rationale. However, empirical results vary significantly in terms of the variables and mechanisms studied as well as their resulting conclusion. Despite the ubiquity of information visualization with modern software, there is little effort to create a comprehensive understanding of the powers and limitations of its use. The purpose of this article is therefore to review, systematize, and integrate extant research on the effects of information visualization on decision-making and to provide a future research agenda with a particular focus on the context of strategic management decisions. The study shows that information visualization can improve decision quality as well as speed, with more mixed effects on other variables, for instance, decision confidence. Several moderators such as user and task characteristics have been investigated as part of this interaction, along with cognitive aspects as mediating processes. The article presents integrative insights based on research spanning multiple domains across the social and information sciences and provides impulses for prospective applications in the realm of managerial decision-making.},
  langid = {english},
  keywords = {Cognitive load,D91,Decision quality,Information visualization,M00,Strategic decision-making,Task characteristics,User characteristics},
  file = {/Users/charliejhadley/Zotero/storage/AVLLSE8A/Eberhard - 2021 - The effects of visualization on judgment and decis.pdf}
}

@article{eberhard_effects_2021-2,
  title = {The Effects of Visualization on Judgment and Decision-Making: A Systematic Literature Review},
  shorttitle = {The Effects of Visualization on Judgment and Decision-Making},
  author = {Eberhard, Karin},
  year = {2021},
  month = aug,
  journal = {Management Review Quarterly},
  issn = {2198-1639},
  doi = {10.1007/s11301-021-00235-8},
  abstract = {The visualization of information is a widely used tool to improve comprehension and, ultimately, decision-making in strategic management decisions as well as in a diverse array of other domains. Across social science research, many findings have supported this rationale. However, empirical results vary significantly in terms of the variables and mechanisms studied as well as their resulting conclusion. Despite the ubiquity of information visualization with modern software, there is little effort to create a comprehensive understanding of the powers and limitations of its use. The purpose of this article is therefore to review, systematize, and integrate extant research on the effects of information visualization on decision-making and to provide a future research agenda with a particular focus on the context of strategic management decisions. The study shows that information visualization can improve decision quality as well as speed, with more mixed effects on other variables, for instance, decision confidence. Several moderators such as user and task characteristics have been investigated as part of this interaction, along with cognitive aspects as mediating processes. The article presents integrative insights based on research spanning multiple domains across the social and information sciences and provides impulses for prospective applications in the realm of managerial decision-making.},
  langid = {english},
  keywords = {Cognitive load,D91,Decision quality,Information visualization,M00,Strategic decision-making,Task characteristics,User characteristics},
  file = {/Users/charliejhadley/Zotero/storage/YKJTDT67/Eberhard - 2021 - The effects of visualization on judgment and decis.pdf}
}

@article{el_emam_protecting_2008,
  title = {Protecting {{Privacy Using}} K-{{Anonymity}}},
  author = {El Emam, Khaled and Dankar, Fida Kamal},
  year = {2008},
  journal = {Journal of the American Medical Informatics Association : JAMIA},
  volume = {15},
  number = {5},
  pages = {627--637},
  issn = {1067-5027},
  doi = {10.1197/jamia.M2716},
  abstract = {Objective There is increasing pressure to share health information and even make it publicly available. However, such disclosures of personal health information raise serious privacy concerns. To alleviate such concerns, it is possible to anonymize the data before disclosure. One popular anonymization approach is k-anonymity. There have been no evaluations of the actual re-identification probability of k-anonymized data sets. Design Through a simulation, we evaluated the re-identification risk of k-anonymization and three different improvements on three large data sets. Measurement Re-identification probability is measured under two different re-identification scenarios. Information loss is measured by the commonly used discernability metric. Results For one of the re-identification scenarios, k-Anonymity consistently over-anonymizes data sets, with this over-anonymization being most pronounced with small sampling fractions. Over-anonymization results in excessive distortions to the data (i.e., high information loss), making the data less useful for subsequent analysis. We found that a hypothesis testing approach provided the best control over re-identification risk and reduces the extent of information loss compared to baseline k-anonymity. Conclusion Guidelines are provided on when to use the hypothesis testing approach instead of baseline k-anonymity.},
  pmcid = {PMC2528029},
  pmid = {18579830},
  file = {/Users/charliejhadley/Zotero/storage/QS3ITX4M/El Emam and Dankar - 2008 - Protecting Privacy Using k-Anonymity.pdf}
}

@inproceedings{englehardt_online_2016,
  title = {Online {{Tracking}}: {{A}} 1-Million-Site {{Measurement}} and {{Analysis}}},
  shorttitle = {Online {{Tracking}}},
  booktitle = {Proceedings of the 2016 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Englehardt, Steven and Narayanan, Arvind},
  year = {2016},
  month = oct,
  series = {{{CCS}} '16},
  pages = {1388--1401},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2976749.2978313},
  abstract = {We present the largest and most detailed measurement of online tracking conducted to date, based on a crawl of the top 1 million websites. We make 15 types of measurements on each site, including stateful (cookie-based) and stateless (fingerprinting-based) tracking, the effect of browser privacy tools, and the exchange of tracking data between different sites ("cookie syncing"). Our findings include multiple sophisticated fingerprinting techniques never before measured in the wild. This measurement is made possible by our open-source web privacy measurement tool, OpenWPM, which uses an automated version of a full-fledged consumer browser. It supports parallelism for speed and scale, automatic recovery from failures of the underlying browser, and comprehensive browser instrumentation. We demonstrate our platform's strength in enabling researchers to rapidly detect, quantify, and characterize emerging online tracking behaviors.},
  isbn = {978-1-4503-4139-4},
  keywords = {browser fingerprinting,browser privacy,browser security,device fingerprinting,measurement,online advertising,web measurement,web privacy,web tracking},
  file = {/Users/charliejhadley/Zotero/storage/IJR8QHY8/Englehardt and Narayanan - 2016 - Online Tracking A 1-million-site Measurement and .pdf}
}

@misc{ensign_runaway_2017,
  title = {Runaway {{Feedback Loops}} in {{Predictive Policing}}},
  author = {Ensign, Danielle and Friedler, Sorelle A. and Neville, Scott and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2017},
  month = dec,
  number = {arXiv:1706.09847},
  eprint = {1706.09847},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.09847},
  abstract = {Predictive policing systems are increasingly used to determine how to allocate police across a city in order to best prevent crime. Discovered crime data (e.g., arrest counts) are used to help update the model, and the process is repeated. Such systems have been empirically shown to be susceptible to runaway feedback loops, where police are repeatedly sent back to the same neighborhoods regardless of the true crime rate. In response, we develop a mathematical model of predictive policing that proves why this feedback loop occurs, show empirically that this model exhibits such problems, and demonstrate how to change the inputs to a predictive policing system (in a black-box manner) so the runaway feedback loop does not occur, allowing the true crime rate to be learned. Our results are quantitative: we can establish a link (in our model) between the degree to which runaway feedback causes problems and the disparity in crime rates between areas. Moreover, we can also demonstrate the way in which \textbackslash emph\{reported\} incidents of crime (those reported by residents) and \textbackslash emph\{discovered\} incidents of crime (i.e. those directly observed by police officers dispatched as a result of the predictive policing algorithm) interact: in brief, while reported incidents can attenuate the degree of runaway feedback, they cannot entirely remove it without the interventions we suggest.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Statistics - Machine Learning},
  file = {/Users/charliejhadley/Zotero/storage/YVYCTA3C/Ensign et al. - 2017 - Runaway Feedback Loops in Predictive Policing.pdf;/Users/charliejhadley/Zotero/storage/QK2SK7CK/1706.html}
}

@misc{epsrc_esprc_2022,
  title = {{{ESPRC Policy Framework}} on {{Research Data}}},
  author = {{EPSRC}},
  year = {2022},
  month = aug,
  howpublished = {https://www.ukri.org/about-us/epsrc/our-policies-and-standards/policy-framework-on-research-data/\#contents-list}
}

@misc{esrc_esrc_2022,
  title = {{{ESRC Research Data Policy}}},
  author = {{ESRC}},
  year = {2022},
  month = aug,
  howpublished = {https://www.ukri.org/wp-content/uploads/2021/07/ESRC-200721-ResearchDataPolicy.pdf}
}

@book{european_parliament_directorate_general_for_parliamentary_research_services_governance_2019,
  title = {A Governance Framework for Algorithmic Accountability and Transparency.},
  author = {{European Parliament. Directorate General for Parliamentary Research Services.}},
  year = {2019},
  publisher = {{Publications Office}},
  address = {{LU}},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/YCQKTWVP/European Parliament. Directorate General for Parliamentary Research Services. - 2019 - A governance framework for algorithmic accountabil.pdf}
}

@misc{european_union_regulation_2016,
  title = {{{REGULATION}} ({{EU}}) 2016/679 {{OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL}}},
  shorttitle = {General {{Data Protection Regulation}} ({{GDPR}})},
  author = {{European Union}},
  year = {2016},
  month = may,
  publisher = {{Official Journal of the European Union}},
  file = {/Users/charliejhadley/Zotero/storage/9SMIKHD5/2016 - REGULATION (EU) 2016679 OF THE EUROPEAN PARLIAMEN.pdf}
}

@article{fanelli_how_2009,
  title = {How {{Many Scientists Fabricate}} and {{Falsify Research}}? {{A Systematic Review}} and {{Meta-Analysis}} of {{Survey Data}}},
  shorttitle = {How {{Many Scientists Fabricate}} and {{Falsify Research}}?},
  author = {Fanelli, Daniele},
  year = {2009},
  month = may,
  journal = {PLOS ONE},
  volume = {4},
  number = {5},
  pages = {e5738},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0005738},
  abstract = {The frequency with which scientists fabricate and falsify data, or commit other forms of scientific misconduct is a matter of controversy. Many surveys have asked scientists directly whether they have committed or know of a colleague who committed research misconduct, but their results appeared difficult to compare and synthesize. This is the first meta-analysis of these surveys. To standardize outcomes, the number of respondents who recalled at least one incident of misconduct was calculated for each question, and the analysis was limited to behaviours that distort scientific knowledge: fabrication, falsification, ``cooking'' of data, etc\ldots{} Survey questions on plagiarism and other forms of professional misconduct were excluded. The final sample consisted of 21 surveys that were included in the systematic review, and 18 in the meta-analysis. A pooled weighted average of 1.97\% (N = 7, 95\%CI: 0.86\textendash 4.45) of scientists admitted to have fabricated, falsified or modified data or results at least once \textendash a serious form of misconduct by any standard\textendash{} and up to 33.7\% admitted other questionable research practices. In surveys asking about the behaviour of colleagues, admission rates were 14.12\% (N = 12, 95\% CI: 9.91\textendash 19.72) for falsification, and up to 72\% for other questionable research practices. Meta-regression showed that self reports surveys, surveys using the words ``falsification'' or ``fabrication'', and mailed surveys yielded lower percentages of misconduct. When these factors were controlled for, misconduct was reported more frequently by medical/pharmacological researchers than others. Considering that these surveys ask sensitive questions and have other limitations, it appears likely that this is a conservative estimate of the true prevalence of scientific misconduct.},
  langid = {english},
  keywords = {Deception,Medical journals,Medicine and health sciences,Metaanalysis,questionable research practices,replicability crisis,Scientific misconduct,Scientists,Social research,Surveys},
  file = {/Users/charliejhadley/Zotero/storage/Q7YGYCQN/Fanelli - 2009 - How Many Scientists Fabricate and Falsify Research.pdf;/Users/charliejhadley/Zotero/storage/VYG6IWZH/article.html}
}

@misc{fieldhouse_british_2019,
  title = {British {{Election Study}}, 2019: {{Post-Election Random Probability Survey}}},
  shorttitle = {British {{Election Study}}, 2019: {{Post-Election Random Probability Survey}}},
  author = {Fieldhouse, E. and Green, J. and Evans, G. and Prosser, C. and De Geus, R. and Bailey, J. and Schmitt, H. and Van Der Eijk, C. and Mellon, J.},
  year = {2019},
  publisher = {{UK Data Service}},
  doi = {10.5255/UKDA-SN-8875-1},
  abstract = {David Butler and Donald Stokes founded the British Election Study (BES) in 1964. They did so with the aim of understanding political change in Britain. Their project transformed the study of electoral behaviour. Indeed, it was so successful that a version of the BES has run after every general election ever since. Almost six decades later, the BES is now one of the world's longest-running social surveys. After every general election, the BES surveys a representative sample of the British electorate. It asks them what they believe, what they think about parties and politicians, and how they voted. The BES team then makes these world-class data available for free, as part of its commitment to public engagement and impact. The British electorate has become more volatile in recent decades. This volatile environment has allowed recent political shocks and events to bring about a period of rapid and dramatic political change. In 2015 we witnessed fragmentation of party support with the collapse of the Liberal Democrats and the rise of smaller and newer parties such as UKIP, the Greens, and the SNP. In 2017, following the Brexit vote, this was reversed, with a surge...}
}

@misc{fieldhouse_british_2022,
  title = {British {{Election Study}}, 2019: {{Post-Election Random Probability Survey}}},
  shorttitle = {{{BESBritish Election Studies}}, 1969-{{British Election Study}}, 2019},
  author = {Fieldhouse, E. and Green, J. and Evans, G. and Prosser, C. and De Geus, R. and Bailey, J. and Schmitt, H. and Van Der Eijk, C. and Mellon, J.},
  year = {2022},
  publisher = {{UK Data Service}},
  doi = {10.5255/UKDA-SN-8875-1},
  abstract = {\&amp;nbsp; \&lt;p\&gt;David Butler and Donald Stokes founded the British Election Study (BES) in 1964. They did so with the aim of understanding political change in Britain. Their project transformed the study of electoral behaviour. Indeed, it was so successful that a version of the BES has run after every general election ever since.\&lt;/p\&gt; \&lt;p\&gt;Almost six decades later, the BES is now one of the world's longest-running social surveys. After every general election, the BES surveys a representative sample of the British electorate. It asks them what they believe, what they think about parties and politicians, and how they voted. The BES team then makes these world-class data available for free, as part of its commitment to public engagement and impact.\&lt;/p\&gt; \&lt;p\&gt;\&lt;span\&gt;The British electorate has become more volatile in recent decades. This volatile environment has allowed recent political shocks and events to bring about a period of rapid and dramatic political change. In 2015 we witnessed fragmentation of party support with the collapse of the Liberal Democrats and the rise of smaller and newer parties such as UKIP, the Greens, and the SNP. In 2017, following the Brexit vote, this was reversed, with a surge in support for the Conservatives and Labour, with many voters choosing on the basis of their attitudes towards Europe and immigration. Whatever form Brexit eventually takes, it will have huge electoral consequences and the next five years are likely to see further shifts in the electoral landscape.\&amp;nbsp;\&lt;/span\&gt;\&lt;span\&gt;The 2019 British Election Study Post-Election Random Probability Survey is designed to\&lt;/span\&gt;\&lt;span\&gt;\&amp;nbsp;provide a deep and theoretically informed understanding of those changes -- both for academic and non-academic beneficiaries.\&lt;/span\&gt;\&lt;/p\&gt;}
}

@article{fraij_literature_2021,
  title = {A Literature {{Review}}: {{Artificial Intelligence Impact}} on the {{Recruitment Process}}},
  shorttitle = {A Literature {{Review}}},
  author = {FraiJ, JihaD and L{\'a}szl{\'o}, V{\'a}rallyai},
  year = {2021},
  month = may,
  journal = {International Journal of Engineering and Management Sciences},
  volume = {6},
  number = {1},
  pages = {108--119},
  issn = {2498-700X},
  doi = {10.21791/IJEMS.2021.1.10},
  abstract = {This paper aim is to review the implementation of artificial intelligence (AI) in the Human Resources Management (HRM) recruitment processes. A systematic review was adopted in which academic papers, magazine articles as well as high rated websites with related fields were checked. The findings of this study should contribute to the general understanding of the impact of AI on the HRM recruitment process. It was impossible to track and cover all topics related to the subject. However, the research methodology used seems to be reasonable and acceptable as it covers a good number of articles which are related to the core subject area. The results and findings were almost clear that using AI is advantages in the area of recruitment as technology can serve best in this area. Moreover, time, efforts, and boring daily tasks are transformed to be computerized which makes a good space for humans to focus on more important subjects related to boosting performance and development. Acquiring automation and cognitive insights as well as cognitive engagement in the recruitment process would make it possible for systems to work similarly to the human brain in terms of data analysis and the ability to build an effective systematic engagement to process the data in an unbiased, efficient and fast way.},
  copyright = {Copyright (c) 2021 International Journal of Engineering and Management Sciences},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/25MWPF9L/FraiJ and László - 2021 - A literature Review Artificial Intelligence Impac.pdf}
}

@article{gadd_what_2019,
  title = {What Does `Green' Open Access Mean? {{Tracking}} Twelve Years of Changes to Journal Publisher Self-Archiving Policies},
  shorttitle = {What Does `Green' Open Access Mean?},
  author = {Gadd, Elizabeth and Troll Covey, Denise},
  year = {2019},
  month = mar,
  journal = {Journal of Librarianship and Information Science},
  volume = {51},
  number = {1},
  pages = {106--122},
  publisher = {{SAGE Publications Ltd}},
  issn = {0961-0006},
  doi = {10.1177/0961000616657406},
  abstract = {Traces the 12-year self-archiving policy journey of the original 107 publishers listed on the SHERPA/RoMEO Publisher Policy Database in 2004, through to 2015. Maps the RoMEO colour codes (`green', `blue', `yellow' and `white') and related restrictions and conditions over time. Finds that while the volume of publishers allowing some form of self-archiving (pre-print, post-print or both) has increased by 12\% over the 12 years, the volume of restrictions around how, where and when self-archiving may take place has increased 119\%, 190\% and 1000\% respectively. A significant positive correlation was found between the increase in self-archiving restrictions and the introduction of Gold paid open access options. Suggests that by conveying only the version of a paper that authors may self-archive, the RoMEO colour codes do not address all the key elements of the Bethesda Definition of Open Access. Compares the number of RoMEO `green' publishers over time with those meeting the definition for `redefined green' (allowing embargo-free deposit of the post-print in an institutional repository). Finds that RoMEO `green' increased by 8\% and `redefined green' decreased by 35\% over the 12 years. Concludes that the RoMEO colour codes no longer convey a commitment to green open access as originally intended. Calls for open access advocates, funders, institutions and authors to redefine what `green' means to better reflect a publisher's commitment to self-archiving.},
  langid = {english},
  keywords = {Embargo periods,green open access,institutional repository,publisher policies,self-archiving},
  file = {/Users/charliejhadley/Zotero/storage/FC5CFKDT/Gadd and Troll Covey - 2019 - What does ‘green’ open access mean Tracking twelv.pdf}
}

@article{gadd_what_2019-1,
  title = {What Does `Green' Open Access Mean? {{Tracking}} Twelve Years of Changes to Journal Publisher Self-Archiving Policies},
  shorttitle = {What Does `Green' Open Access Mean?},
  author = {Gadd, Elizabeth and Troll Covey, Denise},
  year = {2019},
  month = mar,
  journal = {Journal of Librarianship and Information Science},
  volume = {51},
  number = {1},
  pages = {106--122},
  publisher = {{SAGE Publications Ltd}},
  issn = {0961-0006},
  doi = {10.1177/0961000616657406},
  abstract = {Traces the 12-year self-archiving policy journey of the original 107 publishers listed on the SHERPA/RoMEO Publisher Policy Database in 2004, through to 2015. Maps the RoMEO colour codes (`green', `blue', `yellow' and `white') and related restrictions and conditions over time. Finds that while the volume of publishers allowing some form of self-archiving (pre-print, post-print or both) has increased by 12\% over the 12 years, the volume of restrictions around how, where and when self-archiving may take place has increased 119\%, 190\% and 1000\% respectively. A significant positive correlation was found between the increase in self-archiving restrictions and the introduction of Gold paid open access options. Suggests that by conveying only the version of a paper that authors may self-archive, the RoMEO colour codes do not address all the key elements of the Bethesda Definition of Open Access. Compares the number of RoMEO `green' publishers over time with those meeting the definition for `redefined green' (allowing embargo-free deposit of the post-print in an institutional repository). Finds that RoMEO `green' increased by 8\% and `redefined green' decreased by 35\% over the 12 years. Concludes that the RoMEO colour codes no longer convey a commitment to green open access as originally intended. Calls for open access advocates, funders, institutions and authors to redefine what `green' means to better reflect a publisher's commitment to self-archiving.},
  langid = {english},
  keywords = {Embargo periods,green open access,institutional repository,publisher policies,self-archiving},
  file = {/Users/charliejhadley/Zotero/storage/EWBCVHRQ/Gadd and Troll Covey - 2019 - What does ‘green’ open access mean Tracking twelv.pdf}
}

@misc{gallup_why_2018,
  title = {Why {{Phone}} and {{Web Survey Results Aren}}'t the {{Same}}},
  author = {{Gallup}},
  year = {2018},
  month = apr,
  journal = {Gallup.com},
  abstract = {Researchers who are considering mixing survey research modes or contemplating a transition to a new method should be especially mindful of mode effects.},
  chapter = {Methodology Blog},
  howpublished = {https://news.gallup.com/opinion/methodology/233291/why-phone-web-survey-results-aren.aspx},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/U7XJX5K8/why-phone-web-survey-results-aren.html}
}

@article{ginsberg_detecting_2009,
  title = {Detecting Influenza Epidemics Using Search Engine Query Data},
  author = {Ginsberg, Jeremy and Mohebbi, Matthew H. and Patel, Rajan S. and Brammer, Lynnette and Smolinski, Mark S. and Brilliant, Larry},
  year = {2009},
  month = feb,
  journal = {Nature},
  volume = {457},
  number = {7232},
  pages = {1012--1014},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature07634},
  abstract = {This paper - first published on-line in November 2008 - draws on data from an early version of the Google Flu Trends search engine to estimate the levels of flu in a population. It introduces a computational model that converts raw search query data into a region-by-region real-time surveillance system that accurately estimates influenza activity with a lag of about one day - one to two weeks faster than the conventional reports published by the Centers for Disease Prevention and Control.},
  copyright = {2009 Macmillan Publishers Limited. All rights reserved},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/Users/charliejhadley/Zotero/storage/I5TI3VRJ/Ginsberg et al. - 2009 - Detecting influenza epidemics using search engine .pdf;/Users/charliejhadley/Zotero/storage/MBGUPH2K/nature07634.html}
}

@misc{global_health_data_exchange_global_2022,
  title = {Global {{Burden}} of {{Disease Dataset Explorer}}},
  author = {{Global Health Data Exchange}},
  year = {2022},
  journal = {Institute for Health Metrics and Evaluation},
  abstract = {View and download updated estimates of the world's health for 369 diseases and injuries and 87 risk factors from 1990 to 2019 in this interactive tool.},
  howpublished = {https://vizhub.healthdata.org/gbd-results},
  file = {/Users/charliejhadley/Zotero/storage/IH6PUVUI/gbd-results.html}
}

@misc{goldfain_sources_2020,
  title = {Sources of Unintended Bias in Training Data},
  author = {Goldfain, Cristina},
  year = {2020},
  month = aug,
  journal = {Medium},
  abstract = {Practical examples unveiling sources of unintended bias using synthetic training data},
  howpublished = {https://towardsdatascience.com/sources-of-unintended-bias-in-training-data-be5b7f3347d0},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/SQM37H5U/sources-of-unintended-bias-in-training-data-be5b7f3347d0.html}
}

@article{goodman_machine_2018,
  title = {Machine {{Learning}}, {{Health Disparities}}, and {{Causal Reasoning}}},
  author = {Goodman, Steven N. and Goel, Sharad and Cullen, Mark R.},
  year = {2018},
  month = dec,
  journal = {Annals of Internal Medicine},
  volume = {169},
  number = {12},
  pages = {883--884},
  publisher = {{American College of Physicians}},
  issn = {0003-4819},
  doi = {10.7326/M18-3297},
  file = {/Users/charliejhadley/Zotero/storage/MJ5P3U8W/Goodman et al. - 2018 - Machine Learning, Health Disparities, and Causal R.pdf}
}

@misc{google_blog_fall_2011,
  title = {A Fall Sweep},
  author = {{Google Blog}},
  year = {2011},
  month = oct,
  journal = {Official Google Blog},
  abstract = {Insights from Googlers into our products, technology, and the Google culture},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/FI8HYU27/fall-sweep.html}
}

@misc{google_real_2022,
  title = {Real {{Tone}} on {{Google Pixel}}},
  author = {{Google}},
  year = {2022},
  journal = {Google Store},
  abstract = {With Pixel 6, we vastly improved our camera tuning models and algorithms to more accurately highlight the nuances of diverse skin tones.},
  howpublished = {https://store.google.com/intl/en/discover/realtone/},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/4FLTT4CW/realtone.html}
}

@article{gordon_are_2022,
  title = {Are Replication Rates the Same across Academic Fields? {{Community}} Forecasts from the {{DARPA SCORE}} Programme},
  shorttitle = {Are Replication Rates the Same across Academic Fields?},
  author = {Gordon, Michael and Viganola, Domenico and Bishop, Michael and Chen, Yiling and Dreber, Anna and Goldfedder, Brandon and Holzmeister, Felix and Johannesson, Magnus and Liu, Yang and Twardy, Charles and Wang, Juntao and Pfeiffer, Thomas},
  year = {2022},
  month = jul,
  journal = {Royal Society Open Science},
  volume = {7},
  number = {7},
  pages = {200566},
  publisher = {{Royal Society}},
  doi = {10.1098/rsos.200566},
  abstract = {The Defense Advanced Research Projects Agency (DARPA) programme `Systematizing Confidence in Open Research and Evidence' (SCORE) aims to generate confidence scores for a large number of research claims from empirical studies in the social and behavioural sciences. The confidence scores will provide a quantitative assessment of how likely a claim will hold up in an independent replication. To create the scores, we follow earlier approaches and use prediction markets and surveys to forecast replication outcomes. Based on an initial set of forecasts for the overall replication rate in SCORE and its dependence on the academic discipline and the time of publication, we show that participants expect replication rates to increase over time. Moreover, they expect replication rates to differ between fields, with the highest replication rate in economics (average survey response 58\%), and the lowest in psychology and in education (average survey response of 42\% for both fields). These results reveal insights into the academic community's views of the replication crisis, including for research fields for which no large-scale replication studies have been undertaken yet.},
  keywords = {forecasting,replication,reproducibility crisis,science policy},
  file = {/Users/charliejhadley/Zotero/storage/PCLJZ7Q4/Gordon et al. - Are replication rates the same across academic fie.pdf}
}

@article{grahe_eammi2_2022,
  title = {{{EAMMi2 Public Data}}},
  author = {Grahe, Jon and Chalk, Holly and Cramblet Alvarez, Leslie and Faas, Caitlin and Hermann, Anthony and McFall, Joseph and Molyneux, Kathryn},
  year = {2022},
  month = aug,
  publisher = {{Open Science Framework}},
  doi = {10.17605/OSF.IO/QTQPB},
  abstract = {This component includes the raw and processed data from the EAMMi2 project as well as keys to describe variables. Contributors on this component helped to process the data files.},
  collaborator = {Leighton, Dana and Corker, Katherine and Sharon, Tanya and Barlett, Christopher and Peer, Justin and Musial, Joseph and Skulborstad, Hayley and Yang, Chia-chen and Kemp, Andrew and Toyokawa, Teru and Hernandez, Hanna and Oleson, Kathryn and Sylaska, Kateryna and Schmolesky, Matthew and Artime, Tiffany and Chopik, William and Hall, Scott and Open Science Framework}
}

@article{grahe_emerging_2018,
  title = {Emerging {{Adulthood Measured}} at {{Multiple Institutions}} 2: {{The Data}}},
  shorttitle = {Emerging {{Adulthood Measured}} at {{Multiple Institutions}} 2},
  author = {Grahe, Jon E. and Chalk, Holly M. and Alvarez, Leslie D. Cramblet and Faas, Caitlin S. and Hermann, Anthony D. and McFall, Joseph P.},
  year = {2018},
  month = sep,
  journal = {Journal of Open Psychology Data},
  volume = {6},
  number = {1},
  pages = {4},
  publisher = {{Ubiquity Press}},
  issn = {2050-9863},
  doi = {10.5334/jopd.38},
  abstract = {Collaborators from 32 academic institutions primarily in the United States collected data from emerging adults (Nraw = 4220, Nprocessed = 3134). Participants completed self-report measures assessing markers of adulthood, IDEA inventory of dimensions of emerging adulthood, subjective well-being, mindfulness, belonging, self-efficacy, disability identity, somatic health, perceived stress, perceived social support, social media use, political affiliation, beliefs about the American dream, interpersonal transgressions, narcissism, interpersonal exploitativeness, beliefs about marriage, and demographics. The data are available at (https://osf.io/qtqpb/) with details about the study and contributors at our main EAMMi2 page (https://osf.io/te54b/). These data may be used to examine new research questions, provide authentic research experiences for students, and provide demonstrations for research and statistics courses.},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  langid = {english},
  keywords = {Crowdsourcing,Emerging Adulthood,Psychological Measures,Teaching of Psychology,Transitions,Undergraduate research},
  file = {/Users/charliejhadley/Zotero/storage/BMMS3TVX/Grahe et al. - 2018 - Emerging Adulthood Measured at Multiple Institutio.pdf;/Users/charliejhadley/Zotero/storage/IL7UGIGI/jopd.38.html}
}

@article{grima_importance_2020,
  title = {The Importance of Urban Natural Areas and Urban Ecosystem Services during the {{COVID-19}} Pandemic},
  author = {Grima, Nelson and Corcoran, Will and {Hill-James}, Corinne and Langton, Benjamin and Sommer, Haley and Fisher, Brendan},
  editor = {Aguilar, Francisco X.},
  year = {2020},
  month = dec,
  journal = {PLOS ONE},
  volume = {15},
  number = {12},
  pages = {e0243344},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0243344},
  abstract = {Urban, peri-urban forests and other natural areas provide a wide range of material and non-material benefits to people known as ecosystem services. Access to these areas has been linked to benefits for physical and mental health of local populations. In the spring of 2020, the COVID-19 global pandemic forced many governments to impose a set of restrictions including the closure of businesses, cancelation of public events and schooling, social distancing, limitations on the size of social gatherings, and travel restrictions. During this period of restrictions, we conducted a study assessing the importance of urban and peri-urban forests and other natural areas to people living in and around the city of Burlington, Vermont, USA. We evaluated the self-reported use and changes in personal importance related to these natural areas before and during the period of restrictions. We received over 400 responses to our field survey. The results show that 69.0\% of the respondents had               increased               or               greatly increased               their visitation rate to our natural areas and urban forests, and 80.6\% of respondents considered that the importance of these areas, and access to them, either               increased               or               greatly increased               . Moreover 25.8\% of the sample had either never, or very rarely accessed their local natural areas before the pandemic, but 69.2\% of the first time or infrequent visitors reported that having access to these areas during COVID-19 as `very important'. People reported that these areas were important for a wide range of activities from exercise to birding, but also reported values related to reducing stress in a time of global chaos. Our results indicate the increasing demand and value of such areas in times of crisis such as COVID-19. Experts in zoonotic disease predict the potential for more frequent pandemic events, thus predicating the importance for continued funding for, maintenance of, and improved access to, natural areas to our largely urban civilization.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/QD3UZ3EB/Grima et al. - 2020 - The importance of urban natural areas and urban ec.pdf}
}

@inproceedings{habib_okay_2022,
  title = {``{{Okay}}, Whatever'': {{An Evaluation}} of {{Cookie Consent Interfaces}}},
  shorttitle = {``{{Okay}}, Whatever''},
  booktitle = {Proceedings of the 2022 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Habib, Hana and Li, Megan and Young, Ellie and Cranor, Lorrie},
  year = {2022},
  month = apr,
  series = {{{CHI}} '22},
  pages = {1--27},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3491102.3501985},
  abstract = {Many websites have added cookie consent interfaces to meet regulatory consent requirements. While prior work has demonstrated that they often use dark patterns \textemdash{} design techniques that lead users to less privacy-protective options \textemdash{} other usability aspects of these interfaces have been less explored. This study contributes a comprehensive, two-stage usability assessment of cookie consent interfaces. We first inspected 191 consent interfaces against five dark pattern heuristics and identified design choices that may impact usability. We then conducted a 1,109-participant online between-subjects experiment exploring the usability impact of seven design parameters. Participants were exposed to one of 12 consent interface variants during a shopping task on a prototype e-commerce website and answered a survey about their experience. Our findings suggest that a fully-blocking consent interface with in-line cookie options accompanied by a persistent button enabling users to later change their consent decision best meets several design objectives.},
  isbn = {978-1-4503-9157-3},
  keywords = {cookie consent,GDPR,privacy choice,privacy notice},
  file = {/Users/charliejhadley/Zotero/storage/6GKY3P3W/Habib et al. - 2022 - “Okay, whatever” An Evaluation of Cookie Consent .pdf}
}

@misc{hadley_24_2018,
  title = {24 Days of {{Christmassy}} Hot Drinks},
  author = {Hadley, Charlie},
  year = {2018},
  pages = {286222 Bytes},
  publisher = {{figshare}},
  doi = {10.6084/M9.FIGSHARE.7376228.V3},
  abstract = {This deposit contains festive hot drinks marketed in the UK each year from 2018 onwards.{$<$}br{$>$}Hot drinks are selected from nationwide cafe/lunch venues, the list is deliberately limited to 24 drinks each year.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {150401 Food and Hospitality Services,160104 Social and Cultural Anthropology,FOS: Economics and business,FOS: Sociology}
}

@misc{hadley_how_2022,
  title = {How to Tidy Select All That Apply Questions with {{R}}},
  author = {Hadley, Charlotte},
  year = {2022},
  month = jul,
  journal = {R for the Rest of Us Blog},
  howpublished = {https://rfortherestofus.com/2022/05/select-all/}
}

@misc{hans_rosling_best_2006,
  title = {The Best Stats You've Ever Seen [{{Video}}]},
  author = {{Hans Rosling}},
  year = {2006},
  month = feb,
  journal = {The best stats you've ever seen},
  abstract = {You've never seen data presented like this. With the drama and urgency of a sportscaster, statistics guru Hans Rosling debunks myths about the so-called "developing world."},
  howpublished = {https://www.ted.com/talks/hans\_rosling\_the\_best\_stats\_you\_ve\_ever\_seen?language=en},
  langid = {english}
}

@misc{hao_this_2019,
  title = {This Is How {{AI}} Bias Really Happens\textemdash and Why It's so Hard to Fix},
  author = {Hao, Karen},
  year = {2019},
  month = feb,
  journal = {MIT Technology Review},
  abstract = {Bias can creep in at many stages of the deep-learning process, and the standard practices in computer science aren't designed to detect it.},
  howpublished = {https://www.technologyreview.com/2019/02/04/137602/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/KP7EQ9GW/__________________This is how AI bias really happens—and why it’s so hard to fix _ MIT Technology Review.mht;/Users/charliejhadley/Zotero/storage/6M6WCEHS/__html_only_This is how AI bias really happens—and why it’s so hard to fix _ MIT Technology Review.html}
}

@misc{hardt_occupy_2013,
  title = {Occupy {{Algorithms}}: {{Will Algorithms Serve}} the 99\%?},
  shorttitle = {Occupy {{Algorithms}}},
  author = {Hardt, Moritz},
  year = {2013},
  abstract = {This short note is a response to Frank Pasquale's article ``The Emperor's New Codes: Reputation and Search Algorithms in the Finance},
  file = {/Users/charliejhadley/Zotero/storage/Z52UGPWI/Hardt - 2013 - Occupy Algorithms Will Algorithms Serve the 99%.pdf;/Users/charliejhadley/Zotero/storage/I255XAJ8/download.html}
}

@book{harrison_r_2020,
  title = {R for Health Data Science},
  author = {Harrison, Ewen and Pius, Riinu},
  year = {2020},
  series = {Chapman \& {{Hall}}/{{CRC Statistics}} in {{Social}} and {{Behavioural Science}}},
  edition = {First},
  publisher = {{Taylor and Francis}},
  address = {{Boca Raton}},
  abstract = {"Written for those with only a brief introduction to statistics, this book takes you on a statistical journey from how polls are taken to how they can-and should-be used to estimate current popular opinion. Once an understanding of the election process is built, we turn towards testing elections for evidence of unfairness. While holding elections has become the de facto proof of government legitimacy, those electoral processes may hide the dirty little secret of the government illicitly ensuring a favorable election outcome"--},
  isbn = {978-0-367-42832-7}
}

@misc{hawkins_spiralling_2016,
  title = {Spiralling Global Temperatures | {{Climate Lab Book}}},
  author = {Hawkins, Ed},
  year = {2016},
  month = may,
  howpublished = {https://www.climate-lab-book.ac.uk/2016/spiralling-global-temperatures/},
  file = {/Users/charliejhadley/Zotero/storage/HGLLALKB/spiralling-global-temperatures.html}
}

@inproceedings{heer_crowdsourcing_2010,
  title = {Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design},
  shorttitle = {Crowdsourcing Graphical Perception},
  booktitle = {Proceedings of the 28th International Conference on {{Human}} Factors in Computing Systems - {{CHI}} '10},
  author = {Heer, Jeffrey and Bostock, Michael},
  year = {2010},
  pages = {203},
  publisher = {{ACM Press}},
  address = {{Atlanta, Georgia, USA}},
  doi = {10.1145/1753326.1753357},
  isbn = {978-1-60558-929-9},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/EAIZCZTL/Heer and Bostock - 2010 - Crowdsourcing graphical perception using mechanic.pdf}
}

@article{heer_crowdsourcing_nodate,
  title = {Crowdsourcing {{Graphical Perception}}: {{Using Mechanical Turk}} to {{Assess Visualization Design}}},
  author = {Heer, Jeffrey and Bostock, Michael},
  pages = {10},
  abstract = {Understanding perception is critical to effective visualization design. With its low cost and scalability, crowdsourcing presents an attractive option for evaluating the large design space of visualizations; however, it first requires validation. In this paper, we assess the viability of Amazon's Mechanical Turk as a platform for graphical perception experiments. We replicate previous studies of spatial encoding and luminance contrast and compare our results. We also conduct new experiments on rectangular area perception (as in treemaps or cartograms) and on chart size and gridline spacing. Our results demonstrate that crowdsourced perception experiments are viable and contribute new insights for visualization design. Lastly, we report cost and performance data from our experiments and distill recommendations for the design of crowdsourced studies.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/7K2IDSVQ/Heer and Bostock - Crowdsourcing Graphical Perception Using Mechanic.pdf}
}

@article{herndon_does_2014,
  title = {Does High Public Debt Consistently Stifle Economic Growth? {{A}} Critique of {{Reinhart}} and {{Rogoff}}},
  shorttitle = {Does High Public Debt Consistently Stifle Economic Growth?},
  author = {Herndon, T. and Ash, M. and Pollin, R.},
  year = {2014},
  month = mar,
  journal = {Cambridge Journal of Economics},
  volume = {38},
  number = {2},
  pages = {257--279},
  issn = {0309-166X, 1464-3545},
  doi = {10.1093/cje/bet075},
  langid = {english},
  keywords = {excel reproducibility,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/H7E8THPU/Herndon et al. - 2014 - Does high public debt consistently stifle economic.pdf}
}

@article{hirao_natural_2012,
  title = {Natural versus {{Artificial Creation}} of {{Base Pairs}} in {{DNA}}: {{Origin}} of {{Nucleobases}} from the {{Perspectives}} of {{Unnatural Base Pair Studies}}},
  shorttitle = {Natural versus {{Artificial Creation}} of {{Base Pairs}} in {{DNA}}},
  author = {Hirao, Ichiro and Kimoto, Michiko and Yamashige, Rie},
  year = {2012},
  month = dec,
  journal = {Accounts of Chemical Research},
  volume = {45},
  number = {12},
  pages = {2055--2065},
  publisher = {{American Chemical Society}},
  issn = {0001-4842},
  doi = {10.1021/ar200257x},
  abstract = {Since life began on Earth, the four types of bases (A, G, C, and T(U)) that form two sets of base pairs have remained unchanged as the components of nucleic acids that replicate and transfer genetic information. Throughout evolution, except for the U to T modification, the four base structures have not changed. This constancy within the genetic code raises the question of how these complicated nucleotides were generated from the molecules in a primordial soup on the early Earth. At some prebiotic stage, the complementarity of base pairs might have accelerated the generation and accumulation of nucleotides or oligonucleotides. We have no clues whether one pair of nucleobases initially appeared on the early Earth during this process or a set of two base pairs appeared simultaneously.Recently, researchers have developed new artificial pairs of nucleobases (unnatural base pairs) that function alongside the natural base pairs. Some unnatural base pairs in duplex DNA can be efficiently and faithfully amplified in a polymerase chain reaction (PCR) using thermostable DNA polymerases. The addition of unnatural base pair systems could expand the genetic alphabet of DNA, thus providing a new mechanism for the generation novel biopolymers by the site-specific incorporation of functional components into nucleic acids and proteins. Furthermore, the process of unnatural base pair development might provide clues to the origin of the natural base pairs in a primordial soup on the early Earth. In this Account, we describe the development of three representative types of unnatural base pairs that function as a third pair of nucleobases in PCR and reconsider the origin of the natural nucleic acids.As researchers developing unnatural base pairs, they use repeated ``proof of concept'' experiments. As researchers design new base pairs, they improve the structures that function in PCR and eliminate those that do not. We expect that this process is similar to the one functioning in the chemical evolution and selection of the natural nucleobases. Interestingly, the initial structures designed by each research group were quite similar to those of the latest successful unnatural base pairs. In this regard, it is tempting to form a hypothesis that the base pairs on the primordial Earth, in which the natural purine bases, A and G, and pyrimidine bases, C and T(U), originated from structurally similar compounds, such as hypoxanthine for a purine base predecessor. Subsequently, the initial base pair evolved to the present two sets of base pairs via a keto-enol tautomerization of the initial compounds.},
  file = {/Users/charliejhadley/Zotero/storage/HR7MRNQ3/ar200257x.html}
}

@misc{ho_google_2010,
  title = {Google {{Buzz}} in {{Gmail}}},
  author = {Ho, Edward},
  year = {2010},
  month = feb,
  journal = {Official Gmail Blog},
  abstract = {Posted by Edward Ho, Tech Lead, Google Buzz   Five years ago, Gmail was just email. Later we added chat and then video chat, both built righ...},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/M5XWCQ4Q/google-buzz-in-gmail.html}
}

@article{hu_factors_2022,
  title = {Factors Influencing Self-Care Behaviours of Patients with Type 2 Diabetes in {{China}} Based on the Health Belief Model: A Cross-Sectional Study},
  shorttitle = {Factors Influencing Self-Care Behaviours of Patients with Type 2 Diabetes in {{China}} Based on the Health Belief Model},
  author = {Hu, Yue and Liu, Huijun and Wu, Jie and Fang, Guixia},
  year = {2022},
  month = aug,
  journal = {BMJ Open},
  volume = {12},
  number = {8},
  pages = {e044369},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2020-044369},
  abstract = {Objectives\hspace{0.6em} The study aimed to explore the status and predictors of self-\-care behaviours in patients with type 2 diabetes in China based on the health belief model. Design\hspace{0.6em} The cross-\-sectional study included 1140 patients aged {$\geq$}36 years with type 2 diabetes who had established health records in community health service institutions. A questionnaire was designed based on the health belief model, which mainly included perceived susceptibility, severity, benefits, barriers, effectiveness, sociodemographic characteristics and self-\-care behaviours. Setting\hspace{0.6em} Using a multistage sampling method, 36 villages and communities were randomly selected in China. Participants\hspace{0.6em} A total of 1260 patients with type 2 diabetes were contacted, but 118 refused to participate in the study. Of the 1142 participants, two were subsequently excluded, and the final number of participants included in the study was 1140 (90.5\% response rate). Results\hspace{0.6em} The average score of health beliefs was 0.71 (SD=0.08). The logistic regression analysis showed that sex, region, perceived severity, perceived barriers and perceived benefits were related to self-\-care behaviours. Conclusions\hspace{0.6em} Perceived severity, benefits and barriers were key factors affecting self-\-care behaviours in patients with type 2 diabetes; health education for patients should be strengthened to improve the self-\-care level of patients with diabetes.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/6SKT5HU7/Hu et al. - 2022 - Factors influencing self-care behaviours of patien.pdf}
}

@misc{iker_rivas-gonzalez_irg_bio_i_2022,
  type = {Tweet},
  title = {I Am Also Joining the Hexbin Fever! 🐝 {{For}} This Week's \#{{TidyTuesday}}, {{I}} Plotted the Number of Bee Colonies in the {{US}} by Year and Season. {{It}} Seems like Cold and Warm States Have Different Patterns of Seasonal Changes. {{Code}}: {{https://github.com/rivasiker/TidyTuesday/blob/main/2022/2022-01-11/analysis\_2022-01-11.Rmd}} \#{{RStats}} \#{{DataViz}} \#ggplot2 {{https://t.co/OYGyg2az7M}}},
  author = {{Iker Rivas-Gonz\'alez [@irg\_bio]}},
  year = {2022},
  month = jan,
  journal = {Twitter},
  langid = {english},
  keywords = {hexbin honey},
  file = {/Users/charliejhadley/Zotero/storage/L78672MU/1481214254351097859.html}
}

@techreport{information_commissioners_office_anonymisation_2012,
  title = {Anonymisation: Managing Data Protection Risk Code of Practice},
  author = {{Information Commissioner's Office}},
  year = {2012},
  institution = {{Information Commissioner's Office}},
  file = {/Users/charliejhadley/Zotero/storage/BV6RKKLJ/Information Commissioner's Office - 2012 - Anonymisation managing data protection risk code .pdf}
}

@misc{information_commissioners_office_health_2021,
  title = {Health Data},
  author = {{Information Commissioner's Office}},
  year = {2021},
  month = jan,
  publisher = {{ICO}},
  howpublished = {https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/right-of-access/health-data/},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/D7X3F4QI/health-data.html}
}

@article{ioannidis_why_2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  year = {2005},
  month = aug,
  journal = {PLoS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/AY5JVKW6/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf}
}

@misc{ipsos_mori_attitudes_2016,
  title = {Attitudes towards {{Commercial Access}} to {{Health Data}}, 2015-2016},
  author = {Ipsos MORI and Wellcome Trust},
  year = {2016},
  publisher = {{UK Data Service}},
  doi = {10.5255/UKDA-SN-8049-1},
  abstract = {Data are collected throughout the health service in increasingly large quantities, as well as in the contexts of biomedical and health research, for both direct care and secondary uses.\&lt;br\&gt; \&lt;br\&gt; The Wellcome Trust commissioned Ipsos MORI to research attitudes towards commercial organisations having access to health data. As part of this, a survey was conducted to provide measures for some of the themes that arose from qualitative workshops, particularly where these themes were suited to a quantitative follow-up. \&lt;br\&gt; \&lt;br\&gt; The \&lt;I\&gt;Attitudes towards Commercial Access to Health Data, 2015-2016\&lt;/I\&gt; survey was designed to explore perceptions of the sharing of health data, awareness of the extent of this sharing and to attempt to identify key red lines in the attitudes of the public. The findings fed into a wider report for the Wellcome Trust that incorporated the qualitative and quantitative findings.\&lt;br\&gt; \&lt;br\&gt;}
}

@article{ipsos_mori_one-way_2017,
  title = {The {{One-Way Mirror}}: {{Public}} Attitudes to Commercial Access to Health Data},
  shorttitle = {The {{One-Way Mirror}}},
  author = {Ipsos MORI},
  year = {2017},
  pages = {2903147 Bytes},
  publisher = {{Wellcome Trust}},
  doi = {10.6084/M9.FIGSHARE.5616448.V1},
  abstract = {Data is collected throughout the health service in increasingly large quantities, as well as in the contexts of biomedical and health research. Data is collected for direct care and for secondary uses as well. {$<$}br{$>$}In surveys, such as Ipsos MORI's work for the Royal Statistical Society (RSS), the public say that in principle they do not want their health records being shared with private companies. However, there are many different types of commercial access going on now, and possible in future. The Wellcome Trust therefore wanted to investigate how, and in what ways, the public would distinguish between different types of commercial access; and whether the type of data used, and the types of data user, would have an influence on the level of acceptability to the public. {$<$}br{$>$}The Trust therefore commissioned Ipsos MORI to carry out research to understand how attitudes towards commercial access to health data are formed and influenced, among a cross-section of the British general public and with specific audiences such as healthcare professionals, patients, and members of cohort studies.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Science Policy},
  file = {/Users/charliejhadley/Zotero/storage/P24QJJRT/Ipsos MORI - 2017 - The One-Way Mirror Public attitudes to commercial.pdf}
}

@misc{jackson_netflix_2017,
  title = {The {{Netflix Prize}}: {{How}} a \$1 {{Million Contest Changed Binge-Watching Forever}}},
  shorttitle = {The {{Netflix Prize}}},
  author = {Jackson, Dan},
  year = {2017},
  month = jul,
  journal = {Thrillist},
  abstract = {Inside the race for the prize.},
  howpublished = {https://www.thrillist.com/entertainment/nation/the-netflix-prize},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/6SYETIZB/the-netflix-prize.html}
}

@article{jamieson_likert_2004,
  title = {Likert Scales: How to (Ab)Use Them},
  shorttitle = {Likert Scales},
  author = {Jamieson, Susan},
  year = {2004},
  journal = {Medical Education},
  volume = {38},
  number = {12},
  pages = {1217--1218},
  issn = {1365-2923},
  doi = {10.1111/j.1365-2929.2004.02012.x},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2929.2004.02012.x},
  file = {/Users/charliejhadley/Zotero/storage/JW3MLKNY/Jamieson - 2004 - Likert scales how to (ab)use them.pdf;/Users/charliejhadley/Zotero/storage/B6XWQKKF/j.1365-2929.2004.02012.html}
}

@article{jernigan_gaydar_2009,
  title = {Gaydar: {{Facebook}} Friendships Expose Sexual Orientation},
  shorttitle = {Gaydar},
  author = {Jernigan, Carter and Mistree, Behram F. T.},
  year = {2009},
  month = sep,
  journal = {First Monday},
  issn = {1396-0466},
  doi = {10.5210/fm.v14i10.2611},
  abstract = {Public information about one's coworkers, friends, family, and acquaintances, as well as one's associations with them, implicitly reveals private information.  Social-networking websites, e-mail, instant messaging, telephone, and VoIP are all technologies steeped in network data\textemdash data relating one person to another.  Network data shifts the locus of information control away from individuals, as the individual's traditional and absolute discretion is replaced by that of his social-network.  Our research demonstrates a method for accurately predicting the sexual orientation of Facebook users by analyzing friendship associations.  After analyzing 4,080 Facebook profiles from the MIT network, we determined that the percentage of a given user's friends who self-identify as gay male is strongly correlated with the sexual orientation of that user, and we developed a logistic regression classifier with strong predictive power.  Although we studied Facebook friendship ties, network data is pervasive in the broader context of computer-mediated communication, raising significant privacy issues for communication technologies to which there are no neat solutions.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/RV6NXAAK/_View of Gaydar_ Facebook friendships expose sexual orientation _ First Monday.html}
}

@article{john_measuring_2012,
  title = {Measuring the {{Prevalence}} of {{Questionable Research Practices With Incentives}} for {{Truth Telling}}},
  author = {John, Leslie K. and Loewenstein, George and Prelec, Drazen},
  year = {2012},
  month = may,
  journal = {Psychological Science},
  volume = {23},
  number = {5},
  pages = {524--532},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797611430953},
  abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
  langid = {english},
  keywords = {reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/6QLZENEW/John et al. - 2012 - Measuring the Prevalence of Questionable Research .pdf}
}

@article{kastellec_using_2007,
  title = {Using {{Graphs Instead}} of {{Tables}} in {{Political Science}}},
  author = {Kastellec, Jonathan P. and Leoni, Eduardo L.},
  year = {2007},
  month = dec,
  journal = {Perspectives on Politics},
  volume = {5},
  number = {04},
  issn = {1537-5927, 1541-0986},
  doi = {10.1017/S1537592707072209},
  langid = {english},
  keywords = {tables vs charts},
  file = {/Users/charliejhadley/Zotero/storage/82VGXXL5/Kastellec and Leoni - 2007 - Using Graphs Instead of Tables in Political Scienc.pdf}
}

@misc{king_how_2013,
  title = {How to Avoid Making an {{Excel}} Mistake like {{Rogoff}} and {{Reinhart}}},
  author = {King, Ritchie},
  year = {2013},
  month = apr,
  journal = {Quartz},
  abstract = {An~apparent error in Carmen Reinhart and Kenneth Rogoff's influential study of government debt was the result of a simple mistake in Microsoft Excel that all spreadsheet jockeys fear.},
  howpublished = {https://qz.com/75119/how-to-avoid-making-an-excel-mistake-like-rogoff-and-reinhart/},
  langid = {english},
  keywords = {excel reproducibility,reproducibility nightmare},
  file = {/Users/charliejhadley/Zotero/storage/QIYCBNGP/how-to-avoid-making-an-excel-mistake-like-rogoff-and-reinhart.html}
}

@article{kosara_judgment_2016,
  title = {Judgment {{Error}} in {{Pie Chart Variations}}},
  author = {Kosara, Robert and Skau, Drew},
  year = {2016},
  journal = {EuroVis 2016 - Short Papers},
  pages = {5 pages},
  publisher = {{The Eurographics Association}},
  issn = {-},
  doi = {10.2312/EUROVISSHORT.20161167},
  abstract = {Pie charts and their variants are prevalent in business settings and many other uses, even if they are not popular with the academic community. In a recent study, we found that contrary to general belief, there is no clear evidence that these charts are read based on the central angle. Instead, area and arc length appear to be at least equally important.},
  isbn = {9783038680147},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/RSIT5VSX/Kosara and Skau - 2016 - Judgment Error in Pie Chart Variations.pdf}
}

@article{kosara_judgment_2016-1,
  title = {Judgment {{Error}} in {{Pie Chart Variations}}},
  author = {Kosara, Robert and Skau, Drew},
  year = {2016},
  journal = {EuroVis 2016 - Short Papers},
  pages = {5 pages},
  publisher = {{The Eurographics Association}},
  issn = {-},
  doi = {10.2312/EUROVISSHORT.20161167},
  abstract = {Pie charts and their variants are prevalent in business settings and many other uses, even if they are not popular with the academic community. In a recent study, we found that contrary to general belief, there is no clear evidence that these charts are read based on the central angle. Instead, area and arc length appear to be at least equally important. In this paper, we build on that study to test several pie chart variations that are popular in information graphics: exploded pie chart, pie with larger slice, elliptical pie, and square pie (in addition to a regular pie chart used as the baseline). We find that even variants that do not distort central angle cause greater error than regular pie charts. Charts that distort the shape show the highest error. Many of our predictions based on the previous study's results are borne out by this study's findings.},
  isbn = {9783038680147},
  file = {/Users/charliejhadley/Zotero/storage/WHSA9LXT/Kosara and Skau - 2016 - Judgment Error in Pie Chart Variations.pdf}
}

@article{kosara_more_2022,
  title = {More {{Than Meets}} the {{Eye}}: {{A Closer Look}} at {{Encodings}} in {{Visualization}}},
  shorttitle = {More {{Than Meets}} the {{Eye}}},
  author = {Kosara, Robert},
  year = {2022},
  month = mar,
  journal = {IEEE Computer Graphics and Applications},
  volume = {42},
  number = {2},
  pages = {110--114},
  issn = {1558-1756},
  doi = {10.1109/MCG.2021.3138608},
  abstract = {Encoding data visually is at the heart of visualization. We usually assume that encodings are read as specified (i.e., if a bar chart is drawn by the length of the bars based on the data, that is also how we read them). In this paper, we question this assumption and demonstrate that observed encodings often differ from the ones used to specify the visualization. The value of a chart also often comes from higher level derived encodings, and which encodings end up getting used also depends on the user's task.},
  keywords = {Bars,Data visualization,Encoding,Heart,Task analysis},
  file = {/Users/charliejhadley/Zotero/storage/U49QDJQC/Kosara - 2022 - More Than Meets the Eye A Closer Look at Encoding.pdf;/Users/charliejhadley/Zotero/storage/3EGJRPNF/9756627.html}
}

@article{kretschmer_cookie_2021,
  title = {Cookie {{Banners}} and {{Privacy Policies}}: {{Measuring}} the {{Impact}} of the {{GDPR}} on the {{Web}}},
  shorttitle = {Cookie {{Banners}} and {{Privacy Policies}}},
  author = {Kretschmer, Michael and Pennekamp, Jan and Wehrle, Klaus},
  year = {2021},
  month = jul,
  journal = {ACM Transactions on the Web},
  volume = {15},
  number = {4},
  pages = {1--42},
  issn = {1559-1131, 1559-114X},
  doi = {10.1145/3466722},
  abstract = {The General Data Protection Regulation (GDPR) is in effect since May of 2018. As one of the most comprehensive pieces of legislation concerning privacy, it sparked a lot of discussion on the effect it would have on users and providers of online services in particular, due to the large amount of personal data processed in this context. Almost three years later, we are interested in revisiting this question to summarize the impact this new regulation has had on actors in the World Wide Web. Using Scopus, we obtain a vast corpus of academic work to survey studies related to changes on websites since and around the time the GDPR went into force. Our findings show that the emphasis on privacy increased w.r.t. online services, but plenty potential for improvements remains. Although online services are on average more transparent regarding data processing practices in their public data policies, a majority of these policies still either lack information required by the GDPR (e.g., contact information for users to file privacy inquiries) or do not provide this information in a user-friendly form. Additionally, we summarize that online services more often provide means for their users to opt out of data processing, but regularly obstruct convenient access to such means through unnecessarily complex and sometimes illegitimate interface design. Our survey further details that this situation contradicts the preferences expressed by users both verbally and through their actions, and researchers have proposed multiple approaches to facilitate GDPR-conform data processing without negatively impacting the user experience. Thus, we compiled reoccurring points of criticism by privacy researchers and data protection authorities into a list of four guidelines for service providers to consider.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/6JZLX2MD/Kretschmer et al. - 2021 - Cookie Banners and Privacy Policies Measuring the.pdf}
}

@article{kretschmer_cookie_2021-1,
  title = {Cookie {{Banners}} and {{Privacy Policies}}: {{Measuring}} the {{Impact}} of the {{GDPR}} on the {{Web}}},
  shorttitle = {Cookie {{Banners}} and {{Privacy Policies}}},
  author = {Kretschmer, Michael and Pennekamp, Jan and Wehrle, Klaus},
  year = {2021},
  month = jul,
  journal = {ACM Transactions on the Web},
  volume = {15},
  number = {4},
  pages = {1--42},
  issn = {1559-1131, 1559-114X},
  doi = {10.1145/3466722},
  abstract = {The General Data Protection Regulation (GDPR) is in effect since May of 2018. As one of the most comprehensive pieces of legislation concerning privacy, it sparked a lot of discussion on the effect it would have on users and providers of online services in particular, due to the large amount of personal data processed in this context. Almost three years later, we are interested in revisiting this question to summarize the impact this new regulation has had on actors in the World Wide Web. Using Scopus, we obtain a vast corpus of academic work to survey studies related to changes on websites since and around the time the GDPR went into force. Our findings show that the emphasis on privacy increased w.r.t. online services, but plenty potential for improvements remains. Although online services are on average more transparent regarding data processing practices in their public data policies, a majority of these policies still either lack information required by the GDPR (e.g., contact information for users to file privacy inquiries) or do not provide this information in a user-friendly form. Additionally, we summarize that online services more often provide means for their users to opt out of data processing, but regularly obstruct convenient access to such means through unnecessarily complex and sometimes illegitimate interface design. Our survey further details that this situation contradicts the preferences expressed by users both verbally and through their actions, and researchers have proposed multiple approaches to facilitate GDPR-conform data processing without negatively impacting the user experience. Thus, we compiled reoccurring points of criticism by privacy researchers and data protection authorities into a list of four guidelines for service providers to consider.},
  langid = {english}
}

@article{kretschmer_cookie_2021-2,
  title = {Cookie {{Banners}} and {{Privacy Policies}}: {{Measuring}} the {{Impact}} of the {{GDPR}} on the {{Web}}},
  shorttitle = {Cookie {{Banners}} and {{Privacy Policies}}},
  author = {Kretschmer, Michael and Pennekamp, Jan and Wehrle, Klaus},
  year = {2021},
  month = jul,
  journal = {ACM Transactions on the Web},
  volume = {15},
  number = {4},
  pages = {1--42},
  issn = {1559-1131, 1559-114X},
  doi = {10.1145/3466722},
  abstract = {The General Data Protection Regulation (GDPR) is in effect since May of 2018. As one of the most comprehensive pieces of legislation concerning privacy, it sparked a lot of discussion on the effect it would have on users and providers of online services in particular, due to the large amount of personal data processed in this context. Almost three years later, we are interested in revisiting this question to summarize the impact this new regulation has had on actors in the World Wide Web. Using Scopus, we obtain a vast corpus of academic work to survey studies related to changes on websites since and around the time the GDPR went into force. Our findings show that the emphasis on privacy increased w.r.t. online services, but plenty potential for improvements remains. Although online services are on average more transparent regarding data processing practices in their public data policies, a majority of these policies still either lack information required by the GDPR (e.g., contact information for users to file privacy inquiries) or do not provide this information in a user-friendly form. Additionally, we summarize that online services more often provide means for their users to opt out of data processing, but regularly obstruct convenient access to such means through unnecessarily complex and sometimes illegitimate interface design. Our survey further details that this situation contradicts the preferences expressed by users both verbally and through their actions, and researchers have proposed multiple approaches to facilitate GDPR-conform data processing without negatively impacting the user experience. Thus, we compiled reoccurring points of criticism by privacy researchers and data protection authorities into a list of four guidelines for service providers to consider.},
  langid = {english}
}

@misc{landeau_explaining_2020,
  title = {Explaining {{Bias}} in {{Your Data}}},
  author = {Landeau, Alexandre},
  year = {2020},
  month = jun,
  abstract = {An in-depth review of unfairness and bias causes in machine learning and their root in data.},
  howpublished = {https://blog.dataiku.com/explaining-bias-in-your-data},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/EAGMWR2U/explaining-bias-in-your-data.html}
}

@article{lazer_parable_2014,
  title = {The {{Parable}} of {{Google Flu}}: {{Traps}} in {{Big Data Analysis}}},
  shorttitle = {The {{Parable}} of {{Google Flu}}},
  author = {Lazer, David and Kennedy, Ryan and King, Gary and Vespignani, Alessandro},
  year = {2014},
  month = mar,
  journal = {Science},
  volume = {343},
  number = {6176},
  pages = {1203--1205},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1248506},
  file = {/Users/charliejhadley/Zotero/storage/65LCQ6EM/Lazer et al. - 2014 - The Parable of Google Flu Traps in Big Data Analy.pdf}
}

@article{lewis_racial_2019,
  title = {The {{Racial Bias Built Into Photography}}},
  author = {Lewis, Sarah},
  year = {2019},
  month = apr,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {Sarah Lewis explores the relationship between racism and the camera.},
  chapter = {Lens},
  langid = {american},
  keywords = {Blacks,Cameras,Discrimination,Eastman Kodak Company,Fujifilm Corp,Harvard University,Photography,Race and Ethnicity,Skin},
  file = {/Users/charliejhadley/Zotero/storage/EUW2BNMY/sarah-lewis-racial-bias-photography.html}
}

@article{lietzow_biologically_2021,
  title = {Biologically {{Active Compounds}} in {{Mustard Seeds}}: {{A Toxicological Perspective}}},
  shorttitle = {Biologically {{Active Compounds}} in {{Mustard Seeds}}},
  author = {Lietzow, Julika},
  year = {2021},
  month = sep,
  journal = {Foods},
  volume = {10},
  number = {9},
  pages = {2089},
  issn = {2304-8158},
  doi = {10.3390/foods10092089},
  abstract = {Mustard plants have been widely cultivated and used as spice, medicine and as source of edible oils. Currently, the use of the seeds of the mustard species Sinapis alba (white mustard or yellow mustard), Brassica juncea (brown mustard) and Brassica nigra (black mustard) in the food and beverage industry is immensely growing due to their nutritional and functional properties. The seeds serve as a source for a wide range of biologically active components including isothiocyanates that are responsible for the specific flavor of mustard, and tend to reveal conflicting results regarding possible health effects. Other potentially undesirable or toxic compounds, such as bisphenol F, erucic acid or allergens, may also occur in the seeds and in mustard products intended for human consumption. The aim of this article is to provide comprehensive information about potentially harmful compounds in mustard seeds and to evaluate potential health risks as an increasing use of mustard seeds is expected in the upcoming years.},
  pmcid = {PMC8472142},
  pmid = {34574199},
  keywords = {mustard},
  file = {/Users/charliejhadley/Zotero/storage/6EKL9584/Lietzow - 2021 - Biologically Active Compounds in Mustard Seeds A .pdf}
}

@article{lu_modeling_2022,
  title = {Modeling {{Just Noticeable Differences}} in {{Charts}}},
  author = {Lu, Min and Lanir, Joel and Wang, Chufeng and Yao, Yucong and Zhang, Wen and Deussen, Oliver and Huang, Hui},
  year = {2022},
  month = jan,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {28},
  number = {1},
  pages = {718--726},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2021.3114874},
  abstract = {One of the fundamental tasks in visualization is to compare two or more visual elements. However, it is often difficult to visually differentiate graphical elements encoding a small difference in value, such as the heights of similar bars in bar chart or angles of similar sections in pie chart. Perceptual laws can be used in order to model when and how we perceive this difference. In this work, we model the perception of Just Noticeable Differences (JNDs), the minimum difference in visual attributes that allow faithfully comparing similar elements, in charts. Specifically, we explore the relation between JNDs and two major visual variables: the intensity of visual elements and the distance between them, and study it in three charts: bar chart, pie chart and bubble chart. Through an empirical study, we identify main effects on JND for distance in bar charts, intensity in pie charts, and both distance and intensity in bubble charts. By fitting a linear mixed effects model, we model JND and find that JND grows as the exponential function of variables. We highlight several usage scenarios that make use of the JND modeling in which elements below the fitted JND are detected and enhanced with secondary visual cues for better discrimination.},
  keywords = {Bars,Charts,Computational modeling,Correlation,Fans,Just noticeable difference,Modeling,Task analysis,Three-dimensional displays,Visual perception,Visualization},
  file = {/Users/charliejhadley/Zotero/storage/HP74VU8U/Lu et al. - 2022 - Modeling Just Noticeable Differences in Charts.pdf;/Users/charliejhadley/Zotero/storage/28UHE5PJ/9552881.html}
}

@inproceedings{machanavajjhala_l-diversity_2006,
  title = {L-Diversity: Privacy beyond k-Anonymity},
  shorttitle = {L-Diversity},
  booktitle = {22nd {{International Conference}} on {{Data Engineering}} ({{ICDE}}'06)},
  author = {Machanavajjhala, A. and Gehrke, J. and Kifer, D. and Venkitasubramaniam, M.},
  year = {2006},
  month = apr,
  pages = {24--24},
  issn = {2375-026X},
  doi = {10.1109/ICDE.2006.1},
  abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called \textbackslash kappa-anonymity has gained popularity. In a \textbackslash kappa-anonymized dataset, each record is indistinguishable from at least k\textemdash 1 other records with respect to certain "identifying" attributes. In this paper we show with two simple attacks that a \textbackslash kappa-anonymized dataset has some subtle, but severe privacy problems. First, we show that an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. Second, attackers often have background knowledge, and we show that \textbackslash kappa-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks and we propose a novel and powerful privacy definition called \textbackslash ell-diversity. In addition to building a formal foundation for \textbackslash ell-diversity, we show in an experimental evaluation that \textbackslash ell-diversity is practical and can be implemented efficiently.},
  keywords = {Cardiac disease,Computer science,Data privacy,Information analysis,Information resources,Insurance,Joining processes,Medical conditions,Medical diagnostic imaging,Publishing},
  file = {/Users/charliejhadley/Zotero/storage/NN8CT3Y2/Machanavajjhala et al. - 2006 - L-diversity privacy beyond k-anonymity.pdf;/Users/charliejhadley/Zotero/storage/K3ZHSTXU/1617392.html}
}

@article{mackinlay_automating_1986,
  title = {Automating the Design of Graphical Presentations of Relational Information},
  author = {Mackinlay, Jock},
  year = {1986},
  month = apr,
  journal = {ACM Transactions on Graphics},
  volume = {5},
  number = {2},
  pages = {110--141},
  issn = {0730-0301},
  doi = {10.1145/22949.22950},
  abstract = {The goal of the research described in this paper is to develop an application-independent presentation tool that automatically designs effective graphical presentations (such as bar charts, scatter plots, and connected graphs) of relational information. Two problems are raised by this goal: The codification of graphic design criteria in a form that can be used by the presentation tool, and the generation of a wide variety of designs so that the presentation tool can accommodate a wide variety of information. The approach described in this paper is based on the view that graphical presentations are sentences of graphical languages. The graphic design issues are codified as expressiveness and effectiveness criteria for graphical languages. Expressiveness criteria determine whether a graphical language can express the desired information. Effectiveness criteria determine whether a graphical language exploits the capabilities of the output medium and the human visual system. A wide variety of designs can be systematically generated by using a composition algebra that composes a small set of primitive graphical languages. Artificial intelligence techniques are used to implement a prototype presentation tool called APT (A Presentation Tool), which is based on the composition algebra and the graphic design criteria.},
  file = {/Users/charliejhadley/Zotero/storage/RAXV876Z/Mackinlay - 1986 - Automating the design of graphical presentations o.pdf}
}

@article{mackinlay_automating_1986-1,
  title = {Automating the Design of Graphical Presentations of Relational Information},
  author = {Mackinlay, Jock},
  year = {1986},
  month = apr,
  journal = {ACM Transactions on Graphics},
  volume = {5},
  number = {2},
  pages = {110--141},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/22949.22950},
  abstract = {The goal of the research described in this paper is to develop an application-independent presentation tool that automatically designs effective graphical presentations (such as bar charts, scatter plots, and connected graphs) of relational information. Two problems are raised by this goal: The codification of graphic design criteria in a form that can be used by the presentation tool, and the generation of a wide variety of designs so that the presentation tool can accommodate a wide variety of information. The approach described in this paper is based on the view that graphical presentations are sentences of graphical languages. The graphic design issues are codified as expressiveness and effectiveness criteria for graphical languages. Expressiveness criteria determine whether a graphical language can express the desired information. Effectiveness criteria determine whether a graphical language exploits the capabilities of the output medium and the human visual system. A wide variety of designs can be systematically generated by using a composition algebra that composes a small set of primitive graphical languages. Artificial intelligence techniques are used to implement a prototype presentation tool called APT (A Presentation Tool), which is based on the composition algebra and the graphic design criteria.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/YEBUM7HD/Mackinlay - 1986 - Automating the design of graphical presentations o.pdf}
}

@article{mackinlay_automating_nodate,
  title = {Automating the {{Design}} of {{Graphical Presentations}} of {{Relational Information}}},
  author = {Mackinlay, Jock},
  journal = {ACM Transactions on Graphics},
  volume = {5},
  number = {2},
  pages = {32},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/XFMWKM2Z/Mackinlay - Automating the Design of Graphical Presentations o.pdf}
}

@misc{maeda_design_2019,
  title = {Design in {{Tech Report}} 2019 | {{Section}} 6 | {{Addressing Imbalance}}},
  author = {Maeda, John},
  year = {2019},
  month = mar,
  journal = {John Maeda | Design in Tech Report},
  abstract = {Once we recognize exclusion from a historical perspective and a technological lens, what can we do about addressing it? Signup for the latest briefing The best time to get started is right now. Kat\ldots},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/33AV3KVD/design-in-tech-report-2019-section-6-addressing-imbalance.html}
}

@misc{maeda_presentation_2019,
  title = {Presentation: {{Design}} in {{Tech Report}} 2019},
  author = {Maeda, John},
  year = {2019},
  journal = {Design in Tech},
  howpublished = {https://designintech.report/wp-content/uploads/2019/03/dit2019\_v00.pdf}
}

@inproceedings{matejka_same_2017,
  title = {Same {{Stats}}, {{Different Graphs}}: {{Generating Datasets}} with {{Varied Appearance}} and {{Identical Statistics}} through {{Simulated Annealing}}},
  shorttitle = {Same {{Stats}}, {{Different Graphs}}},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Matejka, Justin and Fitzmaurice, George},
  year = {2017},
  month = may,
  series = {{{CHI}} '17},
  pages = {1290--1294},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3025453.3025912},
  abstract = {Datasets which are identical over a number of statistical properties, yet produce dissimilar graphs, are frequently used to illustrate the importance of graphical representations when exploring data. This paper presents a novel method for generating such datasets, along with several examples. Our technique varies from previous approaches in that new datasets are iteratively generated from a seed dataset through random perturbations of individual data points, and can be directed towards a desired outcome through a simulated annealing optimization strategy. Our method has the benefit of being agnostic to the particular statistical properties that are to remain constant between the datasets, and allows for control over the graphical appearance of resulting output.},
  isbn = {978-1-4503-4655-9},
  keywords = {anscombe,scatter plots,visualization}
}

@misc{matloff_teaching_2022,
  title = {Teaching {{R}} in a {{Kinder}}, {{Gentler}}, {{More Effective Manner}}:},
  shorttitle = {Teaching {{R}} in a {{Kinder}}, {{Gentler}}, {{More Effective Manner}}},
  author = {Matloff, Norm},
  year = {2022},
  month = aug,
  abstract = {An opinionated view of the Tidyverse "dialect" of the R language.},
  howpublished = {https://github.com/matloff/TidyverseSkeptic},
  keywords = {anti-tidyverse}
}

@misc{mattu_how_2016,
  title = {How {{We Analyzed}} the {{COMPAS Recidivism Algorithm}}},
  author = {Mattu, Julia Angwin,Lauren Kirchner,Surya, Jeff Larson},
  year = {2016},
  month = may,
  journal = {ProPublica},
  abstract = {ProPublica is an independent, non-profit newsroom that produces investigative journalism in the public interest.},
  howpublished = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/BKME6EX3/how-we-analyzed-the-compas-recidivism-algorithm.html}
}

@misc{mattu_machine_2016,
  title = {Machine {{Bias}}},
  author = {Mattu, Jeff Larson,Lauren Kirchner,Surya, Julia Angwin},
  year = {2016},
  month = may,
  journal = {ProPublica},
  abstract = {There's software used across the country to predict future criminals. And it's biased against blacks.},
  howpublished = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/6NCP9RDF/machine-bias-risk-assessments-in-criminal-sentencing.html}
}

@article{maxmen_self-driving_2018,
  title = {Self-Driving Car Dilemmas Reveal That Moral Choices Are Not Universal},
  author = {Maxmen, Amy},
  year = {2018},
  month = oct,
  journal = {Nature},
  volume = {562},
  number = {7728},
  pages = {469--470},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/d41586-018-07135-0},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/LJIJ3UE9/Maxmen - 2018 - Self-driving car dilemmas reveal that moral choice.pdf}
}

@patent{mikolov_computing_2015,
  title = {Computing Numeric Representations of Words in a High-Dimensional Space},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Gregory S. and Dean, Jeffrey A.},
  year = {2015},
  month = may,
  number = {US9037464~(B1)},
  abstract = {Methods, systems, and apparatus, including computer programs encoded on computer storage media, for computing numeric representations of words. One of the methods includes obtaining a set of training data, wherein the set of training data comprises sequences of words; training a classifier and an embedding function on the set of training data, wherein training the embedding function comprises obtained trained values of the embedding function parameters; processing each word in the vocabulary using the embedding function in accordance with the trained values of the embedding function parameters to generate a respective numerical representation of each word in the vocabulary in the high-dimensional space; and associating each word in the vocabulary with the respective numeric representation of the word in the high-dimensional space.},
  assignee = {Google Inc}
}

@misc{mikolov_distributed_2013,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = oct,
  number = {arXiv:1310.4546},
  eprint = {1310.4546},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1310.4546},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/charliejhadley/Zotero/storage/D33YD446/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf;/Users/charliejhadley/Zotero/storage/6BUBZHJI/1310.html}
}

@misc{mikolov_efficient_2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  number = {arXiv:1301.3781},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1301.3781},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/charliejhadley/Zotero/storage/V74SGJ7C/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;/Users/charliejhadley/Zotero/storage/MIGDVR6X/1301.html}
}

@misc{mit_media_lab_gender_2018,
  title = {Gender {{Shades}}},
  author = {{MIT Media Lab}},
  year = {2018},
  month = feb,
  abstract = {Creative Commons Attribution licence (reuse allowed)}
}

@article{mlinaric_dealing_2017,
  title = {Dealing with the Positive Publication Bias: {{Why}} You Should Really Publish Your Negative Results},
  shorttitle = {Dealing with the Positive Publication Bias},
  author = {Mlinari{\'c}, Ana and Horvat, Martina and {\v S}upak Smol{\v c}i{\'c}, Vesna},
  year = {2017},
  month = oct,
  journal = {Biochemia Medica},
  volume = {27},
  number = {3},
  pages = {030201},
  issn = {1330-0962},
  doi = {10.11613/BM.2017.030201},
  abstract = {Studies with positive results are greatly more represented in literature than studies with negative results, producing so-called publication bias. This review aims to discuss occurring problems around negative results and to emphasize the importance of reporting negative results. Underreporting of negative results introduces bias into meta-analysis, which consequently misinforms researchers, doctors and policymakers. More resources are potentially wasted on already disputed research that remains unpublished and therefore unavailable to the scientific community. Ethical obligations need to be considered when reporting results of studies on human subjects as people have exposed themselves to risk with the assurance that the study is performed to benefit others. Some studies disprove the common conception that journal editors preferably publish positive findings, which are considered as more citable. Therefore, all stakeholders, but especially researchers, need to be conscious of disseminating negative and positive findings alike.},
  pmcid = {PMC5696751},
  pmid = {29180912},
  keywords = {negative results},
  file = {/Users/charliejhadley/Zotero/storage/LZG4MDD6/Mlinarić et al. - 2017 - Dealing with the positive publication bias Why yo.pdf}
}

@article{monk_unceasing_2021,
  title = {The {{Unceasing Significance}} of {{Colorism}}: {{Skin Tone Stratification}} in the {{United States}}},
  shorttitle = {The {{Unceasing Significance}} of {{Colorism}}},
  author = {Monk, Jr., Ellis P.},
  year = {2021},
  month = jan,
  journal = {Daedalus},
  volume = {150},
  number = {2},
  pages = {76--90},
  issn = {0011-5266},
  doi = {10.1162/daed_a_01847},
  abstract = {For many decades now, social scientists have documented immense ethnoracial inequalities in the United States. Much of this work is rooted in comparing the life chances, trajectories, and outcomes of African Americans to White Americans. From health to wealth and nearly every measure of well-being, success, and thriving one can find, White Americans remain ahead of Black Americans. What this focus on ethnoracial inequality between ``groups'' obscures, however, is long-standing skin tone inequality within groups. In this essay, I trace the trajectory of colorism and skin tone stratification in the United States over the past century. Next, I high-light the contemporary persistence of skin tone stratification, not only among African Americans, but among Latinx and Asian Americans as well. I conclude by arguing that future research on colorism will be essential to understand comprehensively the significance of race/ethnicity in a demographically shifting United States (such as immigration and ``multiraciality'').},
  file = {/Users/charliejhadley/Zotero/storage/LALP7SZ6/Monk - 2021 - The Unceasing Significance of Colorism Skin Tone .pdf;/Users/charliejhadley/Zotero/storage/J52HXYL3/The-Unceasing-Significance-of-Colorism-Skin-Tone.html}
}

@article{monk_unceasing_2021-1,
  title = {The {{Unceasing Significance}} of {{Colorism}}: {{Skin Tone Stratification}} in the {{United States}}},
  shorttitle = {The {{Unceasing Significance}} of {{Colorism}}},
  author = {Monk, Ellis P.},
  year = {2021},
  month = jan,
  journal = {Daedalus},
  volume = {150},
  number = {2},
  pages = {76--90},
  issn = {0011-5266, 1548-6192},
  doi = {10.1162/daed_a_01847},
  abstract = {Abstract             For many decades now, social scientists have documented immense ethnoracial inequalities in the United States. Much of this work is rooted in comparing the life chances, trajectories, and outcomes of African Americans to White Americans. From health to wealth and nearly every measure of well-being, success, and thriving one can find, White Americans remain ahead of Black Americans. What this focus on ethnoracial inequality between ``groups'' obscures, however, is long-standing skin tone inequality within groups. In this essay, I trace the trajectory of colorism and skin tone stratification in the United States over the past century. Next, I high-light the contemporary persistence of skin tone stratification, not only among African Americans, but among Latinx and Asian Americans as well. I conclude by arguing that future research on colorism will be essential to understand comprehensively the significance of race/ethnicity in a demographically shifting United States (such as immigration and ``multiraciality'').},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/9JPSIHYX/Monk - 2021 - The Unceasing Significance of Colorism Skin Tone .pdf}
}

@misc{mrc_mrc_2022,
  title = {{{MRC Open Research Data Advice}}},
  author = {{MRC}},
  year = {2022},
  month = aug,
  abstract = {MRC strongly promotes the principles of open research data and aims to make the research process and findings as open, understandable and reproducible as possible. Sharing data can enhance the use of existing data, avoid duplication of research effort and stimulate new discoveries.},
  howpublished = {https://www.ukri.org/about-us/mrc/our-policies-and-standards/research/open-research-data-clinical-trials-and-public-health-interventions/},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/EQYFSQWI/open-research-data-clinical-trials-and-public-health-interventions.html}
}

@misc{narayanan_how_2006,
  title = {How {{To Break Anonymity}} of the {{Netflix Prize Dataset}}},
  author = {Narayanan, Arvind and Shmatikov, Vitaly},
  year = {2006},
  month = oct,
  number = {arXiv:cs/0610105},
  eprint = {cs/0610105},
  eprinttype = {arxiv},
  publisher = {{arXiv}},
  doi = {https://arxiv.org/abs/cs/0610105v1},
  abstract = {We present a new class of statistical de-anonymization attacks against high-dimensional micro-data, such as individual preferences, recommendations, transaction records and so on. Our techniques are robust to perturbation in the data and tolerate some mistakes in the adversary's background knowledge. We apply our de-anonymization methodology to the Netflix Prize dataset, which contains anonymous movie ratings of 500,000 subscribers of Netflix, the world's largest online movie rental service. We demonstrate that an adversary who knows only a little bit about an individual subscriber can easily identify this subscriber's record in the dataset. Using the Internet Movie Database as the source of background knowledge, we successfully identified the Netflix records of known users, uncovering their apparent political preferences and other potentially sensitive information.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Databases},
  file = {/Users/charliejhadley/Zotero/storage/KDHAECCQ/Narayanan and Shmatikov - 2006 - How To Break Anonymity of the Netflix Prize Datase.pdf;/Users/charliejhadley/Zotero/storage/HI4RTYPC/0610105.html}
}

@misc{narayanan_how_2007,
  title = {How {{To Break Anonymity}} of the {{Netflix Prize Dataset}}},
  author = {Narayanan, Arvind and Shmatikov, Vitaly},
  year = {2007},
  month = nov,
  number = {arXiv:cs/0610105},
  eprint = {cs/0610105},
  eprinttype = {arxiv},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.cs/0610105},
  abstract = {We present a new class of statistical de-anonymization attacks against high-dimensional micro-data, such as individual preferences, recommendations, transaction records and so on. Our techniques are robust to perturbation in the data and tolerate some mistakes in the adversary's background knowledge. We apply our de-anonymization methodology to the Netflix Prize dataset, which contains anonymous movie ratings of 500,000 subscribers of Netflix, the world's largest online movie rental service. We demonstrate that an adversary who knows only a little bit about an individual subscriber can easily identify this subscriber's record in the dataset. Using the Internet Movie Database as the source of background knowledge, we successfully identified the Netflix records of known users, uncovering their apparent political preferences and other potentially sensitive information.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Databases},
  file = {/Users/charliejhadley/Zotero/storage/KANYCEL3/Narayanan and Shmatikov - 2007 - How To Break Anonymity of the Netflix Prize Datase.pdf;/Users/charliejhadley/Zotero/storage/WJXH35X9/0610105.html}
}

@misc{narayanan_how_2007-1,
  title = {"{{How}} to {{Break Anonymity}} of the {{Netflix Prize Dataset}}" - {{FAQ}}},
  author = {Narayanan, Arvind and Schmatikov, Vitaly},
  year = {2007},
  month = nov,
  howpublished = {https://www.cs.utexas.edu/\textasciitilde shmat/netflix-faq.html},
  file = {/Users/charliejhadley/Zotero/storage/RWJ4MUDU/netflix-faq.html}
}

@inproceedings{narayanan_robust_2008,
  title = {Robust {{De-anonymization}} of {{Large Sparse Datasets}}},
  booktitle = {2008 {{IEEE Symposium}} on {{Security}} and {{Privacy}} (Sp 2008)},
  author = {Narayanan, Arvind and Shmatikov, Vitaly},
  year = {2008},
  month = may,
  pages = {111--125},
  issn = {2375-1207},
  doi = {10.1109/SP.2008.33},
  abstract = {We present a new class of statistical de- anonymization attacks against high-dimensional micro-data, such as individual preferences, recommendations, transaction records and so on. Our techniques are robust to perturbation in the data and tolerate some mistakes in the adversary's background knowledge. We apply our de-anonymization methodology to the Netflix Prize dataset, which contains anonymous movie ratings of 500,000 subscribers of Netflix, the world's largest online movie rental service. We demonstrate that an adversary who knows only a little bit about an individual subscriber can easily identify this subscriber's record in the dataset. Using the Internet Movie Database as the source of background knowledge, we successfully identified the Netflix records of known users, uncovering their apparent political preferences and other potentially sensitive information.},
  keywords = {Anonymity,Attack,Data mining,Data privacy,Data security,DVD,Internet,Motion pictures,Privacy,Probability,Robustness,Tail,Transaction databases},
  file = {/Users/charliejhadley/Zotero/storage/7ZJ8AXWJ/Narayanan and Shmatikov - 2008 - Robust De-anonymization of Large Sparse Datasets.pdf;/Users/charliejhadley/Zotero/storage/8I7LIUGZ/4531148.html}
}

@article{nast_how_nodate,
  title = {How to Bypass and Block Infuriating Cookie Popups},
  author = {Nast, Cond{\'e}},
  journal = {Wired UK},
  issn = {1357-0978},
  abstract = {Cookie consent popups are everywhere and opting out of tracking is a pain. It doesn't have to be this way},
  chapter = {tags},
  langid = {british},
  keywords = {cookies,data,policy,politics,regulation},
  file = {/Users/charliejhadley/Zotero/storage/A9EE4QNX/cookie-popup-blocker-gdpr.html}
}

@misc{national_transport_safety_board_collision_2018,
  title = {Collision {{Between Vehicle Controlled}} by {{Developmental Automated Driving System}} and {{Pedestrian}}, {{Tempe}}, {{Arizona}}, {{March}} 18, 2018},
  author = {{National Transport Safety Board}},
  year = {2018},
  month = mar,
  publisher = {{National Transport Safety Board}},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/8KSPLJQT/Plaza - Collision Between Vehicle Controlled by Developmen.pdf}
}

@misc{nature_data_2022,
  title = {Data {{Repository Guidance}} | {{Scientific Data}}},
  author = {{Nature}},
  year = {2022},
  issn = {2052-4463},
  abstract = {Data Repository Guidance},
  copyright = {\textcopyright 2022 Macmillan Publishers Limited. All Rights Reserved.},
  howpublished = {https://www.nature.com/sdata/policies/repositories},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/RYIAJZEL/repositories.html}
}

@misc{nerc_nerc_2022,
  title = {{{NERC Data Policy}}},
  author = {{NERC}},
  year = {2022},
  month = aug,
  journal = {NERC Data Policy},
  howpublished = {https://www.ukri.org/wp-content/uploads/2022/03/NERC-080322-policy-data-021219.pdf}
}

@misc{nhs_england_writing_2018,
  title = {Writing an Effective Questionnaire},
  author = {{NHS England}},
  year = {2018},
  month = jan,
  publisher = {{NHS England}},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/4F8YQPMQ/NHS England - 2018 - Writing an effective questionnaire.pdf}
}

@book{nightingale_notes_1858,
  title = {Notes on {{Matters Affecting}} the {{Health}}, {{Efficiency}} and {{Hospital Administration}} of the {{British Army}}},
  author = {Nightingale, Florence},
  year = {1858},
  month = nov,
  publisher = {{Harrison \& Sons}},
  address = {{London}},
  annotation = {https://www.rct.uk/collection/1075240/notes-on-matters-affecting-the-health-efficiency-and-hospital-administration-of}
}

@article{noauthor_anonymisation_nodate,
  title = {Anonymisation: Managing Data Protection Risk Code of Practice},
  pages = {108},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/T5IGPJ3H/Anonymisation managing data protection risk code .pdf}
}

@misc{noauthor_cdc_2021,
  title = {{{CDC}} - {{BRFSS Annual Survey Data}}},
  year = {2021},
  month = aug,
  abstract = {BRFSS has a long history in behavioral and chronic disease surveillance. Fifteen states participated in the first BRFSS, conducted in 1984.},
  howpublished = {https://www.cdc.gov/brfss/annual\_data/annual\_data.htm},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/CEIR6ID9/annual_data.html}
}

@misc{noauthor_consumer_nodate-1,
  title = {{{CONSUMER Privacy}} - {{Quividi}} - {{Insightful}} Data with Fully Anonymous Measurements.},
  journal = {Quividi},
  abstract = {We believe in consumer privacy. We do not record any personal image. We do not follow people around. Ever.},
  howpublished = {https://quividi.com/privacy/},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/G5RL9RML/privacy.html}
}

@misc{noauthor_cookies_2019,
  title = {Cookies, the {{GDPR}}, and the {{ePrivacy Directive}}},
  year = {2019},
  month = may,
  journal = {GDPR.eu},
  abstract = {Cookies can give businesses insight into their users' online activity. Unforunately they are subject to both the GDPR and the ePrivacy Directive, making compliance difficult.},
  chapter = {GDPR Compliance},
  howpublished = {https://gdpr.eu/cookies/},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/K9YJVZIR/cookies.html}
}

@misc{noauthor_data_2020,
  title = {{{DATA}} in the Time of {{COVID-19}}},
  year = {2020},
  month = nov,
  journal = {Open Data Watch},
  abstract = {The largest collection of links to COVID-19 datasets, dashboards, visualizations, and articles on how understand and use open data to fight the spread of the coronavirus pandemic.},
  chapter = {What's Being Said Resource},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/ELWX32ZA/data-in-the-time-of-covid-19.html}
}

@misc{noauthor_espacenet_nodate,
  title = {Espacenet \textendash{} Search Results},
  howpublished = {https://worldwide.espacenet.com/patent/search/family/053054725/publication/US9037464B1?q=pn\%3DUS9037464},
  file = {/Users/charliejhadley/Zotero/storage/YG97PCRL/US9037464B1.html}
}

@misc{noauthor_espacenet_nodate-1,
  title = {Espacenet \textendash{} Search Results},
  howpublished = {https://worldwide.espacenet.com/patent/search/family/053054725/publication/US9037464B1?q=pn\%3DUS9037464B1},
  file = {/Users/charliejhadley/Zotero/storage/TINTMBMA/US9037464B1.html}
}

@misc{noauthor_fairness_nodate,
  title = {Fairness and {{Abstraction}} in {{Sociotechnical Systems}} | {{Proceedings}} of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  howpublished = {https://dl.acm.org/doi/10.1145/3287560.3287598},
  file = {/Users/charliejhadley/Zotero/storage/H8HZBIAV/Fairness and Abstraction in Sociotechnical Systems.pdf;/Users/charliejhadley/Zotero/storage/AV4L5RKW/3287560.html}
}

@misc{noauthor_madhumita_nodate,
  title = {Madhumita {{Venkataramanan}}: {{My}} Identity for Sale | {{WIRED UK}}},
  howpublished = {https://www.wired.co.uk/article/my-identity-for-sale},
  file = {/Users/charliejhadley/Zotero/storage/UAZC8H3D/my-identity-for-sale.html}
}

@misc{noauthor_measuring_nodate,
  title = {Measuring the {{Impact}} of the {{GDPR}} on {{Data Sharing}} in {{Ad Networks}} | {{Proceedings}} of the 15th {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  howpublished = {https://dl.acm.org/doi/10.1145/3320269.3372194},
  file = {/Users/charliejhadley/Zotero/storage/42PX4A4A/3320269.html}
}

@techreport{noauthor_notitle_nodate,
  type = {Techreport}
}

@book{noauthor_notitle_nodate-1,
  type = {Book}
}

@misc{noauthor_open_2022,
  title = {The {{Open Definition}} - {{Open Definition}} - {{Defining Open}} in {{Open Data}}, {{Open Content}} and {{Open Knowledge}}},
  year = {2022},
  month = aug,
  howpublished = {http://opendefinition.org/},
  file = {/Users/charliejhadley/Zotero/storage/3D8NVR9Y/opendefinition.org.html}
}

@misc{noauthor_recommendations_2022,
  title = {Recommendations for the {{Conduct}}, {{Reporting}}, {{Editing}}, and {{Publication}} of {{Scholarly}} Work in {{Medical Journals}} ({{ICMJE}})},
  year = {2022},
  howpublished = {https://www.icmje.org/icmje-recommendations.pdf},
  langid = {english}
}

@misc{noauthor_rstudioconf2022_nodate,
  title = {Rstudio::Conf(2022) {{Schedule}}},
  shorttitle = {Rstudio},
  abstract = {All things R and RStudio},
  howpublished = {https://www.rstudio.com/conference/2022/schedule/},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/WQPW8ULR/schedule.html}
}

@misc{noauthor_rules_nodate,
  title = {Rules of Evidence for Cancer Molecular-Marker Discovery and Validation | {{Nature Reviews Cancer}}},
  howpublished = {https://www.nature.com/articles/nrc1322},
  file = {/Users/charliejhadley/Zotero/storage/6YT5X3ZI/nrc1322.html}
}

@misc{noauthor_welcome_nodate,
  title = {Welcome | {{R}} for {{Data Science}}},
  howpublished = {https://r4ds.had.co.nz/},
  file = {/Users/charliejhadley/Zotero/storage/Z8LJ85FM/r4ds.had.co.nz.html}
}

@article{nosek_preregistration_2018,
  title = {The Preregistration Revolution},
  author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
  year = {2018},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {11},
  pages = {2600--2606},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1708274114},
  keywords = {pre-registration},
  file = {/Users/charliejhadley/Zotero/storage/TJAIFVP5/Nosek et al. - 2018 - The preregistration revolution.pdf}
}

@incollection{nyckel_ahead_2021,
  title = {Ahead of {{Time}}: {{The Infrastructure}} of {{Amazon}}'s {{Anticipatory Shipping Method}}},
  shorttitle = {Ahead of {{Time}}},
  booktitle = {Media {{Infrastructures}} and the {{Politics}} of {{Digital Time}}},
  author = {Nyckel, Eva-Maria},
  editor = {Volmar, Axel and Stine, Kyle},
  year = {2021},
  series = {Essays on {{Hardwired Temporalities}}},
  pages = {263--278},
  publisher = {{Amsterdam University Press}},
  doi = {10.2307/j.ctv1xcxr3n.18},
  abstract = {In the industry of logistics, time is perhaps the most crucial resource not to be wasted. A variety of reference parameters are dedicated to measuring time in logistical processes, with names such as lead time, shipping time, and cycle time, as well as time bucket, time fence, time to market, and time of circulation. Reducing shipping latencies, providing real-time tracking of commodities, and forecasting consumer demand are elementary to structuring temporal relations between customers, carriers, and merchants. Yet even within this context, Amazon's 2013 patent for a ``Method and System for Anticipatory Package Shipping'' marks a decisive shift in the},
  file = {/Users/charliejhadley/Zotero/storage/IQ8YF3J5/Nyckel - 2021 - Ahead of Time The Infrastructure of Amazon’s Anti.pdf}
}

@article{nyhan_roles_2019,
  title = {The Roles of Information Deficits and Identity Threat in the Prevalence of Misperceptions},
  author = {Nyhan, Brendan and Reifler, Jason},
  year = {2019},
  month = apr,
  journal = {Journal of Elections, Public Opinion and Parties},
  volume = {29},
  number = {2},
  pages = {222--244},
  publisher = {{Routledge}},
  issn = {1745-7289},
  doi = {10.1080/17457289.2018.1465061},
  abstract = {Why do so many Americans hold misperceptions? We examine two factors that contribute to the prevalence of these beliefs. First, presenting correct information should reduce misperceptions, especially if provided in a clear and compelling format. We therefore test the effect of graphical information, which may be especially effective in facilitating belief updating about changes in quantities over time. In some cases, though, people may reject information because it threatens their worldview or self-concept \textendash{} a mechanism that can be revealed by affirming individuals' self-worth, which could make them more willing to acknowledge uncomfortable facts. We test both mechanisms jointly. In three experiments, we find that providing information in graphical form reduces misperceptions. A third study shows that this effect is greater than for equivalent textual information. Our findings for self-affirmation are more equivocal. We find limited evidence that self-affirmation can help diminish misperceptions when no other information is provided, but it does not consistently increase willingness to accept corrective information as previous research in social psychology would suggest. These results suggest that misperceptions are caused by a lack of information as well as psychological threat, but that these factors may interact in ways that are not yet well understood.},
  annotation = {\_eprint: https://doi.org/10.1080/17457289.2018.1465061},
  file = {/Users/charliejhadley/Zotero/storage/9ZF23ZXX/Nyhan and Reifler - 2019 - The roles of information deficits and identity thr.pdf}
}

@article{open_science_collaboration_estimating_2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{OPEN SCIENCE COLLABORATION}},
  year = {2015},
  month = aug,
  journal = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aac4716},
  keywords = {reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/IQKE26JW/OPEN SCIENCE COLLABORATION - 2015 - Estimating the reproducibility of psychological sc.pdf}
}

@article{palanisamy_privacy-preserving_2018,
  title = {Privacy-{{Preserving Publishing}} of {{Multilevel Utility-Controlled Graph Datasets}}},
  author = {Palanisamy, Balaji and Liu, Ling and Zhou, Yang and Wang, Qingyang},
  year = {2018},
  month = mar,
  journal = {ACM Transactions on Internet Technology},
  volume = {18},
  number = {2},
  pages = {1--21},
  issn = {1533-5399, 1557-6051},
  doi = {10.1145/3125622},
  abstract = {Conventional private data publication schemes are targeted at publication of sensitive datasets either after the               k               -anonymization process or through differential privacy constraints. Typically these schemes are designed with the objective of retaining as much utility as possible for the aggregate queries while ensuring the privacy of the individual records. Such an approach, though suitable for publishing aggregate information as public datasets, is inapplicable when users have different levels of access to the same data. We argue that existing schemes either result in increased disclosure of private information or lead to reduced utility when some users have more access privileges than the others. In this article, we present an anonymization framework for publishing large datasets with the goals of providing different levels of utility to the users based on their access privilege levels. We design and implement our proposed multilevel utility-controlled anonymization schemes in the context of large association graphs considering three levels of user utility, namely, (1) users having access to only the graph structure, (2) users having access to the graph structure and aggregate query results, and (3) users having access to the graph structure, aggregate query results, and individual associations. Our experiments on real large association graphs show that the proposed techniques are effective and scalable and yield the required level of privacy and utility for each user privacy and access privilege level.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/ISBSLM22/Palanisamy et al. - 2018 - Privacy-Preserving Publishing of Multilevel Utilit.pdf}
}

@article{palanisamy_privacy-preserving_2018-1,
  title = {Privacy-{{Preserving Publishing}} of {{Multilevel Utility-Controlled Graph Datasets}}},
  author = {Palanisamy, Balaji and Liu, Ling and Zhou, Yang and Wang, Qingyang},
  year = {2018},
  month = mar,
  journal = {ACM Transactions on Internet Technology},
  volume = {18},
  number = {2},
  pages = {1--21},
  issn = {1533-5399, 1557-6051},
  doi = {10.1145/3125622},
  abstract = {Conventional private data publication schemes are targeted at publication of sensitive datasets either after the               k               -anonymization process or through differential privacy constraints. Typically these schemes are designed with the objective of retaining as much utility as possible for the aggregate queries while ensuring the privacy of the individual records. Such an approach, though suitable for publishing aggregate information as public datasets, is inapplicable when users have different levels of access to the same data. We argue that existing schemes either result in increased disclosure of private information or lead to reduced utility when some users have more access privileges than the others. In this article, we present an anonymization framework for publishing large datasets with the goals of providing different levels of utility to the users based on their access privilege levels. We design and implement our proposed multilevel utility-controlled anonymization schemes in the context of large association graphs considering three levels of user utility, namely, (1) users having access to only the graph structure, (2) users having access to the graph structure and aggregate query results, and (3) users having access to the graph structure, aggregate query results, and individual associations. Our experiments on real large association graphs show that the proposed techniques are effective and scalable and yield the required level of privacy and utility for each user privacy and access privilege level.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/RA5VW7XR/Palanisamy et al. - 2018 - Privacy-Preserving Publishing of Multilevel Utilit.pdf}
}

@misc{pat_schloss_recreating_2022,
  title = {Recreating Animated Climate Temperature Spirals in {{R}} with Ggplot2 and Gganimate ({{CC219}})},
  author = {{Pat Schloss}},
  year = {2022},
  month = jun,
  abstract = {Creative Commons Attribution licence (reuse allowed)}
}

@article{perdana_does_2018,
  title = {Does {{Visualization Matter}}? {{The Role}} of {{Interactive Data Visualization}} to {{Make Sense}} of {{Information}}},
  shorttitle = {Does {{Visualization Matter}}?},
  author = {Perdana, Arif and Robb, Alastair and Rohde, Fiona},
  year = {2018},
  month = may,
  journal = {Australasian Journal of Information Systems},
  volume = {22},
  publisher = {{Australian Computer Society}},
  issn = {1449-8618},
  doi = {10.3127/ajis.v22i0.1681},
  abstract = {As part of business analytics (BA) technologies, reporting and visualization play essential roles in mitigating users' limitations (i.e., being inexperienced, having limited knowledge, and relying on simplified information). Reporting and visualization can potentially enhance users' sense-making, thus permitting them to focus more on the information's message rather than numerical analysis. To better understand the role of reporting and visualization in a contextualized environment, we investigate using interactive data visualization (IDV) within accounting. We aim to understand whether IDV can help enhance non-professional investors' ability to make sense of foundational financial statement analyses. This study conducted an experiment using a sample of 324 nonprofessional investors. Our findings indicate that nonprofessional investors who use IDV are more heuristically adept than non-professional investors who use non-IDV. These findings enrich the theoretical understanding of business analytics' use in accounting decision making. The results of this study also suggest several practical courses of action, such as promoting wider use of IDV and making affordable IDV more broadly available, particularly for non-professional investors.},
  copyright = {Copyright (c) 2018 Arif Perdana, Alastair Robb, Fiona Rohde},
  langid = {english},
  keywords = {AAIS,ACPHIS,ACS,ACS Digital Library,AJIS,Australasian Association for Information Systems,Australia,Australian Computer Society,Australian Council of Professors and Heads of Information Systems,computers,governance,Human computer interaction,ICT,information processing,Information Systems,interactive dataviz improves comprehension,IS,IT,management,New Zealand,PHISNZ,Professors and Heads of Information Systems New Zealand,visualization},
  file = {/Users/charliejhadley/Zotero/storage/8PMIIJNP/Perdana et al. - 2018 - Does Visualization Matter The Role of Interactive.pdf}
}

@article{perneger_sample_2015,
  title = {Sample Size for Pre-Tests of Questionnaires},
  author = {Perneger, Thomas V. and Courvoisier, Delphine S. and Hudelson, Patricia M. and {Gayet-Ageron}, Ang{\`e}le},
  year = {2015},
  month = jan,
  journal = {Quality of Life Research},
  volume = {24},
  number = {1},
  pages = {147--151},
  issn = {1573-2649},
  doi = {10.1007/s11136-014-0752-2},
  abstract = {To provide guidance regarding the desirable size of pre-tests of psychometric questionnaires, when the purpose of the pre-test is to detect misunderstandings, ambiguities, or other difficulties participants may encounter with instrument items (called \guillemotleft problems\guillemotright ).},
  langid = {english},
  keywords = {Cognitive interviewing,Power,Pre-tests,Questionnaires,Sample size,Validity},
  file = {/Users/charliejhadley/Zotero/storage/IBFJUP28/Perneger et al. - 2015 - Sample size for pre-tests of questionnaires.pdf}
}

@article{piccitto_does_2022,
  title = {Does the {{Survey Mode Affect}} the {{Association Between Subjective Well-being}} and Its {{Determinants}}? {{An Experimental Comparison Between Face-to-Face}} and {{Web Mode}}},
  shorttitle = {Does the {{Survey Mode Affect}} the {{Association Between Subjective Well-being}} and Its {{Determinants}}?},
  author = {Piccitto, Giorgio and Liefbroer, Aart C. and Emery, Tom},
  year = {2022},
  month = jul,
  journal = {Journal of Happiness Studies},
  issn = {1573-7780},
  doi = {10.1007/s10902-022-00553-y},
  abstract = {Subjective well-being research increasingly uses web surveys to understand how subjective well-being indicators are related to other concepts of interest. Although we know that mean scores on these indicators may differ between modes, we know little about whether a move to web will influence the conclusions we draw about our conceptual models. This study uses data from a unique mixed-mode survey collected in Croatia and Germany as part of the Generations and Gender Programme to examine whether the relationships between a range of subjective well-being indicators and a set of objective and subjective determinants differ between respondents answering these questions in face-to-face or web mode. Although respondents report lower subjective well-being in web than in face-to-face mode, the relationships between these variables and a range of objective and subjective indicators are relatively stable across modes. This suggests that substantive conclusions about antecedents of subjective well-being do not depend on whether data are collected via a face-to-face interview or through web survey.},
  langid = {english},
  keywords = {Face-to-face survey,Mode effect,Social desirability,Subjective well-being,Web survey},
  file = {/Users/charliejhadley/Zotero/storage/P3TTCEPD/Piccitto et al. - 2022 - Does the Survey Mode Affect the Association Betwee.pdf}
}

@misc{piper_science_2020,
  title = {Science Has Been in a "Replication Crisis" for a Decade. {{Have}} We Learned Anything?},
  author = {Piper, Kelsey},
  year = {2020},
  month = oct,
  journal = {Vox},
  abstract = {Bad papers are still published. But some other things might be getting better.},
  howpublished = {https://www.vox.com/future-perfect/21504366/science-replication-crisis-peer-review-statistics},
  langid = {english},
  keywords = {reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/IZLAZHP4/science-replication-crisis-peer-review-statistics.html}
}

@article{presser_methods_2004,
  title = {Methods for {{Testing}} and {{Evaluating Survey Questions}}},
  author = {Presser, Stanley and Couper, Mick P. and Lessler, Judith T. and Martin, Elizabeth and Martin, Jean and Rothgeb, Jennifer M. and Singer, Eleanor},
  year = {2004},
  month = mar,
  journal = {Public Opinion Quarterly},
  volume = {68},
  number = {1},
  pages = {109--130},
  issn = {0033-362X},
  doi = {10.1093/poq/nfh008},
  abstract = {An examination of survey pretesting reveals a paradox. On the one hand, pretesting is the only way to evaluate in advance whether a questionnaire causes problems for interviewers or respondents. Consequently, both elementary textbooks and experienced researchers declare pretesting indispensable. On the other hand, most textbooks offer minimal, if any, guidance about pretesting methods, and published survey reports usually provide no information about whether questionnaires were pretested and, if so, how, and with what results. Moreover, until recently there was relatively little methodological research on pretesting. Thus pretesting's universally acknowledged importance has been honored more in the breach than in the practice, and not a great deal is known about many aspects of pretesting, including the extent to which pretests serve their intended purpose and lead to improved questionnaires.},
  file = {/Users/charliejhadley/Zotero/storage/LSXAFMI9/Presser et al. - 2004 - Methods for Testing and Evaluating Survey Question.pdf;/Users/charliejhadley/Zotero/storage/YA4Y8BEV/1855073.html}
}

@misc{quividi_consumer_2022,
  title = {{{CONSUMER Privacy}} - {{Quividi}} - {{Insightful}} Data with Fully Anonymous Measurements.},
  author = {{Quividi}},
  year = {2022},
  journal = {Quividi},
  abstract = {We believe in consumer privacy. We do not record any personal image. We do not follow people around. Ever.},
  howpublished = {https://quividi.com/privacy/},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/QAE2VA2T/privacy.html}
}

@book{radley-gardner_fundamental_2016,
  title = {Fundamental {{Texts On European Private Law}}},
  editor = {{Radley-Gardner}, Oliver and Beale, Hugh and Zimmermann, Reinhard},
  year = {2016},
  publisher = {{Hart Publishing}},
  doi = {10.5040/9781782258674},
  isbn = {978-1-78225-864-3 978-1-78225-865-0 978-1-78225-866-7 978-1-78225-867-4},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/9GCCAEMW/Radley-Gardner et al. - 2016 - Fundamental Texts On European Private Law.pdf}
}

@article{reifman_introduction_2016,
  title = {Introduction to the {{Special Issue}} of {{Emerging Adulthood}}},
  author = {Reifman, Alan and Grahe, Jon E.},
  year = {2016},
  month = jun,
  journal = {Emerging Adulthood},
  volume = {4},
  number = {3},
  pages = {135--141},
  publisher = {{SAGE Publications Inc}},
  issn = {2167-6968},
  doi = {10.1177/2167696815588022},
  abstract = {This article introduces the special issue on the national Emerging Adulthood Measured at Multiple Institutions data set, its historical background and methodology, and the articles appearing herein. The project aimed to test associations between markers/processes of the transition to adulthood and political attitudes/behaviors, in conjunction with the 2004 U.S. presidential election. Measures in other areas (e.g., psychological health, disability, and media usage) were also assessed. A total of 1,353 respondents (nearly all in the emerging-adulthood age range) participated through 1 of 10 university-based sites across the United States, with students in undergraduate statistics and research methods courses gathering the data. The resulting data set has allowed social scientists to test formulations involving emerging adulthood in new domains, as presented in this issue, and will allow future investigators to do so. The project also dovetails with parallel developments in the promotion of undergraduate research as a source of substantive scientific contributions.},
  langid = {english},
  keywords = {disabilities,measurement,mental health,politics,transitions to adulthood},
  file = {/Users/charliejhadley/Zotero/storage/XSIG44VF/Reifman and Grahe - 2016 - Introduction to the Special Issue of Emerging Adul.pdf}
}

@article{reinhart_growth_2010,
  title = {Growth in a {{Time}} of {{Debt}}},
  author = {Reinhart, Carmen M and Rogoff, Kenneth S},
  year = {2010},
  month = may,
  journal = {American Economic Review},
  volume = {100},
  number = {2},
  pages = {573--578},
  issn = {0002-8282},
  doi = {10.1257/aer.100.2.573},
  langid = {english},
  keywords = {excel reproducibility,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/DGU93X7T/Reinhart and Rogoff - 2010 - Growth in a Time of Debt.pdf}
}

@article{rhemtulla_asymptotic_2016,
  title = {On the {{Asymptotic Relative Efficiency}} of {{Planned Missingness Designs}}},
  author = {Rhemtulla, Mijke and Savalei, Victoria and Little, Todd D.},
  year = {2016},
  month = mar,
  journal = {Psychometrika},
  volume = {81},
  number = {1},
  pages = {60--89},
  issn = {1860-0980},
  doi = {10.1007/s11336-014-9422-0},
  abstract = {In planned missingness (PM) designs, certain data are set a priori to be missing. PM designs can increase validity and reduce cost; however, little is known about the loss of efficiency that accompanies these designs. The present paper compares PM designs to reduced sample (RN) designs that have the same total number of data points concentrated in fewer participants. In 4 studies, we consider models for both observed and latent variables, designs that do or do not include an ``X set'' of variables with complete data, and a full range of between- and within-set correlation values. All results are obtained using asymptotic relative efficiency formulas, and thus no data are generated; this novel approach allows us to examine whether PM designs have theoretical advantages over RN designs removing the impact of sampling error. Our primary findings are that (a) in manifest variable regression models, estimates of regression coefficients have much lower relative efficiency in PM designs as compared to RN designs, (b) relative efficiency of factor correlation or latent regression coefficient estimates is maximized when the indicators of each latent variable come from different sets, and (c) the addition of an X set improves efficiency in manifest variable regression models only for the parameters that directly involve the X-set variables, but it substantially improves efficiency of most parameters in latent variable models. We conclude that PM designs can be beneficial when the model of interest is a latent variable model; recommendations are made for how to optimize such a design.},
  langid = {english},
  keywords = {efficiency,incomplete data,missing data,missingness by design,planned missing,power},
  file = {/Users/charliejhadley/Zotero/storage/VIZ3WJI7/Rhemtulla et al. - 2016 - On the Asymptotic Relative Efficiency of Planned M.pdf}
}

@misc{rivas-gonzalez_seasonality_2022,
  title = {Seasonality in Bee Colonies with Hexbin Geofacets},
  author = {{Rivas-Gonz{\'a}lez}, Iker},
  year = {2022},
  month = aug,
  file = {/Users/charliejhadley/Zotero/storage/27QGZBR7/seasonality-in-honey-hexbin-geofacet.Rmd}
}

@article{roche_public_2015,
  title = {Public {{Data Archiving}} in {{Ecology}} and {{Evolution}}: {{How Well Are We Doing}}?},
  shorttitle = {Public {{Data Archiving}} in {{Ecology}} and {{Evolution}}},
  author = {Roche, Dominique G. and Kruuk, Loeske E. B. and Lanfear, Robert and Binning, Sandra A.},
  year = {2015},
  month = nov,
  journal = {PLOS Biology},
  volume = {13},
  number = {11},
  pages = {e1002295},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1002295},
  abstract = {Policies that mandate public data archiving (PDA) successfully increase accessibility to data underlying scientific publications. However, is the data quality sufficient to allow reuse and reanalysis? We surveyed 100 datasets associated with nonmolecular studies in journals that commonly publish ecological and evolutionary research and have a strong PDA policy. Out of these datasets, 56\% were incomplete, and 64\% were archived in a way that partially or entirely prevented reuse. We suggest that cultural shifts facilitating clearer benefits to authors are necessary to achieve high-quality PDA and highlight key guidelines to help authors increase their data's reuse potential and compliance with journal data policies.},
  langid = {english},
  keywords = {Archives,Computer software,Evolutionary biology,Metadata,open data,Public policy,Reproducibility,Science policy,Scientific publishing},
  file = {/Users/charliejhadley/Zotero/storage/IJARP6DI/Roche et al. - 2015 - Public Data Archiving in Ecology and Evolution Ho.pdf;/Users/charliejhadley/Zotero/storage/QBSKTI7E/article.html}
}

@article{rodriguez_current_2022,
  title = {Current Recommendations/Practices for Anonymising Data from Clinical Trials in Order to Make It Available for Sharing: {{A}} Scoping Review},
  shorttitle = {Current Recommendations/Practices for Anonymising Data from Clinical Trials in Order to Make It Available for Sharing},
  author = {Rodriguez, Aryelly and Tuck, Christopher and Dozier, Marshall F and Lewis, Stephanie C and Eldridge, Sandra and Jackson, Tracy and Murray, Alastair and Weir, Christopher J},
  year = {2022},
  month = aug,
  journal = {Clinical Trials},
  volume = {19},
  number = {4},
  pages = {452--463},
  publisher = {{SAGE Publications}},
  issn = {1740-7745},
  doi = {10.1177/17407745221087469},
  abstract = {Background/AimsThere are increasing pressures for anonymised datasets from clinical trials to be shared across the scientific community, and differing recommendations exist on how to perform anonymisation prior to sharing. We aimed to systematically identify, describe and synthesise existing recommendations for anonymising clinical trial datasets to prepare for data sharing.MethodsWe systematically searched MEDLINE?, EMBASE and Web of Science from inception to 8 February 2021. We also searched other resources to ensure the comprehensiveness of our search. Any publication reporting recommendations on anonymisation to enable data sharing from clinical trials was included. Two reviewers independently screened titles, abstracts and full text for eligibility. One reviewer extracted data from included papers using thematic synthesis, which then was sense-checked by a second reviewer. Results were summarised by narrative analysis.ResultsFifty-nine articles (from 43 studies) were eligible for inclusion. Three distinct themes are emerging: anonymisation, de-identification and pseudonymisation. The most commonly used anonymisation techniques are: removal of direct patient identifiers; and careful evaluation and modification of indirect identifiers to minimise the risk of identification. Anonymised datasets joined with controlled access was the preferred method for data sharing.ConclusionsThere is no single standardised set of recommendations on how to anonymise clinical trial datasets for sharing. However, this systematic review shows a developing consensus on techniques used to achieve anonymisation. Researchers in clinical trials still consider that anonymisation techniques by themselves are insufficient to protect patient privacy, and they need to be paired with controlled access.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/GUZBCT36/Rodriguez et al. - 2022 - Current recommendationspractices for anonymising .pdf}
}

@misc{rogers_falsehoods_2018,
  title = {Falsehoods {{Programmers Believe About Names}} - {{With Examples}}},
  author = {{rogers}, tony},
  year = {2018},
  month = jan,
  journal = {Shine Solutions Group},
  abstract = {In 2010, Patrick McKenzie wrote the now-famous blog ``Falsehoods Programmers Believe About Names'', in which he listed 40 things that were not universally true about names. Did programmers sit up, take notice and change their attitudes to names? Sadly, not really. We still get asked...},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/6D9J2WQ6/falsehoods-programmers-believe-about-names-with-examples.html}
}

@article{roth_examining_2020,
  title = {Examining the Feasibility of Using Open Data to Benchmark Building Energy Usage in Cities: {{A}} Data Science and Policy Perspective},
  shorttitle = {Examining the Feasibility of Using Open Data to Benchmark Building Energy Usage in Cities},
  author = {Roth, Jonathan and Lim, Benjamin and Jain, Rishee K. and Grueneich, Dian},
  year = {2020},
  month = apr,
  journal = {Energy Policy},
  volume = {139},
  pages = {111327},
  issn = {0301-4215},
  doi = {10.1016/j.enpol.2020.111327},
  abstract = {Buildings are by far the largest source of urban energy consumption. In an effort to reduce energy use, cities are mandating that buildings undergo energy benchmarking\textemdash the process of measuring building energy performance in order to identify buildings that are inefficient. In this paper, we examine the feasibility of using city-specific, public open data sources in two benchmarking models and compare the results to the same models when using the Commercial Building Energy Consumption Survey (CBECS) dataset, the basis for Energy Star. The two benchmarking models use datasets containing building characteristics and annual energy use from ten major cities. To examine the difference in performance between linear and non-linear models, we use random forest and lasso regression. Results demonstrate that benchmarking models using open data outperform models based solely on the CBECS dataset. Additionally, our results indicate that building area, property type, conditioned area, and water usage are the most important variables for cities to collect. Having demonstrated the benefits of using open data, we recommend two changes to current benchmarking practices: (1) new guidelines that support a data-driven benchmarking framework relying on open data and a transparent modeling process and (2) supporting policies that publicize benchmarking results and incentivize energy savings.},
  langid = {english},
  keywords = {Benchmarking,Building energy performance,Disclosure policy,Energy efficiency,Open data,Variable selection},
  file = {/Users/charliejhadley/Zotero/storage/7L8NLCHV/Roth et al. - 2020 - Examining the feasibility of using open data to be.pdf;/Users/charliejhadley/Zotero/storage/7DB6V8Q2/S0301421520300847.html}
}

@article{roth_looking_2009,
  title = {Looking at {{Shirley}}, the {{Ultimate Norm}}: {{Colour Balance}}, {{Image Technologies}}, and {{Cognitive Equity}}},
  shorttitle = {Looking at {{Shirley}}, the {{Ultimate Norm}}},
  author = {Roth, Lorna},
  year = {2009},
  month = mar,
  journal = {Canadian Journal of Communication},
  volume = {34},
  number = {1},
  pages = {111--136},
  publisher = {{University of Toronto Press}},
  issn = {0705-3657},
  doi = {10.22230/cjc.2009v34n1a2196},
  abstract = {Until recently, due to a light-skin bias embedded in colour film stock emulsions and digital camera design, the rendering of non-Caucasian skin tones was highly deficient and required the development of compensatory practices and technology improvements to redress its shortcomings. Using the emblematic ``Shirley'' norm reference card as a central metaphor reflecting the changing state of race relations/aesthetics, this essay analytically traces the colour adjustment processes in the industries of visual representation and identifies some prototypical changes in the field. The author contextualizes the history of these changes using three theoretical categories: the `technological unconscious' (Vaccari, 1981), `dysconsciousness' (King, 2001), and an original concept of `cognitive equity,' which is proposed as an intelligent strategy for creating and promoting equity by inscribing a wider dynamic range of skin tones into image technologies, products, and emergent practices in the visual industries.},
  keywords = {Balance de couleur,Cartes de référence normatives,Cognitive equity,Colour balance,Cultural studies,Dynamic range,Dysconscience,Dysconsciousness,Équité cognitive,Études culturelles,Gamme  dynamique,Inconscient technologique,Norm reference cards,Technological unconscious},
  file = {/Users/charliejhadley/Zotero/storage/4MBV3KZ5/Roth - 2009 - Looking at Shirley, the Ultimate Norm Colour Bala.pdf}
}

@article{roth_looking_2009-1,
  title = {Looking at {{Shirley}}, the {{Ultimate Norm}}: {{Colour Balance}}, {{Image Technologies}}, and {{Cognitive Equity}}},
  shorttitle = {Looking at {{Shirley}}, the {{Ultimate Norm}}},
  author = {Roth, Lorna},
  year = {2009},
  month = mar,
  journal = {Canadian Journal of Communication},
  volume = {34},
  number = {1},
  pages = {111--136},
  publisher = {{University of Toronto Press}},
  issn = {0705-3657},
  doi = {10.22230/cjc.2009v34n1a2196},
  abstract = {Until recently, due to a light-skin bias embedded in colour film stock emulsions and digital camera design, the rendering of non-Caucasian skin tones was highly deficient and required the development of compensatory practices and technology improvements to redress its shortcomings. Using the emblematic ``Shirley'' norm reference card as a central metaphor reflecting the changing state of race relations/aesthetics, this essay analytically traces the colour adjustment processes in the industries of visual representation and identifies some prototypical changes in the field. The author contextualizes the history of these changes using three theoretical categories: the `technological unconscious' (Vaccari, 1981), `dysconsciousness' (King, 2001), and an original concept of `cognitive equity,' which is proposed as an intelligent strategy for creating and promoting equity by inscribing a wider dynamic range of skin tones into image technologies, products, and emergent practices in the visual industries.},
  keywords = {Balance de couleur,Cartes de référence normatives,Cognitive equity,Colour balance,Cultural studies,Dynamic range,Dysconscience,Dysconsciousness,Équité cognitive,Études culturelles,Gamme  dynamique,Inconscient technologique,Norm reference cards,Technological unconscious},
  file = {/Users/charliejhadley/Zotero/storage/8TSC4SAU/Roth - 2009 - Looking at Shirley, the Ultimate Norm Colour Bala.pdf}
}

@techreport{samarati_protecting_1998,
  title = {Protecting {{Privacy}} When {{Disclosing Information}}: K-{{Anonymity}} and {{Its Enforcement}} through {{Generalization}} and {{Suppression}}},
  shorttitle = {Protecting {{Privacy}} When {{Disclosing Information}}},
  author = {Samarati, Pierangela and Sweeney, Latanya},
  year = {1998},
  abstract = {Today's globally networked society places great demand on the dissemination and sharing of person-specific data. Situations where aggregate statistical information was once the reporting norm now rely heavily on the transfer of microscopically detailed transaction and encounter information. This happens at a time when more and more historically public information is also electronically available. When these data are linked together, they provide an electronic shadow of a person or organization that is as identifying and personal as a fingerprint, even when the sources of the information contains no explicit identifiers, such as name and phone number. In order to protect the anonymity of individuals to whom released data refer, data holders often remove or encrypt explicit identifiers such as names, addresses and phone numbers. However, other distinctive data, which we term quasi-identifiers, often combine uniquely and can be linked to publicly available information to re-identify indiv...},
  file = {/Users/charliejhadley/Zotero/storage/7JGCGY26/Samarati and Sweeney - 1998 - Protecting Privacy when Disclosing Information k-.pdf;/Users/charliejhadley/Zotero/storage/8T5H5S5D/summary.html}
}

@phdthesis{sanchez_tome_impact_2018,
  title = {The Impact of Mode of Data Collection on Measures of Subjective Wellbeing},
  author = {S{\'a}nchez Tom{\'e}, Rosa},
  year = {2018},
  abstract = {Measures on quality of life are now widely available and questions such as life satisfaction and happiness are common in social surveys, providing invaluable information to researchers and policy makers across the world. However, surveys are subject to error and it is important to evaluate the effect of survey design on data quality. In particular, some survey methodologists have focused on the mode of data collection, as there are concerns about nonresponse bias in traditional single-mode surveys. As a consequence, alternative ways of collecting information have become popular, such as the combination of multiple modes of data collection (e.g. telephone and web) as a way of attracting people that would otherwise not respond. However, collecting data using different modes may render data incomparable, which could pose a problem for those researchers that rely on data collected using different modes. This thesis attempts to provide some answers about the potential drawbacks of using data on the topic of wellbeing that come from different modes of data collection. Analysing data from a mode comparison experiment implemented in Switzerland, I compared responses to twenty- seven subjective wellbeing questions in telephone, web and mail. The results of the study demonstrate that mode has an effect on who responds and how responses are given. Mode affected measures such as happiness and job satisfaction, responses to open-ended questions about life events, and the relationship between subjective wellbeing and its predictors. However, the latent measure of general subjective wellbeing was equivalent across modes.},
  school = {University of Lausanne}
}

@article{savage_quantitative_2007,
  title = {A Quantitative, Theoretical Framework for Understanding Mammalian Sleep},
  author = {Savage, Van M. and West, Geoffrey B.},
  year = {2007},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {104},
  number = {3},
  pages = {1051--1056},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.0610080104},
  file = {/Users/charliejhadley/Zotero/storage/4SWG5D6X/Savage and West - 2007 - A quantitative, theoretical framework for understa.pdf}
}

@misc{schoettle_preliminary_2015,
  title = {A {{Preliminary Analysis}} of {{Real-World Crashes Involving Self-Driving Vehicles}}},
  author = {Schoettle, Brandon and Sivak, Michael},
  year = {2015},
  month = oct,
  publisher = {{The University of Michigan}}
}

@inproceedings{selbst_fairness_2019,
  title = {Fairness and {{Abstraction}} in {{Sociotechnical Systems}}},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Selbst, Andrew D. and Boyd, Danah and Friedler, Sorelle A. and Venkatasubramanian, Suresh and Vertesi, Janet},
  year = {2019},
  month = jan,
  series = {{{FAT}}* '19},
  pages = {59--68},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3287560.3287598},
  abstract = {A key goal of the fair-ML community is to develop machine-learning based systems that, once introduced into a social context, can achieve social and legal outcomes such as fairness, justice, and due process. Bedrock concepts in computer science---such as abstraction and modular design---are used to define notions of fairness and discrimination, to produce fairness-aware learning algorithms, and to intervene at different stages of a decision-making pipeline to produce "fair" outcomes. In this paper, however, we contend that these concepts render technical interventions ineffective, inaccurate, and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five "traps" that fair-ML work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally, we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions, and by drawing abstraction boundaries to include social actors rather than purely technical ones.},
  isbn = {978-1-4503-6125-5},
  keywords = {Fairness-aware Machine Learning,Interdisciplinary,Sociotechnical Systems},
  file = {/Users/charliejhadley/Zotero/storage/8UHNXV74/Selbst et al. - 2019 - Fairness and Abstraction in Sociotechnical Systems.pdf}
}

@article{serdar_sample_2021,
  title = {Sample Size, Power and Effect Size Revisited: Simplified and Practical Approaches in Pre-Clinical, Clinical and Laboratory Studies},
  shorttitle = {Sample Size, Power and Effect Size Revisited},
  author = {Serdar, Ceyhan Ceran and Cihan, Murat and Y{\"u}cel, Do{\u g}an and Serdar, Muhittin A},
  year = {2021},
  month = feb,
  journal = {Biochemia Medica},
  volume = {31},
  number = {1},
  pages = {010502},
  issn = {1330-0962},
  doi = {10.11613/BM.2021.010502},
  abstract = {Calculating the sample size in scientific studies is one of the critical issues as regards the scientific contribution of the study. The sample size critically affects the hypothesis and the study design, and there is no straightforward way of calculating the effective sample size for reaching an accurate conclusion. Use of a statistically incorrect sample size may lead to inadequate results in both clinical and laboratory studies as well as resulting in time loss, cost, and ethical problems. This review holds two main aims. The first aim is to explain the importance of sample size and its relationship to effect size (ES) and statistical significance. The second aim is to assist researchers planning to perform sample size estimations by suggesting and elucidating available alternative software, guidelines and references that will serve different scientific purposes.},
  pmcid = {PMC7745163},
  pmid = {33380887},
  file = {/Users/charliejhadley/Zotero/storage/8JW2D68L/Serdar et al. - 2021 - Sample size, power and effect size revisited simp.pdf}
}

@article{shin_toward_2019,
  title = {Toward {{Fair}}, {{Accountable}}, and {{Transparent Algorithms}}: {{Case Studies}} on {{Algorithm Initiatives}} in {{Korea}} and {{China}}},
  shorttitle = {Toward {{Fair}}, {{Accountable}}, and {{Transparent Algorithms}}},
  author = {Shin, Donghee (Don)},
  year = {2019},
  month = jul,
  journal = {Javnost - The Public},
  volume = {26},
  number = {3},
  pages = {274--290},
  publisher = {{Routledge}},
  issn = {1318-3222},
  doi = {10.1080/13183222.2019.1589249},
  abstract = {Algorithms are playing an increasingly huge role becoming a big part of human lives. With the conceptualisation of algorithms as a socio-technical system, this study investigates algorithm initiatives in Korea and China in terms of the opportunities, risks, and challenges embedded in their development. This study analyses algorithm development and trends from a critical socio-technical lens: social, technological, cultural, and industrial phenomena that represent strategic interactions involving people, technology, and society and elicit sensitive legal, cultural, and ethical rhetoric issues. Despite rosy predictions and proactive drives, new risks related to privacy, transparency, and fairness emerge as critical concerns of the social ramifications of algorithms and of their impacts on the new information milieu. With these emerging issues, questions are raised on the ways to govern algorithms and to respond to potential outcomes that such a policy approach may have on society and industry. Both Korea and China will likely struggle with the social cost of AI as it challenges what it means to be fair, transparent, and accountable. The socio-political implications of algorithms are discussed to identify key issues as both countries progress toward an algorithm-based, AI-driven society.},
  keywords = {algorithm governance,algorithm-based society,algorithms,China,Chinese algorithm policy,social credit system,socio-technical algorithms},
  annotation = {\_eprint: https://doi.org/10.1080/13183222.2019.1589249},
  file = {/Users/charliejhadley/Zotero/storage/9TV8VHE8/Shin - 2019 - Toward Fair, Accountable, and Transparent Algorith.pdf}
}

@article{shin_toward_2019-1,
  title = {Toward {{Fair}}, {{Accountable}}, and {{Transparent Algorithms}}: {{Case Studies}} on {{Algorithm Initiatives}} in {{Korea}} and {{China}}},
  shorttitle = {Toward {{Fair}}, {{Accountable}}, and {{Transparent Algorithms}}},
  author = {Shin, Donghee (Don)},
  year = {2019},
  month = jul,
  journal = {Javnost - The Public},
  volume = {26},
  number = {3},
  pages = {274--290},
  publisher = {{Routledge}},
  issn = {1318-3222},
  doi = {10.1080/13183222.2019.1589249},
  abstract = {Algorithms are playing an increasingly huge role becoming a big part of human lives. With the conceptualisation of algorithms as a socio-technical system, this study investigates algorithm initiatives in Korea and China in terms of the opportunities, risks, and challenges embedded in their development. This study analyses algorithm development and trends from a critical socio-technical lens: social, technological, cultural, and industrial phenomena that represent strategic interactions involving people, technology, and society and elicit sensitive legal, cultural, and ethical rhetoric issues. Despite rosy predictions and proactive drives, new risks related to privacy, transparency, and fairness emerge as critical concerns of the social ramifications of algorithms and of their impacts on the new information milieu. With these emerging issues, questions are raised on the ways to govern algorithms and to respond to potential outcomes that such a policy approach may have on society and industry. Both Korea and China will likely struggle with the social cost of AI as it challenges what it means to be fair, transparent, and accountable. The socio-political implications of algorithms are discussed to identify key issues as both countries progress toward an algorithm-based, AI-driven society.},
  keywords = {algorithm governance,algorithm-based society,algorithms,China,Chinese algorithm policy,social credit system,socio-technical algorithms},
  annotation = {\_eprint: https://doi.org/10.1080/13183222.2019.1589249}
}

@article{siddique_minority_2019,
  title = {Minority Ethnic {{Britons}} Face 'shocking' Job Discrimination},
  author = {Siddique, Haroon},
  year = {2019},
  month = jan,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {Exclusive: research finds levels of discrimination unchanged since late 1960s},
  chapter = {World news},
  langid = {british},
  keywords = {Discrimination at work,Job hunting,Race,UK news,Work \& careers},
  file = {/Users/charliejhadley/Zotero/storage/8YNXM42X/minority-ethnic-britons-face-shocking-job-discrimination.html}
}

@article{simmons_false-positive_2011,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  shorttitle = {False-{{Positive Psychology}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  year = {2011},
  month = nov,
  journal = {Psychological Science},
  volume = {22},
  number = {11},
  pages = {1359--1366},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists? nominal endorsement of a low rate of false-positive findings ({$\leq$} .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  keywords = {p-hacking},
  file = {/Users/charliejhadley/Zotero/storage/JFKDYQ4X/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf}
}

@article{skau_arcs_2016,
  title = {Arcs, {{Angles}}, or {{Areas}}: {{Individual Data Encodings}} in {{Pie}} and {{Donut Charts}}},
  shorttitle = {Arcs, {{Angles}}, or {{Areas}}},
  author = {Skau, Drew and Kosara, Robert},
  year = {2016},
  journal = {Computer Graphics Forum},
  volume = {35},
  number = {3},
  pages = {121--130},
  issn = {1467-8659},
  doi = {10.1111/cgf.12888},
  abstract = {Pie and donut charts have been a hotly debated topic in the visualization community for some time now. Even though pie charts have been around for over 200 years, our understanding of the perceptual factors used to read data in them is still limited. Data is encoded in pie and donut charts in three ways: arc length, center angle, and segment area. For our first study, we designed variations of pie charts to test the importance of individual encodings for reading accuracy. In our second study, we varied the inner radius of a donut chart from a filled pie to a thin outline to test the impact of removing the central angle. Both studies point to angle being the least important visual cue for both charts, and the donut chart being as accurate as the traditional pie chart.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12888}
}

@article{smerecnik_understanding_2010,
  title = {Understanding the {{Positive Effects}} of {{Graphical Risk Information}} on {{Comprehension}}: {{Measuring Attention Directed}} to {{Written}}, {{Tabular}}, and {{Graphical Risk Information}}},
  shorttitle = {Understanding the {{Positive Effects}} of {{Graphical Risk Information}} on {{Comprehension}}},
  author = {Smerecnik, Chris M. R. and Mesters, Ilse and Kessels, Loes T. E. and Ruiter, Robert A. C. and De Vries, Nanne K. and De Vries, Hein},
  year = {2010},
  journal = {Risk Analysis},
  volume = {30},
  number = {9},
  pages = {1387--1398},
  issn = {1539-6924},
  doi = {10.1111/j.1539-6924.2010.01435.x},
  abstract = {Risk communications are an integral aspect of health education and promotion. However, the commonly used textual risk information is relatively difficult to understand for the average recipient. Consequently, researchers and health promoters have started to focus on so-called decision aids, such as tables and graphs. Although tabular and graphical risk information more effectively communicate risks than textual risk information, the cognitive mechanisms responsible for this enhancement are unclear. This study aimed to examine two possible mechanisms (i.e., cognitive workload and attention). Cognitive workload (mean pupil size and peak pupil dilation) and attention directed to the risk information (viewing time, number of eye fixations, and eye fixation durations) were both measured in a between-subjects experimental design. The results suggest that graphical risk information facilitates comprehension of that information because it attracts and holds attention for a longer period of time than textual risk information. Graphs are thus a valuable asset to risk communication practice for two reasons: first, they tend to attract attention and, second, when attended to, they elicit information extraction with relatively little cognitive effort, and finally result in better comprehension.},
  langid = {english},
  keywords = {Attention,cognitive workload,eye movement,risk communication,risk format},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.2010.01435.x},
  file = {/Users/charliejhadley/Zotero/storage/ST2W4HIG/Smerecnik et al. - 2010 - Understanding the Positive Effects of Graphical Ri.pdf;/Users/charliejhadley/Zotero/storage/DNHNKYP2/j.1539-6924.2010.01435.html}
}

@book{snow_mode_1855,
  title = {On the Mode of Communication of Cholera},
  author = {Snow, John},
  year = {1855},
  edition = {Second},
  publisher = {{John Churchill}},
  address = {{London}},
  file = {/Users/charliejhadley/Zotero/storage/JH24FZYS/one.html}
}

@patent{spiegel_method_2013,
  title = {Method and System for Anticipatory Package Shipping},
  author = {Spiegel, Joel R. and McKenna, Michael T. and Lakshman, Girish S. and Nordstrom, Paul G.},
  year = {2013},
  month = dec,
  number = {US8615473B2},
  abstract = {A method and system for anticipatory package shipping are disclosed. According to one embodiment, a method may include packaging one or more items as a package for eventual shipment to a delivery address, selecting a destination geographical area to which to ship the package, shipping the package to the destination geographical area without completely specifying the delivery address at time of shipment, and while the package is in transit, completely specifying the delivery address for the package.},
  assignee = {Amazon Technologies Inc},
  langid = {english},
  nationality = {US},
  keywords = {determining,given,package,packages,shipped},
  file = {/Users/charliejhadley/Zotero/storage/9VH5CDGZ/Spiegel et al. - 2013 - Method and system for anticipatory package shippin.pdf}
}

@article{spurgeon_glaxosmithkline_2004,
  title = {{{GlaxoSmithKline}} Staff Told Not to Publicise Ineffectiveness of Its Drug},
  author = {Spurgeon, David},
  year = {2004},
  month = feb,
  journal = {BMJ : British Medical Journal},
  volume = {328},
  number = {7437},
  pages = {422},
  issn = {0959-8138},
  pmcid = {PMC344289},
  pmid = {null},
  keywords = {pre-registration clinical trials}
}

@article{stauffer_existence_2005,
  title = {The {{Existence}} and {{Nature}} of {{Racial Bias}} in {{Supervisory Ratings}}},
  author = {Stauffer, Joseph M. and Buckley, M. Ronald},
  year = {2005},
  journal = {Journal of Applied Psychology},
  volume = {90},
  pages = {586--591},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.90.3.586},
  abstract = {The purpose of this article is to facilitate a reconsideration of what the authors consider to be a mistaken belief among personnel psychologists--the belief that supervisory ratings of job performance are not biased on the basis of race. In this article, the authors reviewed the current literature, reexamined the data, and concluded that the research on which this mistaken belief is based clearly demonstrates that racial bias may indeed exist and is significant, both in statistical and practical terms. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Job Performance,Management Personnel,Personnel Evaluation,Racial Bias,Racism,Rating},
  file = {/Users/charliejhadley/Zotero/storage/67VKD9UW/___stauffer2005.pdf;/Users/charliejhadley/Zotero/storage/6EZLXQZ9/Stauffer and Buckley - 2005 - The Existence and Nature of Racial Bias in Supervi.pdf;/Users/charliejhadley/Zotero/storage/KZQ4BHN2/doiLanding.html}
}

@misc{stfc_stfc_2021,
  title = {{{STFC Open Data Policy}}},
  author = {{STFC}},
  year = {2021},
  month = aug,
  howpublished = {https://www.ukri.org/councils/stfc/guidance-for-applicants/what-to-include-in-your-proposal/data-management-plan}
}

@article{sucholutsky_less_2021,
  title = {`{{Less Than One}}'-{{Shot Learning}}: {{Learning N Classes From M}} {$<$} {{N Samples}}},
  shorttitle = {`{{Less Than One}}'-{{Shot Learning}}},
  author = {Sucholutsky, Ilia and Schonlau, Matthias},
  year = {2021},
  month = may,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {11},
  pages = {9739--9746},
  issn = {2374-3468},
  doi = {10.1609/aaai.v35i11.17171},
  abstract = {Deep neural networks require large training sets but suffer from high computational cost and long training times. Training on much smaller training sets while maintaining nearly the same accuracy would be very beneficial. In the few-shot learning setting, a model must learn a new class given only a small number of samples from that class. One-shot learning is an extreme form of few-shot learning where the model must learn a new class from a single example. We propose the 'less than one'-shot learning task where models must learn N new classes given only M},
  copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {Other Foundations of Machine Learning},
  file = {/Users/charliejhadley/Zotero/storage/CS9ZFVQC/Sucholutsky and Schonlau - 2021 - `Less Than One'-Shot Learning Learning N Classes .pdf}
}

@techreport{sun_erp_2022,
  type = {Preprint},
  title = {{{ERP Staff}} versus {{AI Recruitment}} with {{Employment Real-Time Big Data}}},
  author = {Sun, Zhaohao and Strang, Kenneth David},
  year = {2022},
  month = apr,
  institution = {{In Review}},
  doi = {10.21203/rs.3.rs-1515074/v1},
  abstract = {Abstract           The purpose of this study was to compare the performance of recruiters and an artificial intelligence (AI) program for processing internet employment big data in the enterprise resources planning (ERP) function. Previous AI implementations were discriminatory. Thus, the research question was: Could ERP staff perform better than AI in selecting the best candidate from internet employment real-time big data. A quasi-experiment was created using primary data. Job criteria were developed using machine learning to identify key skills from existing staff in a case study company. The skills were transformed into hiring criteria and a job description. AI software and a random sample of ERP recruiters assessed the same internet-based real-time big data. The results were compared between the ERP staff and AI using ANOVA followed by post-hoc Tukey. Contrary to the research question, AI out-performed ERP staff. The proposed approach might facilitate the research and development of big data, data analytics, artificial intelligence, and human resource management.},
  file = {/Users/charliejhadley/Zotero/storage/3F22GAZD/Sun and Strang - 2022 - ERP Staff versus AI Recruitment with Employment Re.pdf}
}

@misc{surveymonkey_does_nodate,
  title = {Does Adding One More Question Impact Survey Completion Rate?},
  author = {{SurveyMonkey}},
  journal = {SurveyMonkey},
  abstract = {It will come as no surprise that the more questions you ask, the fewer respondents who start a survey or questionnaire will complete the full questionnaire. If you want or need to receive responses from a certain number of respondents, and you have a limited audience or sample size that you can get to start [\ldots ]},
  howpublished = {https://www.surveymonkey.co.uk/curiosity/survey\_questions\_and\_completion\_rates/},
  langid = {british},
  file = {/Users/charliejhadley/Zotero/storage/IYGXX8I7/survey_questions_and_completion_rates.html}
}

@article{sweeney_k-anonymity_2002,
  title = {K-{{ANONYMITY}}: {{A MODEL FOR PROTECTING PRIVACY}}},
  shorttitle = {K-{{ANONYMITY}}},
  author = {Sweeney, Latanya},
  year = {2002},
  month = oct,
  journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume = {10},
  number = {05},
  pages = {557--570},
  publisher = {{World Scientific Publishing Co.}},
  issn = {0218-4885},
  doi = {10.1142/S0218488502001648},
  abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, {$\mu$}-Argus and k-Similar provide guarantees of privacy protection.},
  keywords = {Data anonymity,data fusion,data privacy,privacy,re-identification},
  file = {/Users/charliejhadley/Zotero/storage/EXVMJ4R2/Sweeney - 2002 - k-ANONYMITY A MODEL FOR PROTECTING PRIVACY.pdf}
}

@article{sweeney_only_2015,
  title = {Only {{You}}, {{Your Doctor}}, and {{Many Others May Know}}},
  author = {Sweeney, Latanya},
  year = {2015},
  journal = {Technology Science},
  abstract = {Washington State responds to a re-identification study of anonymized health records that it sells by removing fields sensitive to re-identification.},
  file = {/Users/charliejhadley/Zotero/storage/2WWTLFQ7/2015092903.html}
}

@article{sweeney_simple_2000,
  title = {Simple {{Demographics Often Identify People Uniquely}}},
  author = {Sweeney, Latanya},
  year = {2000},
  month = jan,
  publisher = {{Carnegie Mellon University}},
  doi = {10.1184/R1/6625769.v1},
  abstract = {In this document, I report on experiments I conducted using 1990 U.S. Census summary data to determine how many individuals within geographically situated populations had combinations of demographic values that occurred infrequently. It was found that combinations of few characteristics often combine in populations to uniquely or nearly uniquely identify some individuals. Clearly, data released containing such information about these individuals should not be considered anonymous. Yet, health and other person-specific data are publicly available in this form. Here are some surprising results using only three fields of information, even though typical data releases contain many more fields. It was found that 87\% (216 million of 248 million) of the population in the United States had reported characteristics that likely made them unique based only on \{5-digit ZIP, gender, date of birth\}. About half of the U.S. population (132 million of 248 million or 53\%) are likely to be uniquely identified by only \{place, gender, date of birth\}, where place is basically the city, town, or municipality in which the person resides. And even at the county level, \{county, gender, date of birth\} are likely to uniquely identify 18\% of the U.S. population. In general, few characteristics are needed to uniquely identify a person.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/KZ53LATU/Sweeney - 2000 - Simple Demographics Often Identify People Uniquely.pdf;/Users/charliejhadley/Zotero/storage/NWYVB9E7/6625769.html}
}

@article{sweeney_simple_2000-1,
  title = {Simple {{Demographics Often Identify People Uniquely}}},
  author = {Sweeney, Latanya},
  year = {2000},
  pages = {0 Bytes},
  publisher = {{Carnegie Mellon University}},
  doi = {10.1184/R1/6625769.V1},
  abstract = {In this document, I report on experiments I conducted using 1990 U.S. Census summary data to determine how many individuals within geographically situated populations had combinations of demographic values that occurred infrequently. It was found that combinations of few characteristics often combine in populations to uniquely or nearly uniquely identify some individuals. Clearly, data released containing such information about these individuals should not be considered anonymous. Yet, health and other person-specific data are publicly available in this form. Here are some surprising results using only three fields of information, even though typical data releases contain many more fields. It was found that 87\% (216 million of 248 million) of the population in the United States had reported characteristics that likely made them unique based only on \{5-digit ZIP, gender, date of birth\}. About half of the U.S. population (132 million of 248 million or 53\%) are likely to be uniquely identified by only \{place, gender, date of birth\}, where place is basically the city, town, or municipality in which the person resides. And even at the county level, \{county, gender, date of birth\} are likely to uniquely identify 18\% of the U.S. population. In general, few characteristics are needed to uniquely identify a person.},
  copyright = {In Copyright},
  keywords = {80399 Computer Software not elsewhere classified,FOS: Computer and information sciences},
  file = {/Users/charliejhadley/Zotero/storage/SDPSDZLW/Sweeney - 2000 - Simple Demographics Often Identify People Uniquely.pdf}
}

@article{sweeney_weaving_1997,
  title = {Weaving {{Technology}} and {{Policy Together}} to {{Maintain Confidentiality}}},
  author = {Sweeney, Latanya},
  year = {1997},
  journal = {The Journal of Law, Medicine \& Ethics},
  volume = {25},
  number = {2-3},
  pages = {98--110},
  issn = {1748-720X},
  doi = {10.1111/j.1748-720X.1997.tb01885.x},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1748-720X.1997.tb01885.x},
  file = {/Users/charliejhadley/Zotero/storage/5NBUE57I/Sweeney - Weaving Technology and Poliq^ Together to Maintain.pdf;/Users/charliejhadley/Zotero/storage/GQ8WYGVY/21kanon (1).ppt;/Users/charliejhadley/Zotero/storage/4546YN4X/j.1748-720X.1997.tb01885.html}
}

@article{sweeney_weaving_nodate,
  title = {Weaving {{Technology}} and {{Poliq}}\^ {{Together}} to {{Maintain Confidentiality}}},
  author = {Sweeney, Latanya},
  pages = {14},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/VN5D88CN/Sweeney - Weaving Technology and Poliq^ Together to Maintain.pdf}
}

@article{tedersoo_data_2021,
  title = {Data Sharing Practices and Data Availability upon Request Differ across Scientific Disciplines},
  author = {Tedersoo, Leho and K{\"u}ngas, Rainer and Oras, Ester and K{\"o}ster, Kajar and Eenmaa, Helen and Leijen, {\"A}li and Pedaste, Margus and Raju, Marju and Astapova, Anastasiya and Lukner, Heli and Kogermann, Karin and Sepp, Tuul},
  year = {2021},
  month = jul,
  journal = {Scientific Data},
  volume = {8},
  number = {1},
  pages = {192},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/s41597-021-00981-0},
  abstract = {Data sharing is one of the cornerstones of modern science that enables large-scale analyses and reproducibility. We evaluated data availability in research articles across nine disciplines in Nature and Science magazines and recorded corresponding authors' concerns, requests and reasons for declining data sharing. Although data sharing has improved in the last decade and particularly in recent years, data availability and willingness to share data still differ greatly among disciplines. We observed that statements of data availability upon (reasonable) request are inefficient and should not be allowed by journals. To improve data sharing at the time of manuscript acceptance, researchers should be better motivated to release their data with real benefits such as recognition, or bonus points in grant and job applications. We recommend that data management costs should be covered by funding agencies; publicly available research data ought to be included in the evaluation of applications; and surveillance of data sharing should be enforced by both academic publishers and funders. These cross-discipline survey data are available from the plutoF repository.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Genetic databases,Molecular ecology,open data statistics},
  file = {/Users/charliejhadley/Zotero/storage/7M2WJP9G/Tedersoo et al. - 2021 - Data sharing practices and data availability upon .pdf;/Users/charliejhadley/Zotero/storage/QQZVFT9K/s41597-021-00981-0.html}
}

@misc{tedx_talks_danger_2018,
  title = {The Danger of Predictive Algorithms in Criminal Justice | {{Hany Farid}} | {{TEDxAmoskeagMillyard}}},
  author = {{TEDx Talks}},
  year = {2018},
  month = oct
}

@misc{teller_sample_2014,
  title = {Sample Size: {{How}} Many People Should Take the Survey?},
  author = {Teller, Siim},
  year = {2014},
  month = jan,
  journal = {on device research},
  howpublished = {https://ondeviceresearch.com/blog/sample-size-people-participate-take-survey},
  file = {/Users/charliejhadley/Zotero/storage/NAFFJBRX/sample-size-people-participate-take-survey.html}
}

@article{tenopir_data_2011,
  title = {Data {{Sharing}} by {{Scientists}}: {{Practices}} and {{Perceptions}}},
  shorttitle = {Data {{Sharing}} by {{Scientists}}},
  author = {Tenopir, Carol and Allard, Suzie and Douglass, Kimberly and Aydinoglu, Arsev Umur and Wu, Lei and Read, Eleanor and Manoff, Maribeth and Frame, Mike},
  year = {2011},
  month = jun,
  journal = {PLOS ONE},
  volume = {6},
  number = {6},
  pages = {e21101},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0021101},
  abstract = {Background Scientific research in the 21st century is more data intensive and collaborative than in the past. It is important to study the data practices of researchers \textendash{} data accessibility, discovery, re-use, preservation and, particularly, data sharing. Data sharing is a valuable part of the scientific method allowing for verification of results and extending research from prior results. Methodology/Principal Findings A total of 1329 scientists participated in this survey exploring current data sharing practices and perceptions of the barriers and enablers of data sharing. Scientists do not make their data electronically available to others for various reasons, including insufficient time and lack of funding. Most respondents are satisfied with their current processes for the initial and short-term parts of the data or research lifecycle (collecting their research data; searching for, describing or cataloging, analyzing, and short-term storage of their data) but are not satisfied with long-term data preservation. Many organizations do not provide support to their researchers for data management both in the short- and long-term. If certain conditions are met (such as formal citation and sharing reprints) respondents agree they are willing to share their data. There are also significant differences and approaches in data management practices based on primary funding agency, subject discipline, age, work focus, and world region. Conclusions/Significance Barriers to effective data sharing and preservation are deeply rooted in the practices and culture of the research process as well as the researchers themselves. New mandates for data management plans from NSF and other federal agencies and world-wide attention to the need to share and preserve data could lead to changes. Large scale programs, such as the NSF-sponsored DataNET (including projects like DataONE) will both bring attention and resources to the issue and make it easier for scientists to apply sound data management principles.},
  langid = {english},
  keywords = {Data management,data with secrets,Ecology and environmental sciences,Europe,Medicine and health sciences,Metadata,open data,Scientists,Social sciences,Surveys},
  file = {/Users/charliejhadley/Zotero/storage/7T29N5RV/Tenopir et al. - 2011 - Data Sharing by Scientists Practices and Percepti.pdf;/Users/charliejhadley/Zotero/storage/4LISN3VQ/article.html}
}

@article{thornton_towards_2022,
  title = {Towards Statistical Best Practices for Gender and Sex Data},
  author = {Thornton, Suzanne and Roy, Dooti and Parry, Stephen and LaLonde, Donna and Martinez, Wendy and Ellis, Renee and Corliss, David},
  year = {2022},
  journal = {Significance},
  volume = {19},
  number = {1},
  pages = {40--45},
  issn = {1740-9713},
  doi = {10.1111/1740-9713.01614},
  abstract = {Suzanne Thornton, Dooti Roy, Stephen Parry, Donna LaLonde, Wendy Martinez, Renee Ellis and David Corliss call for a more inclusive \textendash{} and informative \textendash{} approach to collecting data on human gender and sex},
  langid = {english},
  keywords = {gender and statistics},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1740-9713.01614},
  file = {/Users/charliejhadley/Zotero/storage/Z8BJ7Q4X/Thornton et al. - 2022 - Towards statistical best practices for gender and .pdf;/Users/charliejhadley/Zotero/storage/7TUEPR9Q/1740-9713.html}
}

@misc{uk_government_data_2018,
  title = {Data {{Protection Act}} 2018},
  author = {{UK Government}},
  year = {2018},
  publisher = {{Queen's Printer of Acts of Parliament}},
  howpublished = {https://www.legislation.gov.uk/ukpga/2018/12/contents/enacted},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/GHEX2UN3/UK Government - 2018 - Data Protection Act 2018.pdf;/Users/charliejhadley/Zotero/storage/VSYDAIT7/enacted.html}
}

@misc{uk_government_equality_2010,
  title = {Equality {{Act}} 2010},
  author = {{UK Government}},
  year = {2010},
  journal = {legislation.gov.uk},
  howpublished = {https://www.legislation.gov.uk/ukpga/2010/15/contents}
}

@misc{uk_government_national_2006,
  title = {National {{Health Service Act}} 2006},
  author = {{UK Government}},
  year = {2006},
  publisher = {{Statute Law Database}},
  abstract = {An Act to consolidate certain enactments relating to the health service.},
  howpublished = {https://www.legislation.gov.uk/ukpga/2006/41/contents},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/QYYLRE7I/contents.html}
}

@misc{uk_government_open_2022,
  title = {Open {{Government Licence}}},
  author = {{UK Government}},
  year = {2022},
  abstract = {UK Government Open Government License},
  howpublished = {https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/},
  file = {/Users/charliejhadley/Zotero/storage/HFTQSM6S/3.html}
}

@misc{ukri_ukri_2022,
  title = {{{UKRI Common Principles}} on {{Research Data}}},
  author = {{UKRI}},
  year = {2022},
  month = aug,
  howpublished = {https://www.ukri.org/manage-your-award/publishing-your-research-findings/making-your-research-data-open/},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/J73LUXM5/making-your-research-data-open.html}
}

@misc{ukri_ukri_2022-1,
  title = {{{UKRI Open Access Policy}}},
  author = {{UKRI}},
  year = {2022},
  month = jul,
  howpublished = {https://www.ukri.org/wp-content/uploads/2022/07/UKRI-28072022-Final\_UKRI-Open-Access-Policy\_Version-1.5\_July-2022.pdf}
}

@misc{united_nations_general_assembly_universal_1948,
  title = {Universal {{Declaration}} of {{Human Rights}}},
  author = {{United Nations General Assembly}},
  year = {1948},
  month = dec,
  publisher = {{United Nations General Assembly}}
}

@inproceedings{urban_measuring_2020,
  title = {Measuring the {{Impact}} of the {{GDPR}} on {{Data Sharing}} in {{Ad Networks}}},
  booktitle = {Proceedings of the 15th {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Urban, Tobias and Tatang, Dennis and Degeling, Martin and Holz, Thorsten and Pohlmann, Norbert},
  year = {2020},
  month = oct,
  pages = {222--235},
  publisher = {{ACM}},
  address = {{Taipei Taiwan}},
  doi = {10.1145/3320269.3372194},
  isbn = {978-1-4503-6750-9},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/MZLR5JKI/Urban et al. - 2020 - Measuring the Impact of the GDPR on Data Sharing i.pdf}
}

@article{venkataramanan_madhumita_2014,
  title = {Madhumita {{Venkataramanan}}: {{My}} Identity for Sale},
  shorttitle = {Madhumita {{Venkataramanan}}},
  author = {Venkataramanan, Madhumita},
  year = {2014},
  month = oct,
  journal = {Wired UK},
  issn = {1357-0978},
  abstract = {Even as you're reading this, your smartphone can reveal your location},
  chapter = {tags},
  langid = {british},
  keywords = {data,magazine,november 2014 issue,technology},
  file = {/Users/charliejhadley/Zotero/storage/AARJWR48/my-identity-for-sale.html}
}

@article{viet_data-driven_2020,
  title = {Data-Driven Process Redesign: Anticipatory Shipping in Agro-Food Supply Chains},
  shorttitle = {Data-Driven Process Redesign},
  author = {Viet, Nguyen Quoc and Behdani, Behzad and Bloemhof, Jacqueline},
  year = {2020},
  month = mar,
  journal = {International Journal of Production Research},
  volume = {58},
  number = {5},
  pages = {1302--1318},
  publisher = {{Taylor \& Francis}},
  issn = {0020-7543},
  doi = {10.1080/00207543.2019.1629673},
  abstract = {Anticipatory shipping uses historical order and customer data to predict future orders and accordingly ship products to the nearest distribution centres before customers actually place the orders. It is a method to meet the increasing customer requirements on delivery service and simultaneously to reduce operational costs. This paper presents a case of anticipatory shipping in the context of agro-food supply chains. The challenge in these chains is the product perishability that leads to product obsolescence in the case of un-balanced supply and demand. This study introduces a data-driven approach that integrates product quality characteristics in data analytics to identify suitable products for anticipatory shipping at the strategic level. It also proposes process redesigns concerning production and transportation at the operational level to realise anticipatory shipping. Finally, using historical data from a Dutch floriculture supplier as input for a multi-agent simulation, the proposed approach and process redesigns are verified. The simulation output shows that anticipatory shipping could increase delivery service level up to 35.3\% and reduce associated costs up to 9.3\%.},
  keywords = {agro-food,anticipatory shipping,association rule mining,multi-agent simulation,perishable,process redesign},
  annotation = {\_eprint: https://doi.org/10.1080/00207543.2019.1629673},
  file = {/Users/charliejhadley/Zotero/storage/L3LI92UZ/Viet et al. - 2020 - Data-driven process redesign anticipatory shippin.pdf}
}

@techreport{von_borzyskowski_data_2021,
  title = {Data Science and {{AI}} in the Age of {{COVID-19}}},
  author = {{von Borzyskowski}, Inken and Mateen, Bilal and Mazumder, Anjali and Wooldridge, Michael},
  year = {2021},
  month = jun,
  pages = {1--13},
  institution = {{The Alan Turing Institute}},
  langid = {english},
  keywords = {covid ai replicability,reproducibility crisis},
  file = {/Users/charliejhadley/Zotero/storage/LV27VXR2/data-science-and-ai-in-the-age-of-covid_full-report_2.pdf}
}

@misc{vox_color_2015,
  title = {Color Film Was Built for White People. {{Here}}'s What It Did to Dark Skin.},
  author = {{Vox}},
  year = {2015},
  month = sep
}

@misc{ward_table_2017,
  type = {Text},
  title = {{{TABLE}} 1, {{Fitzpatrick Classification}} of {{Skin Types I}} through {{VI}}},
  author = {Ward, William H. and Lambreton, Fernando and Goel, Neha and Yu, Jian Q. and Farma, Jeffrey M.},
  year = {2017},
  month = dec,
  publisher = {{Codon Publications}},
  howpublished = {https://www.ncbi.nlm.nih.gov/books/NBK481857/table/chapter6.t1/},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/KUFQER6Y/chapter6.t1.html}
}

@misc{waxman_whoops_2010,
  title = {Whoops! {{Netflix Gets Caught}} by {{FTC}}, {{Cancels Contest}}},
  author = {Waxman, Sharon},
  year = {2010},
  month = mar,
  abstract = {Movie download company found a contest revealed identity of its customer base},
  chapter = {Movies},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/L6HUICQR/whoops-netflix-gets-caught-ftc-cancels-contest-15231.html}
}

@book{wei_algorithmic_2017,
  title = {Algorithmic {{Discrimination White Paper}}},
  author = {Wei, Vicky and Stephenson, Teresa},
  year = {2017},
  month = may,
  publisher = {{University of Washington Technology Law and Public Policy Clinic}},
  address = {{Seattle}},
  abstract = {Technological innovation has led to the prevalent use of algorithms in everyday decision making. So ubiquitous is the application of algorithms that many may not recognize its impact on their daily lives. From online shopping to applying for a home loan, algorithms are at play in categorizing and filtering individuals to serve the goal of providing more accurate and efficient results than human decisionmaking would. At the basic level, algorithms are nothing more than a series of step-by-step instructions compiled by a computer, which then analyzes swaths of data based on those instructions. However, when algorithms use incorrect variables to filter results\textemdash such as certain stereotypes about minorities\textemdash or, more imperceptibly, learn bad habits from how humans behave online, our absolute reliance on their results can cause disparate harm to minority communities. The pervasive use of algorithms by both corporate and government organizations for the purposes of efficiency and pattern analysis in the collection of Big Data has brought questions to light as to (1) whether these algorithms are fair across the board and (2) whether they contribute to disparate outcomes resulting in discriminatory practices. The inquiry then ultimately turns to the legal methods to regulate algorithms in order to combat their negative influence while still maintaining all the technological success and convenience society enjoys.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/2UJABZIC/Wei and Stephenson - Algorithmic Discrimination White Paper.pdf}
}

@techreport{wellcome_trust_public_nodate,
  title = {Public Attitudes to Commercial Access to Health Data},
  author = {{Wellcome Trust}}
}

@book{wickham_r_2016,
  title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
  shorttitle = {R for Data Science},
  author = {Wickham, Hadley and Grolemund, Garrett},
  year = {2016},
  edition = {First edition},
  publisher = {{O'Reilly}},
  address = {{Sebastopol, CA}},
  abstract = {This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience},
  isbn = {978-1-4919-1039-9 978-1-4919-1036-8},
  lccn = {QA276.45.R3 W53 2016},
  keywords = {Big data,Computer programs,Data mining,Databases,Electronic data processing,Information visualization,R (Computer program language),Statistics},
  annotation = {OCLC: ocn968213225}
}

@article{wickham_tidy_2014,
  title = {Tidy {{Data}}},
  author = {Wickham, Hadley},
  year = {2014},
  month = sep,
  journal = {Journal of Statistical Software},
  volume = {59},
  pages = {1--23},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
  copyright = {Copyright (c) 2013 Hadley  Wickham},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/C2ZD2CEX/Wickham - 2014 - Tidy Data.pdf}
}

@article{wiogo_understanding_2011,
  title = {Understanding the {{Formation}} of {{Iron Oxide Nanoparticles}} with {{Acicular Structure}} from {{Iron}}({{III}}) {{Chloride}} and {{Hydrazine Monohydrate}}},
  author = {Wiogo, Hilda and Lim, May and Munroe, Paul and Amal, Rose},
  year = {2011},
  month = may,
  journal = {Crystal Growth \& Design},
  volume = {11},
  number = {5},
  pages = {1689--1696},
  publisher = {{American Chemical Society}},
  issn = {1528-7483},
  doi = {10.1021/cg101623n},
  abstract = {Iron oxide nanoparticles, nanowires, and nanobelts were prepared from a 50 vol \% ethanol solution of 28 mM iron(III) chloride and 0.3 mM polyethylene glycol (20 kDa) by hydrothermal treatment at 120 \textdegree C, using hydrazine monohydrate (N2H4) as a reducing agent. Factors governing phase and morphology of the iron oxide nanoparticles were studied. The amount of hydrazine added affected the hydrolysis of iron(III); therefore, the type of iron oxyhydroxide formed; this in turn controlled whether akagan\'eite, goethite, hematite, or magnetite was obtained after the hydrothermal treatment step. For conditions that favored the formation of magnetite, the addition rate of hydrazine was shown to affect the reduction of iron(III) to iron(II) and, hence, the relative amount of magnetite and goethite in the final product. Increasing the pH of the precursor solution to 14 resulted in the formation of magnetite nanobelts. Phase analysis of the intermediate products showed that the magnetite nanobelts were formed from the dissolution of goethite nanowires at high pH, interspersed with the partial reduction of iron(III) to iron(II) by hydrazine, and reaction between iron(III) and iron(II) to form magnetite on the surface of the goethite nanowires.}
}

@misc{world_bank_open_2021,
  title = {Open {{Data Essentials}} | {{Data}}},
  author = {{World Bank}},
  year = {2021},
  month = may,
  abstract = {The Open Government Data Toolkit is designed to help governments, Bank staff and users understand the basic precepts of Open Data, then get "up to speed" in planning and implementing an open government data program, while avoiding common pitfalls.},
  howpublished = {http://opendatatoolkit.worldbank.org/en/essentials.html},
  langid = {english},
  keywords = {open data policy},
  file = {/Users/charliejhadley/Zotero/storage/HWSVLDUH/essentials.html}
}

@misc{world_medical_association_declaration_2013,
  title = {Declaration of {{Helsinki}}, {{Ethical Principles}} for {{Medical Research}} Involving Human Subjects},
  author = {{World Medical Association}},
  year = {2013},
  howpublished = {https://www.wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/}
}

@inproceedings{xiao_hardness_2010,
  title = {The Hardness and Approximation Algorithms for L-Diversity},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Extending Database Technology}}},
  author = {Xiao, Xiaokui and Yi, Ke and Tao, Yufei},
  year = {2010},
  month = mar,
  series = {{{EDBT}} '10},
  pages = {135--146},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1739041.1739060},
  abstract = {The existing solutions to privacy preserving publication can be classified into the theoretical and heuristic categories. The former guarantees provably low information loss, whereas the latter incurs gigantic loss in the worst case, but is shown empirically to perform well on many real inputs. While numerous heuristic algorithms have been developed to satisfy advanced privacy principles such as l-diversity, t-closeness, etc., the theoretical category is currently limited to k-anonymity which is the earliest principle known to have severe vulnerability to privacy attacks. Motivated by this, we present the first theoretical study on l-diversity, a popular principle that is widely adopted in the literature. First, we show that optimal l-diverse generalization is NP-hard even when there are only 3 distinct sensitive values in the microdata. Then, an (l {$\cdot$} d)-approximation algorithm is developed, where d is the dimensionality of the underlying dataset. This is the first known algorithm with a non-trivial bound on information loss. Extensive experiments with real datasets validate the effectiveness and efficiency of proposed solution.},
  isbn = {978-1-60558-945-9},
  file = {/Users/charliejhadley/Zotero/storage/FBJSFTN7/Xiao et al. - 2010 - The hardness and approximation algorithms for l-di.pdf}
}

@article{yanai_hypothesis_2020,
  title = {A Hypothesis Is a Liability},
  author = {Yanai, Itai and Lercher, Martin},
  year = {2020},
  month = sep,
  journal = {Genome Biology},
  volume = {21},
  number = {1},
  pages = {231},
  issn = {1474-760X},
  doi = {10.1186/s13059-020-02133-w},
  keywords = {data with secrets},
  file = {/Users/charliejhadley/Zotero/storage/5NGJBVKP/Yanai and Lercher - 2020 - A hypothesis is a liability.pdf;/Users/charliejhadley/Zotero/storage/9JGIEB7N/s13059-020-02133-w.html}
}

@article{zhang_efficient_2017,
  title = {On {{Efficient}} and {{Robust Anonymization}} for {{Privacy Protection}} on {{Massive Streaming Categorical Information}}},
  author = {Zhang, Ji and Li, Hongzhou and Liu, Xuemei and Luo, Yonglong and Chen, Fulong and Wang, Hua and Chang, Liang},
  year = {2017},
  month = sep,
  journal = {IEEE Transactions on Dependable and Secure Computing},
  volume = {14},
  number = {5},
  pages = {507--520},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2015.2483503},
  abstract = {Protecting users' privacy when transmitting a large amount of data over the Internet is becoming increasingly important nowadays. In this paper, we focus on the streaming categorical information and propose a novel anonymization technique for providing a strong privacy protection to safeguard against privacy disclosure and information tampering. Our technique utilizes an innovative two-phase anonymization approach which is very easy to implement, highly efficient in terms of speed and communication and is robust against possible tampering from adversaries. Extensive experimental evaluation that is conducted demonstrates that our technique is very efficient and more robust than the existing method.},
  keywords = {anonymization,categorical information,Data privacy,Decoding,Distortion,Encoding,Privacy,Privacy protection,Real-time systems,Robustness},
  file = {/Users/charliejhadley/Zotero/storage/56E4IUKU/Zhang et al. - 2017 - On Efficient and Robust Anonymization for Privacy .pdf}
}

@misc{zuckerberg_our_2011,
  title = {Our {{Commitment}} to the {{Facebook Community}}},
  author = {Zuckerberg, Mark},
  year = {2011},
  month = nov,
  journal = {Meta},
  abstract = {By Mark Zuckerberg I founded Facebook on the idea that people want to share and connect with people in their lives, but to do this everyone needs complete},
  langid = {american},
  file = {/Users/charliejhadley/Zotero/storage/LYRP55LP/our-commitment-to-the-facebook-community.html}
}

@article{zuo_data_2021,
  title = {Data {{Anonymization}} for {{Pervasive Health Care}}: {{Systematic Literature Mapping Study}}},
  shorttitle = {Data {{Anonymization}} for {{Pervasive Health Care}}},
  author = {Zuo, Zheming and Watson, Matthew and Budgen, David and Hall, Robert and Kennelly, Chris and Moubayed, Noura Al},
  year = {2021},
  month = oct,
  journal = {JMIR Medical Informatics},
  volume = {9},
  number = {10},
  pages = {e29871},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/29871},
  abstract = {Background: Data science offers an unparalleled opportunity to identify new insights into many aspects of human life with recent advances in health care. Using data science in digital health raises significant challenges regarding data privacy, transparency, and trustworthiness. Recent regulations enforce the need for a clear legal basis for collecting, processing, and sharing data, for example, the European Union's General Data Protection Regulation (2016) and the United Kingdom's Data Protection Act (2018). For health care providers, legal use of the electronic health record (EHR) is permitted only in clinical care cases. Any other use of the data requires thoughtful considerations of the legal context and direct patient consent. Identifiable personal and sensitive information must be sufficiently anonymized. Raw data are commonly anonymized to be used for research purposes, with risk assessment for reidentification and utility. Although health care organizations have internal policies defined for information governance, there is a significant lack of practical tools and intuitive guidance about the use of data for research and modeling. Off-the-shelf data anonymization tools are developed frequently, but privacy-related functionalities are often incomparable with regard to use in different problem domains. In addition, tools to support measuring the risk of the anonymized data with regard to reidentification against the usefulness of the data exist, but there are question marks over their efficacy. Objective: In this systematic literature mapping study, we aim to alleviate the aforementioned issues by reviewing the landscape of data anonymization for digital health care. Methods: We used Google Scholar, Web of Science, Elsevier Scopus, and PubMed to retrieve academic studies published in English up to June 2020. Noteworthy gray literature was also used to initialize the search. We focused on review questions covering 5 bottom-up aspects: basic anonymization operations, privacy models, reidentification risk and usability metrics, off-the-shelf anonymization tools, and the lawful basis for EHR data anonymization. Results: We identified 239 eligible studies, of which 60 were chosen for general background information; 16 were selected for 7 basic anonymization operations; 104 covered 72 conventional and machine learning\textendash based privacy models; four and 19 papers included seven and 15 metrics, respectively, for measuring the reidentification risk and degree of usability; and 36 explored 20 data anonymization software tools. In addition, we also evaluated the practical feasibility of performing anonymization on EHR data with reference to their usability in medical decision-making. Furthermore, we summarized the lawful basis for delivering guidance on practical EHR data anonymization. Conclusions: This systematic literature mapping study indicates that anonymization of EHR data is theoretically achievable; yet, it requires more research efforts in practical implementations to balance privacy preservation and usability to ensure more reliable health care applications.},
  copyright = {This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published JMIR Medical Informatics, is properly cited. The complete bibliographic information, a link to the original publication on https://medinform.jmir.org/, as well as this copyright and license information must be included.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/ND8PTWZ9/Zuo et al. - 2021 - Data Anonymization for Pervasive Health Care Syst.pdf;/Users/charliejhadley/Zotero/storage/967F6JKW/e29871.html}
}

@article{zuo_data_2021-1,
  title = {Data {{Anonymization}} for {{Pervasive Health Care}}: {{Systematic Literature Mapping Study}}},
  shorttitle = {Data {{Anonymization}} for {{Pervasive Health Care}}},
  author = {Zuo, Zheming and Watson, Matthew and Budgen, David and Hall, Robert and Kennelly, Chris and Al Moubayed, Noura},
  year = {2021},
  month = oct,
  journal = {JMIR Medical Informatics},
  volume = {9},
  number = {10},
  pages = {e29871},
  issn = {2291-9694},
  doi = {10.2196/29871},
  abstract = {Background: Data science offers an unparalleled opportunity to identify new insights into many aspects of human life with recent advances in health care. Using data science in digital health raises significant challenges regarding data privacy, transparency, and trustworthiness. Recent regulations enforce the need for a clear legal basis for collecting, processing, and sharing data, for example, the European Union's General Data Protection Regulation (2016) and the United Kingdom's Data Protection Act (2018). For health care providers, legal use of the electronic health record (EHR) is permitted only in clinical care cases. Any other use of the data requires thoughtful considerations of the legal context and direct patient consent. Identifiable personal and sensitive information must be sufficiently anonymized. Raw data are commonly anonymized to be used for research purposes, with risk assessment for reidentification and utility. Although health care organizations have internal policies defined for information governance, there is a significant lack of practical tools and intuitive guidance about the use of data for research and modeling. Off-the-shelf data anonymization tools are developed frequently, but privacy-related functionalities are often incomparable with regard to use in different problem domains. In addition, tools to support measuring the risk of the anonymized data with regard to reidentification against the usefulness of the data exist, but there are question marks over their efficacy. Objective: In this systematic literature mapping study, we aim to alleviate the aforementioned issues by reviewing the landscape of data anonymization for digital health care. Methods: We used Google Scholar, Web of Science, Elsevier Scopus, and PubMed to retrieve academic studies published in English up to June 2020. Noteworthy gray literature was also used to initialize the search. We focused on review questions covering 5 bottom-up aspects: basic anonymization operations, privacy models, reidentification risk and usability metrics, off-the-shelf anonymization tools, and the lawful basis for EHR data anonymization. Results: We identified 239 eligible studies, of which 60 were chosen for general background information; 16 were selected for 7 basic anonymization operations; 104 covered 72 conventional and machine learning\textendash based privacy models; four and 19 papers included seven and 15 metrics, respectively, for measuring the reidentification risk and degree of usability; and 36 explored 20 data anonymization software tools. In addition, we also evaluated the practical feasibility of performing anonymization on EHR data with reference to their usability in medical decision-making. Furthermore, we summarized the lawful basis for delivering guidance on practical EHR data anonymization. Conclusions: This systematic literature mapping study indicates that anonymization of EHR data is theoretically achievable; yet, it requires more research efforts in practical implementations to balance privacy preservation and usability to ensure more reliable health care applications.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/FUX7YCW5/Zuo et al. - 2021 - Data Anonymization for Pervasive Health Care Syst.pdf}
}

@article{zuo_data_2021-2,
  title = {Data {{Anonymization}} for {{Pervasive Health Care}}: {{Systematic Literature Mapping Study}}},
  shorttitle = {Data {{Anonymization}} for {{Pervasive Health Care}}},
  author = {Zuo, Zheming and Watson, Matthew and Budgen, David and Hall, Robert and Kennelly, Chris and Al Moubayed, Noura},
  year = {2021},
  month = oct,
  journal = {JMIR Medical Informatics},
  volume = {9},
  number = {10},
  pages = {e29871},
  issn = {2291-9694},
  doi = {10.2196/29871},
  abstract = {Background: Data science offers an unparalleled opportunity to identify new insights into many aspects of human life with recent advances in health care. Using data science in digital health raises significant challenges regarding data privacy, transparency, and trustworthiness. Recent regulations enforce the need for a clear legal basis for collecting, processing, and sharing data, for example, the European Union's General Data Protection Regulation (2016) and the United Kingdom's Data Protection Act (2018). For health care providers, legal use of the electronic health record (EHR) is permitted only in clinical care cases. Any other use of the data requires thoughtful considerations of the legal context and direct patient consent. Identifiable personal and sensitive information must be sufficiently anonymized. Raw data are commonly anonymized to be used for research purposes, with risk assessment for reidentification and utility. Although health care organizations have internal policies defined for information governance, there is a significant lack of practical tools and intuitive guidance about the use of data for research and modeling. Off-the-shelf data anonymization tools are developed frequently, but privacy-related functionalities are often incomparable with regard to use in different problem domains. In addition, tools to support measuring the risk of the anonymized data with regard to reidentification against the usefulness of the data exist, but there are question marks over their efficacy. Objective: In this systematic literature mapping study, we aim to alleviate the aforementioned issues by reviewing the landscape of data anonymization for digital health care. Methods: We used Google Scholar, Web of Science, Elsevier Scopus, and PubMed to retrieve academic studies published in English up to June 2020. Noteworthy gray literature was also used to initialize the search. We focused on review questions covering 5 bottom-up aspects: basic anonymization operations, privacy models, reidentification risk and usability metrics, off-the-shelf anonymization tools, and the lawful basis for EHR data anonymization. Results: We identified 239 eligible studies, of which 60 were chosen for general background information; 16 were selected for 7 basic anonymization operations; 104 covered 72 conventional and machine learning\textendash based privacy models; four and 19 papers included seven and 15 metrics, respectively, for measuring the reidentification risk and degree of usability; and 36 explored 20 data anonymization software tools. In addition, we also evaluated the practical feasibility of performing anonymization on EHR data with reference to their usability in medical decision-making. Furthermore, we summarized the lawful basis for delivering guidance on practical EHR data anonymization. Conclusions: This systematic literature mapping study indicates that anonymization of EHR data is theoretically achievable; yet, it requires more research efforts in practical implementations to balance privacy preservation and usability to ensure more reliable health care applications.},
  langid = {english},
  file = {/Users/charliejhadley/Zotero/storage/ENVYWT3I/Zuo et al. - 2021 - Data Anonymization for Pervasive Health Care Syst.pdf}
}

